{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "import random\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import pandas as pd\n",
    "#sys.path.append(\"/home/CVShare/Jeni/hts/machine_learning/sampling_with_data_cleaning\")\n",
    "import sampling_with_data_cleaning as sdc\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN on cleaned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47383,)\n",
      "907.0\n",
      "907\n"
     ]
    }
   ],
   "source": [
    "findex = 1\n",
    "x,y = get_features(findex,train=True,cleaned=True)\n",
    "print y.shape\n",
    "print sum(y)\n",
    "y = y.astype(int)\n",
    "print sum(y)\n",
    "x,y = shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47383 154\n"
     ]
    }
   ],
   "source": [
    "no_ex,ip_dim = x.shape\n",
    "print no_ex,ip_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_mlp_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c_mlp_1,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,1000)\n",
    "        self.l2 = nn.Linear(1000,1000)\n",
    "        self.l3 = nn.Linear(1000,500)\n",
    "        #self.l4 = nn.Linear(500,500)\n",
    "        self.l5 = nn.Linear(500,100)\n",
    "        self.l6 = nn.Linear(100,50)\n",
    "        self.l7 = nn.Linear(50,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = F.leaky_relu(self.l3(x))\n",
    "        #x = F.leaky_relu(self.l4(x))\n",
    "        x = F.leaky_relu(self.l5(x))\n",
    "        x = F.leaky_relu(self.l6(x))\n",
    "        x = (self.l7(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_mlp_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c_mlp_2,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,1000)\n",
    "        self.l2 = nn.Linear(1000,1000)\n",
    "        self.l3 = nn.Linear(1000,500)\n",
    "        #self.l4 = nn.Linear(500,500)\n",
    "        self.l5 = nn.Linear(500,100)\n",
    "        self.l6 = nn.Linear(100,50)\n",
    "        self.l7 = nn.Linear(50,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.l1(x))\n",
    "        x = F.tanh(self.l2(x))\n",
    "        x = F.tanh(self.l3(x))\n",
    "        #x = F.leaky_relu(self.l4(x))\n",
    "        x = F.tanh(self.l5(x))\n",
    "        x = F.tanh(self.l6(x))\n",
    "        x = (self.l7(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_mlp_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c_mlp_3,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,1000)\n",
    "        self.l2 = nn.Linear(1000,1000)\n",
    "        self.l3 = nn.Linear(1000,500)\n",
    "        #self.l4 = nn.Linear(500,500)\n",
    "        self.l5 = nn.Linear(500,100)\n",
    "        self.l6 = nn.Linear(100,50)\n",
    "        self.l7 = nn.Linear(50,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.selu(self.l1(x))\n",
    "        x = F.selu(self.l2(x))\n",
    "        x = F.selu(self.l3(x))\n",
    "        #x = F.leaky_relu(self.l4(x))\n",
    "        x = F.selu(self.l5(x))\n",
    "        x = F.selu(self.l6(x))\n",
    "        x = (self.l7(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mymlps = [c_mlp_1().cuda(),c_mlp_2().cuda(),c_mlp_3().cuda()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('val iter: ', 1)\n",
      "('tn, fp, fn, tp: ', array([9274,   27,    3,  172]))\n",
      "('min fp, max_percent', 27, 0.9828571428571429)\n",
      "('saving model on val: ', 1, ' and weight: ', 40.0)\n",
      "('tn, fp, fn, tp: ', array([9278,   23,    7,  168]))\n",
      "('tn, fp, fn, tp: ', array([9274,   27,   10,  165]))\n",
      "('tn, fp, fn, tp: ', array([9269,   32,   16,  159]))\n",
      "('tn, fp, fn, tp: ', array([9282,   19,   19,  156]))\n",
      "('val iter: ', 2)\n",
      "('tn, fp, fn, tp: ', array([9260,   21,    3,  193]))\n",
      "('min fp, max_percent', 21, 0.9846938775510204)\n",
      "('saving model on val: ', 2, ' and weight: ', 40.0)\n",
      "('tn, fp, fn, tp: ', array([9256,   25,    4,  192]))\n",
      "('tn, fp, fn, tp: ', array([9256,   25,    7,  189]))\n",
      "('tn, fp, fn, tp: ', array([9256,   25,    7,  189]))\n",
      "('tn, fp, fn, tp: ', array([9251,   30,    9,  187]))\n",
      "('val iter: ', 3)\n",
      "('tn, fp, fn, tp: ', array([9266,   23,    0,  187]))\n",
      "('tn, fp, fn, tp: ', array([9268,   21,    2,  185]))\n",
      "('tn, fp, fn, tp: ', array([9256,   33,    6,  181]))\n",
      "('tn, fp, fn, tp: ', array([9268,   21,   13,  174]))\n",
      "('tn, fp, fn, tp: ', array([9257,   32,   15,  172]))\n",
      "('val iter: ', 4)\n",
      "('tn, fp, fn, tp: ', array([9291,    4,    5,  177]))\n",
      "('tn, fp, fn, tp: ', array([9292,    3,   10,  172]))\n",
      "('tn, fp, fn, tp: ', array([9289,    6,   10,  172]))\n",
      "('tn, fp, fn, tp: ', array([9289,    6,   12,  170]))\n",
      "('tn, fp, fn, tp: ', array([9279,   16,   15,  167]))\n",
      "('val iter: ', 5)\n",
      "('tn, fp, fn, tp: ', array([9299,   11,    0,  167]))\n",
      "('tn, fp, fn, tp: ', array([9298,   12,    4,  163]))\n",
      "('tn, fp, fn, tp: ', array([9240,   70,    5,  162]))\n",
      "('tn, fp, fn, tp: ', array([9292,   18,    8,  159]))\n",
      "('tn, fp, fn, tp: ', array([9296,   14,   12,  155]))\n",
      "('val iter: ', 1)\n",
      "('tn, fp, fn, tp: ', array([7724, 1577,   56,  119]))\n",
      "('tn, fp, fn, tp: ', array([7729, 1572,   59,  116]))\n",
      "('tn, fp, fn, tp: ', array([7760, 1541,   53,  122]))\n",
      "('tn, fp, fn, tp: ', array([7784, 1517,   48,  127]))\n",
      "('tn, fp, fn, tp: ', array([7986, 1315,   38,  137]))\n",
      "('val iter: ', 2)\n",
      "('tn, fp, fn, tp: ', array([8089, 1192,   35,  161]))\n",
      "('tn, fp, fn, tp: ', array([8183, 1098,   30,  166]))\n",
      "('min fp, max_percent', 1098, 0.8469387755102041)\n",
      "('saving model on val: ', 2, ' and weight: ', 45.0)\n",
      "('tn, fp, fn, tp: ', array([8410,  871,   35,  161]))\n",
      "('tn, fp, fn, tp: ', array([8546,  735,   38,  158]))\n",
      "('tn, fp, fn, tp: ', array([8644,  637,   36,  160]))\n",
      "('val iter: ', 3)\n",
      "('tn, fp, fn, tp: ', array([8789,  500,    9,  178]))\n",
      "('min fp, max_percent', 500, 0.9518716577540107)\n",
      "('saving model on val: ', 3, ' and weight: ', 40.0)\n",
      "('tn, fp, fn, tp: ', array([8922,  367,   20,  167]))\n",
      "('tn, fp, fn, tp: ', array([9001,  288,   25,  162]))\n",
      "('tn, fp, fn, tp: ', array([9077,  212,   33,  154]))\n",
      "('tn, fp, fn, tp: ', array([9072,  217,   31,  156]))\n",
      "('val iter: ', 4)\n",
      "('tn, fp, fn, tp: ', array([9179,  116,    2,  180]))\n",
      "('tn, fp, fn, tp: ', array([9180,  115,    6,  176]))\n",
      "('tn, fp, fn, tp: ', array([9186,  109,   12,  170]))\n",
      "('tn, fp, fn, tp: ', array([9200,   95,   16,  166]))\n",
      "('tn, fp, fn, tp: ', array([9217,   78,   22,  160]))\n",
      "('val iter: ', 5)\n",
      "('tn, fp, fn, tp: ', array([9247,   63,    0,  167]))\n",
      "('tn, fp, fn, tp: ', array([9244,   66,    2,  165]))\n",
      "('tn, fp, fn, tp: ', array([9243,   67,    3,  164]))\n",
      "('tn, fp, fn, tp: ', array([9246,   64,    6,  161]))\n",
      "('tn, fp, fn, tp: ', array([9243,   67,    8,  159]))\n",
      "('val iter: ', 1)\n",
      "('tn, fp, fn, tp: ', array([7855, 1446,   59,  116]))\n",
      "('tn, fp, fn, tp: ', array([7950, 1351,   51,  124]))\n",
      "('tn, fp, fn, tp: ', array([7946, 1355,   39,  136]))\n",
      "('tn, fp, fn, tp: ', array([8234, 1067,   46,  129]))\n",
      "('tn, fp, fn, tp: ', array([8388,  913,   40,  135]))\n",
      "('val iter: ', 2)\n",
      "('tn, fp, fn, tp: ', array([8550,  731,   17,  179]))\n",
      "('min fp, max_percent', 731, 0.9132653061224489)\n",
      "('saving model on val: ', 2, ' and weight: ', 40.0)\n",
      "('tn, fp, fn, tp: ', array([8605,  676,   19,  177]))\n",
      "('min fp, max_percent', 676, 0.9030612244897959)\n",
      "('saving model on val: ', 2, ' and weight: ', 45.0)\n",
      "('tn, fp, fn, tp: ', array([8807,  474,   30,  166]))\n",
      "('tn, fp, fn, tp: ', array([8787,  494,   25,  171]))\n",
      "('tn, fp, fn, tp: ', array([8951,  330,   37,  159]))\n",
      "('val iter: ', 3)\n",
      "('tn, fp, fn, tp: ', array([8912,  377,    4,  183]))\n",
      "('tn, fp, fn, tp: ', array([8980,  309,   13,  174]))\n",
      "('tn, fp, fn, tp: ', array([8998,  291,   15,  172]))\n"
     ]
    }
   ],
   "source": [
    "for mlp_no,mymlp in enumerate(mymlps):\n",
    "    max_percent = 0.85\n",
    "    model_no = 1\n",
    "    for i in range(1,6):\n",
    "        val_iter = i\n",
    "        print(\"val iter: \",val_iter)\n",
    "        \n",
    "        if model_no is 4:\n",
    "                break\n",
    "        else:\n",
    "        #weights_array = [7]\n",
    "            weights_array = np.linspace(40,60,5)\n",
    "\n",
    "            for i,w in enumerate(weights_array): \n",
    "            \n",
    "            \n",
    "           \n",
    "            #mymlp = c_mlp().cuda()\n",
    "                optimizer = torch.optim.Adagrad(mymlp.parameters(),lr=1e-3)\n",
    "                criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "                for ep in range(2500):\n",
    "\n",
    "                    ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "                    xtrain,ytrain = get_train_batch(x,y,batch_size=100,indices=ind)\n",
    "\n",
    "                    model_op = mymlp(xtrain)\n",
    "\n",
    "                    loss = criterion(model_op,ytrain)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            #     if(ep%30==29):\n",
    "            #         print(loss.data[0])\n",
    "\n",
    "                ## After training check on cross validation data\n",
    "                xval,yval = get_val_data(x,y,no_examples=no_ex,val_iter=val_iter)\n",
    "                min_fp = xval.size()[0]*0.17\n",
    "                yval = yval.reshape(yval.shape[0],)\n",
    "                train_op = mymlp(xval)\n",
    "                train_op = train_op.cpu().data.numpy()\n",
    "                pred_labels = np.argmax(train_op,axis=1)\n",
    "\n",
    "                cf = metrics.confusion_matrix(yval,pred_labels).ravel()\n",
    "                [tn,fp,fn,tp] = cf\n",
    "                print('tn, fp, fn, tp: ',cf)\n",
    "                percent = float(float(tp)/float(tp+fn))\n",
    "                if(percent>max_percent*0.98):\n",
    "                    if(fp<min_fp):\n",
    "                        if(model_no<3):\n",
    "                                max_percent = percent\n",
    "                                print(\"min fp, max_percent\",fp,percent)\n",
    "                                model_path = os.getcwd() + '/fnn_' + str(findex)+'_model'+str(model_no)+'_mlp'+str(mlp_no)\n",
    "                                torch.save(mymlp.state_dict(),model_path)\n",
    "                                print(\"saving model on val: \",val_iter,\" and weight: \",w)\n",
    "                                model_no = model_no + 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest_t,ytest = get_features(findex,train=False)\n",
    "xtest = Variable(torch.cuda.FloatTensor(xtest_t).cuda())\n",
    "final_pred = np.zeros(ytest.shape[0],)\n",
    "print final_pred.shape\n",
    "\n",
    "test_models = []\n",
    "for model in [c_mlp_1().cuda(),c_mlp_2().cuda(),c_mlp_3.().cuda()]:\n",
    "    for i range(3):\n",
    "        test_models.append(model)\n",
    "for mlp_no,test_model in enumerate(test_models):\n",
    "    model_path = os.getcwd() + '/fnn_' + str(findex)+'_model'+str(model_no)+'_mlp'+str(mlp_no)\n",
    "    \n",
    "    test_model.load_state_dict(torch.load(model_path))\n",
    "    test_op = test_model(xtest)\n",
    "    test_op = test_op.cpu().data.numpy()\n",
    "    pred_labels = np.argmax(test_op,axis=1).reshape(final_pred.shape[0],)\n",
    "    print pred_labels.shape\n",
    "    final_pred = pred_labels + final_pred\n",
    "    print final_pred.shape\n",
    "    cf = metrics.confusion_matrix(ytest,pred_labels).ravel()\n",
    "    print('tn, fp, fn, tp: ',cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pred[final_pred>1] = 1\n",
    "cf = metrics.confusion_matrix(ytest,final_pred).ravel()\n",
    "print('tn, fp, fn, tp: ',cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
