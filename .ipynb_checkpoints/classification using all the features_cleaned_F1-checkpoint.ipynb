{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "import random\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import pandas as pd\n",
    "#sys.path.append(\"/home/CVShare/Jeni/hts/machine_learning/sampling_with_data_cleaning\")\n",
    "import sampling_with_data_cleaning as sdc\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findex = 0\n",
    "x,y = get_features(findex,train=False)\n",
    "x,y = shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "856\n",
      "torch.Size([50, 1, 144]) torch.Size([50])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Variable' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8f92abec25a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_val_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_ex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mxval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Variable' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "no_ex = x.shape[0]\n",
    "print no_ex\n",
    "for val_iter in range(1,6):\n",
    "    ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "    xtrain,ytrain = get_train_batch(x,y,batch_size=50,indices=ind)\n",
    "    print xtrain.size(),ytrain.size()\n",
    "    xval,yval = get_val_data(x,y,no_examples=no_ex,val_iter=val_iter)\n",
    "    print xval.size(),yval.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(5)\n",
    "print t\n",
    "np.random.shuffle(t)\n",
    "print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c_mlp,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,500)\n",
    "        self.l2 = nn.Linear(500,500)\n",
    "        self.l3 = nn.Linear(500,250)\n",
    "        self.l4 = nn.Linear(250,50)\n",
    "        self.l5 = nn.Linear(50,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = F.leaky_relu(self.l3(x))\n",
    "        x = F.leaky_relu(self.l4(x))\n",
    "        x = (self.l5(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_fn = 15\n",
    "max_fp = 160\n",
    "cm_list = []\n",
    "batch_size = 128\n",
    "for i in range(1,6):\n",
    "    val_iter = i\n",
    "    print(\"val iter: \",val_iter)\n",
    "    \n",
    "   \n",
    "    #weights_array = [7]\n",
    "    weights_array = np.linspace(20,50,20)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(3000):\n",
    "            train_batch,target = get_train_batch(batch_size,binary = True,validation_iter = val_iter)\n",
    "            model_op = mymlp(train_batch)\n",
    "            #print(model_op.type)\n",
    "            #print(target.type)\n",
    "            loss = criterion(model_op,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    #     if(ep%30==29):\n",
    "    #         print(loss.data[0])\n",
    "\n",
    "        ## After training check on cross validation data\n",
    "        val_data,labels_val = get_val_data(val_iter,binary = True)\n",
    "        train_op = mymlp(val_data)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "        #tmp_labels = tmp_labels.data.cpu().numpy()\n",
    "        #print(sum(tmp_labels))\n",
    "        cf = metrics.confusion_matrix(labels_val,pred_labels).ravel()\n",
    "        #print(val_iter,w)\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        wcf = [val_iter] + [w] + [cf]\n",
    "        if(fn < 3):\n",
    "            cm_list.append(wcf)\n",
    "            if(fn<4):\n",
    "                if(fp < max_fp):\n",
    "                    max_fp = fp\n",
    "                    model_path = os.getcwd() + '/model_all_feat_file' + fname\n",
    "                    torch.save(mymlp.state_dict(),model_path)\n",
    "                    print(\"saving model on val: \",val_iter,\" and weight: \",w)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_fingerprints_test = []\n",
    "c_fingerprints_test = []\n",
    "labels_test = []\n",
    "with open(path+fname+'red_test.csv') as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        p_fingerprints_test.append(row[:bf])\n",
    "        c_fingerprints_test.append(row[bf:-1])\n",
    "        labels_test.append(row[-1])\n",
    "        \n",
    "p_fingerprints_test = np.asarray(p_fingerprints_test)[1:]\n",
    "p_fingerprints_test = p_fingerprints_test.astype(int)\n",
    "p_fingerprints_test[(p_fingerprints_test==0)] = -1\n",
    "\n",
    "c_fingerprints_test = np.asarray(c_fingerprints_test)[1:]\n",
    "c_fingerprints_test = c_fingerprints_test.astype(float)\n",
    "\n",
    "#Normalise the features\n",
    "c_fingerprints_test = (c_fingerprints_test - np.mean(c_fingerprints_test,axis=0))/np.std(c_fingerprints_test,axis=0)\n",
    "\n",
    "fingerprints_test = np.concatenate((p_fingerprints_test,c_fingerprints_test),axis=1)\n",
    "\n",
    "#p2_fingerprints = np.ones(p_fingerprints.shape)\n",
    "(no_examples_test , ip_dim_test) = fingerprints_test.shape\n",
    "labels_test = labels_test[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels2_test = np.zeros((len(labels_test),1))\n",
    "for i,l in enumerate(labels_test):\n",
    "    if l=='Active':\n",
    "        labels2_test[i] = 1\n",
    "    else:\n",
    "        labels2_test[i] = 0\n",
    "labels2_test = labels2_test.astype(int)\n",
    "total_pos = np.sum(labels2_test)\n",
    "print(\"tot_positive\",total_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model = c_mlp().cuda()\n",
    "test_x = Variable(torch.cuda.FloatTensor(fingerprints_test).cuda())\n",
    "model_path = os.getcwd() + '/model_all_feat_file'+fname\n",
    "test_model.load_state_dict(torch.load(model_path))\n",
    "test_op = test_model(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_op = test_op.cpu().data.numpy()\n",
    "pred_labels = np.argmax(test_op,axis=1)\n",
    "cf = metrics.confusion_matrix(labels2_test,pred_labels).ravel()\n",
    "print('tn, fp, fn, tp: ',cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
