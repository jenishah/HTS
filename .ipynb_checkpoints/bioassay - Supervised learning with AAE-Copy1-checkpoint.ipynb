{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "import random\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('screen_info.txt','rb') as fl:\n",
    "    t = pickle.load(fl)\n",
    "fnames = t[0]\n",
    "totf = t[1]\n",
    "binf = t[2]\n",
    "runfile = 1\n",
    "fname = fnames[runfile]\n",
    "bf = binf[runfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47831, 122)\n",
      "['0' '0' '0' '0']\n",
      "(47831, 122)\n",
      "('total no of 1s', 256419)\n",
      "('total no of 0s', 5578963)\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + '/bioassay-datasets/'\n",
    "p_fingerprints = []\n",
    "c_fingerprints = []\n",
    "labels = []\n",
    "\n",
    "with open(path+fname+'red_train.csv') as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        p_fingerprints.append(row[:bf])\n",
    "        c_fingerprints.append(row[bf:-1])\n",
    "        labels.append(row[-1])\n",
    "p_fingerprints = np.asarray(p_fingerprints)[1:]\n",
    "c_fingerprints = np.asarray(c_fingerprints)[1:]\n",
    "print(p_fingerprints.shape)\n",
    "print(p_fingerprints[1:5,-1])\n",
    "\n",
    "p_fingerprints = p_fingerprints.astype(int)\n",
    "c_fingerprints = c_fingerprints.astype(float)\n",
    "(no_examples , ip_dim) = p_fingerprints.shape\n",
    "labels = labels[1:]\n",
    "print(no_examples,ip_dim)\n",
    "print(\"total no of 1s\",np.sum(p_fingerprints))\n",
    "print(\"total no of 0s\",no_examples*ip_dim-np.sum(p_fingerprints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels2 = np.zeros((len(labels),1))\n",
    "for i,l in enumerate(labels):\n",
    "    if l=='Active':\n",
    "        labels2[i] = 1\n",
    "    else:\n",
    "        labels2[i] = 0\n",
    "labels2 = labels2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\n"
     ]
    }
   ],
   "source": [
    "no_active_ele = (sum(labels2))\n",
    "print(no_active_ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47831, 1)\n"
     ]
    }
   ],
   "source": [
    "print labels2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_embedded = TSNE(n_components=2).fit_transform(p_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 6)) \n",
    "# labels2 = labels2.astype(float)\n",
    "# labels2 = labels2.reshape(no_examples,)\n",
    "# plt.scatter(X_embedded[:, 0], X_embedded[:, 1],c = labels2)#map=plt.cm.BrOr)\n",
    "# #plt.colorbar()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 120\n",
    "\n",
    "z_dim = 30\n",
    "comb_dim = ip_dim + z_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Encoder\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,500)\n",
    "        self.l2 = nn.Linear(500,500)\n",
    "        #self.l3 = nn.Linear(500,500)\n",
    "        self.l4 = nn.Linear(500,z_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        #x = F.leaky_relu(self.l3(x))\n",
    "        x = (self.l4(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "### Decoder\n",
    "\n",
    "class decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder,self).__init__()\n",
    "        self.l1 = nn.Linear(z_dim,500)\n",
    "        self.l2 = nn.Linear(500,500)\n",
    "        #self.l3 = nn.Linear(500,500)\n",
    "        self.l4 = nn.Linear(500,ip_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        #x = F.leaky_relu(self.l3(x))\n",
    "        x = F.tanh(self.l4(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "###  Discriminator\n",
    "\n",
    "class disc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(disc,self).__init__()\n",
    "        self.l1 = nn.Linear(z_dim,100)\n",
    "        #self.l2 = nn.Linear(100,100)\n",
    "        self.l3 = nn.Linear(100,100)\n",
    "        self.l4 = nn.Linear(100,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.elu(self.l3(x))\n",
    "        x = F.sigmoid(self.l4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.arange(no_examples)\n",
    "np.random.shuffle(ind)\n",
    "p_fingerprints = p_fingerprints[ind]\n",
    "c_fingerprints = c_fingerprints[ind]\n",
    "labels2 = labels2[ind]\n",
    "labels2 = labels2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_batch(batch_size,validation_iter=0,binary=True,high_pos=False):\n",
    "    \n",
    "    if validation_iter == 0: #no validation\n",
    "        curr_data_size = no_examples\n",
    "        labels_train = labels2\n",
    "        #print labels_train.shape\n",
    "        p_train_data = p_fingerprints\n",
    "    else:\n",
    "        curr_data_size = int(no_examples*0.8)\n",
    "        interval_size = int(no_examples*0.2)\n",
    "        \n",
    "        if(val_iter==1):\n",
    "            s_ind1 = int((validation_iter)*interval_size)\n",
    "            end_ind1 = int((validation_iter+1)*interval_size)\n",
    "            s_ind2 = int((validation_iter + 1) * interval_size)\n",
    "            end_ind2 = int(no_examples)\n",
    "        else:\n",
    "            s_ind1 = 0\n",
    "            end_ind1 = int((validation_iter)*interval_size)\n",
    "            s_ind2 = int((validation_iter + 1) * interval_size)\n",
    "            end_ind2 = int(no_examples)\n",
    "        \n",
    "        #print(\"train_ind \",s_ind1,end_ind1,s_ind2,end_ind2)\n",
    "        indices = range(s_ind1,end_ind1) + range(s_ind2,end_ind2)\n",
    "        c_train_data = c_fingerprints[indices]\n",
    "        p_train_data = p_fingerprints[indices]\n",
    "        labels_train = labels2[indices]\n",
    "    samples = np.random.randint(low=0,high=curr_data_size,size=(batch_size,1))\n",
    "     \n",
    "\n",
    "    if binary == True:\n",
    "        train_batch = p_train_data[samples].reshape(batch_size,ip_dim)\n",
    "        train_batch = train_batch.astype(int)\n",
    "    else:\n",
    "        train_batch = c_fingerprints[samples].reshape(batch_size,ip_dim2)\n",
    "        train_batch = train_batch.astype(float)\n",
    "    \n",
    "    train_batch = torch.cuda.FloatTensor(train_batch)\n",
    "    train_batch = Variable(train_batch,requires_grad=False).cuda()\n",
    "    target = Variable(torch.cuda.LongTensor(labels_train[samples]),requires_grad=False)\n",
    "    target = target.view(batch_size,)\n",
    "    return train_batch,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_data(validation_iter,binary = True):\n",
    "    interval_size = int(no_examples)*0.2\n",
    "    s_ind = int((validation_iter-1)*interval_size)\n",
    "    e_ind = int((validation_iter) * interval_size)\n",
    "    if(binary==True):\n",
    "        train_data = p_fingerprints[s_ind:e_ind]\n",
    "    else:\n",
    "        train_data = c_fingerprints[s_ind:e_ind]\n",
    "    labels_val = labels2[s_ind:e_ind]   \n",
    "    #print(\"val ind \",s_ind,e_ind)\n",
    "    #print train_data.shape, labels_val.shape\n",
    "    return Variable(torch.cuda.FloatTensor(train_data)),labels_val  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = decoder().cuda()\n",
    "E = encoder().cuda()\n",
    "D = disc().cuda()\n",
    "\n",
    "def clear_grad():\n",
    "    G.zero_grad()\n",
    "    E.zero_grad()\n",
    "    D.zero_grad()\n",
    "\n",
    "E_solver = optim.Adam(E.parameters(),lr = 1e-3)\n",
    "G_solver = optim.Adam(G.parameters(),lr = 1e-3)\n",
    "D_solver = optim.Adam(D.parameters(),lr = 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_true_z(label):\n",
    "    \n",
    "    noise = np.random.randn(batch_size,z_dim)\n",
    "    label = label.numpy().reshape(batch_size,1)\n",
    "    #print noise.shape,label.shape\n",
    "    z = 0.5*noise + label*10\n",
    "    z = Variable(torch.FloatTensor(z).cuda())\n",
    "    return z\n",
    "    #z = torch.add(noise,value=1,other=label)\n",
    "    #z = Variable(z.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0450062938035 1.38266718388 0.668599307537\n",
      "0.0419138558209 1.37024331093 0.668599307537\n",
      "0.0451978743076 1.36437916756 0.668599307537\n",
      "0.0363538302481 1.35767543316 0.62461489439\n",
      "0.0387718901038 1.36448991299 0.62461489439\n",
      "0.0360762625933 1.35247552395 0.62461489439\n",
      "0.0360966622829 1.34569656849 0.600272536278\n",
      "0.0375973209739 1.35035014153 0.600272536278\n",
      "0.0375850126147 1.34888899326 0.600272536278\n",
      "0.0357049070299 1.31475114822 0.606083810329\n",
      "0.0359413102269 1.31826806068 0.606083810329\n",
      "0.0394050553441 1.29819655418 0.606083810329\n",
      "0.0353109464049 1.26042532921 0.660216987133\n",
      "0.0373059250414 1.22897422314 0.660216987133\n",
      "0.0354544892907 1.19245171547 0.660216987133\n",
      "0.0367123782635 1.15753567219 0.764692544937\n",
      "0.0358410328627 1.13890206814 0.764692544937\n",
      "0.0333201736212 1.09445416927 0.764692544937\n",
      "0.036911290139 1.06241190434 0.862509906292\n",
      "0.0362692028284 1.07554805279 0.862509906292\n",
      "0.0351646579802 1.05687892437 0.862509906292\n",
      "0.035792928189 0.996283471584 0.909785270691\n",
      "0.0334416441619 1.05420053005 0.909785270691\n",
      "0.0331160202622 1.02209532261 0.909785270691\n",
      "0.0349920988083 1.00577378273 0.914426088333\n",
      "0.0341901853681 1.02668702602 0.914426088333\n",
      "0.0342491157353 1.02586495876 0.914426088333\n",
      "0.0365698561072 0.995100796223 0.896790623665\n",
      "0.0338442474604 1.08559715748 0.896790623665\n",
      "0.0349698141217 1.08808493614 0.896790623665\n",
      "0.0336704328656 1.06270134449 0.790696799755\n",
      "0.0379339717329 1.23082411289 0.790696799755\n",
      "0.0352019965649 1.23375689983 0.790696799755\n",
      "0.0360333174467 1.22070968151 0.652928590775\n",
      "0.0344892181456 1.38642954826 0.652928590775\n",
      "0.0346186123788 1.34930884838 0.652928590775\n",
      "0.0334303230047 1.27091348171 0.613705694675\n",
      "0.0363954789937 1.53894150257 0.613705694675\n",
      "0.0346629433334 1.45879411697 0.613705694675\n",
      "0.0345530770719 1.35515260696 0.638552486897\n",
      "0.0357447937131 1.49529135227 0.638552486897\n",
      "0.0374506227672 1.44940328598 0.638552486897\n",
      "0.0342368967831 1.28862631321 0.778998911381\n",
      "0.0346373319626 1.48895955086 0.778998911381\n",
      "0.0332067944109 1.31672203541 0.778998911381\n",
      "0.0332354977727 1.14960241318 0.963626027107\n",
      "0.0383502468467 1.37014245987 0.963626027107\n",
      "0.0363323427737 1.33664810658 0.963626027107\n",
      "0.0360516682267 1.15871608257 0.962020933628\n",
      "0.035217218101 1.57506716251 0.962020933628\n",
      "0.0355286225677 1.66453003883 0.962020933628\n",
      "0.0335706546903 1.53231287003 0.656226336956\n",
      "0.0363312251866 2.17011904716 0.656226336956\n",
      "0.0322040952742 2.06588625908 0.656226336956\n",
      "0.0356257334352 2.03200292587 0.437162548304\n",
      "0.0401899442077 2.7688024044 0.437162548304\n",
      "0.0385873764753 2.53806376457 0.437162548304\n",
      "0.0375604778528 2.4400396347 0.353858828545\n",
      "0.0352224558592 2.83809876442 0.353858828545\n",
      "0.033449575305 2.60813093185 0.353858828545\n",
      "0.0365801751614 2.50944638252 0.347070723772\n",
      "0.0361417047679 3.08231949806 0.347070723772\n",
      "0.037072584033 2.85219502449 0.347070723772\n",
      "0.0340035520494 2.43930101395 0.407807201147\n",
      "0.0391800813377 2.8511865139 0.407807201147\n",
      "0.0381735451519 2.72267746925 0.407807201147\n",
      "0.035094037652 2.17191171646 0.636829912663\n",
      "0.036096367985 2.44091033936 0.636829912663\n",
      "0.0380420312285 2.17882680893 0.636829912663\n",
      "0.037046931684 1.9232827425 0.938473820686\n",
      "0.0387269854546 2.22319173813 0.938473820686\n",
      "0.0375910922885 2.15730118752 0.938473820686\n",
      "0.0380256660283 1.84438514709 1.07979011536\n",
      "0.0362830199301 2.21146821976 1.07979011536\n",
      "0.0396257415414 2.13701868057 1.07979011536\n",
      "0.0368646420538 1.8713310957 1.34312784672\n",
      "0.0380583666265 2.17192077637 1.34312784672\n",
      "0.0370559431612 1.95988380909 1.34312784672\n",
      "0.0359379462898 1.6302498579 1.96864318848\n",
      "0.0341081805527 1.74464988708 1.96864318848\n",
      "0.0371401384473 1.72028529644 1.96864318848\n",
      "0.034545879811 1.59547531605 2.54658651352\n",
      "0.0376016497612 1.55811059475 2.54658651352\n",
      "0.0369785577059 1.5801807642 2.54658651352\n",
      "0.0374565422535 1.42954492569 2.85389685631\n",
      "0.0335064940155 1.6239221096 2.85389685631\n",
      "0.0384017117321 1.51005899906 2.85389685631\n",
      "0.0354429967701 1.49011933804 2.20413184166\n",
      "0.0337182469666 1.56504571438 2.20413184166\n",
      "0.0378998555243 1.60580670834 2.20413184166\n",
      "0.0349819622934 1.49377679825 1.85252785683\n",
      "0.0357114002109 1.68689239025 1.85252785683\n",
      "0.0403261296451 1.45927155018 1.85252785683\n",
      "0.0356361009181 1.57454168797 1.79050266743\n",
      "0.0358065962791 1.64471030235 1.79050266743\n",
      "0.0321426615119 1.51034903526 1.79050266743\n",
      "0.0377085022628 1.43738055229 1.61453223228\n",
      "0.0375146232545 1.50805449486 1.61453223228\n",
      "0.0349113345146 1.54169762135 1.61453223228\n",
      "0.0353786833584 1.50280976295 1.38477790356\n",
      "0.0332836396992 1.52270615101 1.38477790356\n",
      "0.0357890240848 1.55992496014 1.38477790356\n",
      "0.0352968722582 1.46651780605 1.35534918308\n",
      "0.0338736958802 1.61312782764 1.35534918308\n",
      "0.0343661345541 1.41152083874 1.35534918308\n",
      "0.0355707220733 1.41563212872 1.45795106888\n",
      "0.032988589257 1.40087497234 1.45795106888\n",
      "0.038051802665 1.39243614674 1.45795106888\n",
      "0.0326087623835 1.36207163334 1.40167403221\n",
      "0.0333350300789 1.41109275818 1.40167403221\n",
      "0.0367877520621 1.37861824036 1.40167403221\n",
      "0.0340453162789 1.38184893131 1.33759605885\n",
      "0.0390885993838 1.33831191063 1.33759605885\n",
      "0.0323912836611 1.37061524391 1.33759605885\n",
      "0.0361418090761 1.38213205338 1.23638856411\n",
      "0.0368636101484 1.38507783413 1.23638856411\n",
      "0.0387787520885 1.4364221096 1.23638856411\n",
      "0.0362892597914 1.4271222353 1.13963568211\n",
      "0.0354493558407 1.39935922623 1.13963568211\n",
      "0.0380420647562 1.42208242416 1.13963568211\n",
      "0.0387360155582 1.37217736244 1.05255377293\n",
      "0.0413936860859 1.38834428787 1.05255377293\n",
      "0.0374942496419 1.39550626278 1.05255377293\n",
      "0.0373346060514 1.42406404018 0.983888208866\n",
      "0.0400478430092 1.45322060585 0.983888208866\n",
      "0.0346625372767 1.44627153873 0.983888208866\n",
      "0.038806322962 1.42388868332 0.870707809925\n",
      "0.0396996848285 1.44524168968 0.870707809925\n",
      "0.0363780297339 1.4576934576 0.870707809925\n",
      "0.0380848273635 1.44552445412 0.812584638596\n",
      "0.0384410694242 1.50170910358 0.812584638596\n",
      "0.0355719923973 1.49286413193 0.812584638596\n",
      "0.0372904092073 1.52940785885 0.727548718452\n",
      "0.0411991626024 1.53694188595 0.727548718452\n",
      "0.0405197739601 1.55881249905 0.727548718452\n",
      "0.0360155329108 1.52406609058 0.666210532188\n",
      "0.0371785201132 1.54722642899 0.666210532188\n",
      "0.0407803356647 1.55685317516 0.666210532188\n",
      "0.0391379669309 1.58176290989 0.614486455917\n",
      "0.0359767526388 1.55232775211 0.614486455917\n",
      "0.0372392386198 1.56192457676 0.614486455917\n",
      "0.0341197513044 1.54853117466 0.590160250664\n",
      "0.0361559130251 1.56961882114 0.590160250664\n",
      "0.0371355228126 1.56635546684 0.590160250664\n",
      "0.0363794602454 1.56609380245 0.557759702206\n",
      "0.0400370247662 1.59757912159 0.557759702206\n",
      "0.0367676243186 1.61750137806 0.557759702206\n",
      "0.0367874018848 1.58333003521 0.53151267767\n",
      "0.0385149270296 1.59206068516 0.53151267767\n",
      "0.0370238870382 1.56768584251 0.53151267767\n",
      "0.0371937826276 1.5804194212 0.510903835297\n",
      "0.0386534035206 1.58379101753 0.510903835297\n",
      "0.0350572168827 1.58547616005 0.510903835297\n",
      "0.0386210940778 1.5806350708 0.497455060482\n",
      "0.035912040621 1.59105718136 0.497455060482\n",
      "0.036672860384 1.57798933983 0.497455060482\n",
      "0.0345407426357 1.56972801685 0.483192890882\n",
      "0.0343942157924 1.58231985569 0.483192890882\n",
      "0.0370521396399 1.56668901443 0.483192890882\n",
      "0.0366877540946 1.58778822422 0.473425716162\n",
      "0.032867629081 1.55857121944 0.473425716162\n",
      "0.0376454666257 1.55972087383 0.473425716162\n",
      "0.0346993766725 1.55341553688 0.472719699144\n",
      "0.0364171676338 1.56089651585 0.472719699144\n",
      "0.0335228256881 1.53515291214 0.472719699144\n",
      "0.0376103334129 1.53287827969 0.472033530474\n",
      "0.0359583720565 1.53695380688 0.472033530474\n",
      "0.0361304357648 1.5215638876 0.472033530474\n",
      "0.0360047519207 1.53283858299 0.475088477135\n",
      "0.0343142673373 1.52509915829 0.475088477135\n",
      "0.0357091091573 1.51295888424 0.475088477135\n",
      "0.0355594083667 1.51418220997 0.476595491171\n",
      "0.031104516238 1.50254881382 0.476595491171\n",
      "0.0337116643786 1.50274050236 0.476595491171\n",
      "0.0371507033706 1.50637865067 0.478326678276\n",
      "0.0328611657023 1.4942637682 0.478326678276\n",
      "0.0377115607262 1.49481379986 0.478326678276\n",
      "0.0345738753676 1.48452603817 0.485906392336\n",
      "0.0351128950715 1.48544609547 0.485906392336\n",
      "0.0357304699719 1.48461484909 0.485906392336\n",
      "0.038322031498 1.48360395432 0.485337883234\n",
      "0.030513105914 1.47302508354 0.485337883234\n",
      "0.0317312031984 1.46905648708 0.485337883234\n",
      "0.0311381351203 1.46804404259 0.500876069069\n",
      "0.0348868146539 1.45723807812 0.500876069069\n",
      "0.0327821224928 1.4639095068 0.500876069069\n",
      "0.0337063446641 1.45845687389 0.50301605463\n",
      "0.0353176593781 1.4534034729 0.50301605463\n",
      "0.0351424589753 1.45399487019 0.50301605463\n",
      "0.03368569538 1.45753335953 0.510273039341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0332493409514 1.44489681721 0.510273039341\n",
      "0.034836281091 1.45512509346 0.510273039341\n",
      "0.0368060953915 1.44363832474 0.51666021347\n",
      "0.0349570140243 1.45429396629 0.51666021347\n",
      "0.0334687530994 1.44104301929 0.51666021347\n",
      "0.0339143499732 1.43041718006 0.537091910839\n",
      "0.038024995476 1.45846557617 0.537091910839\n",
      "0.0344054624438 1.4367133379 0.537091910839\n",
      "0.0349417217076 1.42291939259 0.553725481033\n",
      "0.0344651862979 1.43855941296 0.553725481033\n",
      "0.0380040071905 1.44039189816 0.553725481033\n",
      "0.0360239706933 1.41010177135 0.589811265469\n",
      "0.0368385948241 1.41032791138 0.589811265469\n",
      "0.0345869809389 1.3705650568 0.589811265469\n",
      "0.0361988767982 1.35318005085 0.671022057533\n",
      "0.0347646437585 1.34908890724 0.671022057533\n",
      "0.0367395654321 1.30272161961 0.671022057533\n",
      "0.033504806459 1.27600669861 0.789512634277\n",
      "0.032869040966 1.26040029526 0.789512634277\n",
      "0.0373009070754 1.22974145412 0.789512634277\n",
      "0.0356831625104 1.21269202232 0.948707997799\n",
      "0.035286474973 1.19316327572 0.948707997799\n",
      "0.0319055989385 1.20089137554 0.948707997799\n",
      "0.0338212177157 1.14028584957 1.05204546452\n",
      "0.0353354848921 1.15604507923 1.05204546452\n",
      "0.0353956930339 1.1746224165 1.05204546452\n",
      "0.0321480929852 1.15830075741 1.0425709486\n",
      "0.0360553339124 1.17181062698 1.0425709486\n",
      "0.0346893146634 1.18397152424 1.0425709486\n",
      "0.033877234906 1.18254029751 1.00678145885\n",
      "0.0318521820009 1.22413408756 1.00678145885\n",
      "0.0344889834523 1.21942913532 1.00678145885\n",
      "0.0347967818379 1.26131165028 0.941671669483\n",
      "0.0359175726771 1.2498267889 0.941671669483\n",
      "0.0346342213452 1.28260695934 0.941671669483\n",
      "0.0361276902258 1.30218231678 0.888199806213\n",
      "0.0345292128623 1.30638301373 0.888199806213\n",
      "0.0344525687397 1.33339083195 0.888199806213\n",
      "0.0363779179752 1.35049247742 0.805828750134\n",
      "0.0343231707811 1.38179039955 0.805828750134\n",
      "0.0335454419255 1.38959383965 0.805828750134\n",
      "0.0338031090796 1.48942172527 0.705590605736\n",
      "0.0335684902966 1.45095050335 0.705590605736\n",
      "0.0351606793702 1.45465135574 0.705590605736\n",
      "0.0321008376777 1.43865799904 0.642637491226\n",
      "0.0357581786811 1.49716866016 0.642637491226\n",
      "0.0335487984121 1.48293411732 0.642637491226\n",
      "0.03568469733 1.50818943977 0.588452935219\n",
      "0.0307859145105 1.53885281086 0.588452935219\n",
      "0.0331446453929 1.53839337826 0.588452935219\n",
      "0.0329387336969 1.50574755669 0.54299390316\n",
      "0.0348887071013 1.56105923653 0.54299390316\n",
      "0.0321939177811 1.57748484612 0.54299390316\n",
      "0.036676902324 1.59252786636 0.504386603832\n",
      "0.035777464509 1.60538697243 0.504386603832\n",
      "0.0332621335983 1.62199759483 0.504386603832\n",
      "0.032723903656 1.61099302769 0.477687060833\n",
      "0.0339112170041 1.63673102856 0.477687060833\n",
      "0.0361813269556 1.65118217468 0.477687060833\n",
      "0.033568713814 1.62446582317 0.458319664001\n",
      "0.037075906992 1.68573224545 0.458319664001\n",
      "0.0352337583899 1.67080795765 0.458319664001\n",
      "0.0296470299363 1.65860593319 0.452380120754\n",
      "0.0341123975813 1.68063080311 0.452380120754\n",
      "0.0347138233483 1.66091322899 0.452380120754\n",
      "0.0367731489241 1.66935026646 0.437429010868\n",
      "0.0356616042554 1.70803415775 0.437429010868\n",
      "0.0341221541166 1.69694566727 0.437429010868\n",
      "0.0375560224056 1.68775486946 0.436318010092\n",
      "0.0331491306424 1.70398628712 0.436318010092\n",
      "0.0372012332082 1.72652840614 0.436318010092\n",
      "0.0333216562867 1.6802097559 0.446146309376\n",
      "0.0341852195561 1.72272181511 0.446146309376\n",
      "0.0353407487273 1.7259465456 0.446146309376\n",
      "0.0352375507355 1.69737446308 0.446564406157\n",
      "0.0383583568037 1.74831712246 0.446564406157\n",
      "0.0354419946671 1.72747468948 0.446564406157\n",
      "0.0317038111389 1.67985999584 0.489513456821\n",
      "0.0342120230198 1.70281934738 0.489513456821\n",
      "0.0362581089139 1.68656003475 0.489513456821\n",
      "0.0366914384067 1.64344966412 0.541805446148\n",
      "0.0311191473156 1.62911486626 0.541805446148\n",
      "0.0357656106353 1.59650301933 0.541805446148\n",
      "0.0335197523236 1.54812324047 0.659096598625\n",
      "0.0330508463085 1.53061711788 0.659096598625\n",
      "0.0369640290737 1.4791572094 0.659096598625\n",
      "0.035841871053 1.42456710339 0.844115614891\n",
      "0.0340053886175 1.43487966061 0.844115614891\n",
      "0.0365981310606 1.3862156868 0.844115614891\n",
      "0.0361087024212 1.35342681408 1.04022812843\n",
      "0.0316596031189 1.35416340828 1.04022812843\n",
      "0.0326814763248 1.33406460285 1.04022812843\n",
      "0.0346739143133 1.29572975636 1.17088472843\n",
      "0.0336997285485 1.28863489628 1.17088472843\n",
      "0.035342939198 1.28296065331 1.17088472843\n",
      "0.0327528975904 1.32249569893 1.16165220737\n",
      "0.0357369892299 1.29720711708 1.16165220737\n",
      "0.0326582230628 1.32669007778 1.16165220737\n",
      "0.0365817286074 1.3053239584 1.13081407547\n",
      "0.0341871157289 1.37637972832 1.13081407547\n",
      "0.032456971705 1.39439940453 1.13081407547\n",
      "0.0345681905746 1.39369893074 0.966455519199\n",
      "0.0340781882405 1.41996693611 0.966455519199\n",
      "0.0334201827645 1.4582413435 0.966455519199\n",
      "0.0336170569062 1.45347845554 0.832615971565\n",
      "0.0346171185374 1.49716496468 0.832615971565\n",
      "0.034456718713 1.49721395969 0.832615971565\n",
      "0.0352814272046 1.53388917446 0.75767326355\n",
      "0.0332179740071 1.5135705471 0.75767326355\n",
      "0.0391225144267 1.55105257034 0.75767326355\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "for ep in range(epochs):\n",
    "    if(1==1):\n",
    "    #for idx ,(x,label) in enumerate(train_loader):\n",
    "        x,label = get_train_batch(batch_size,validation_iter=0)\n",
    "        label = label.type(torch.FloatTensor).data\n",
    "        z = get_true_z(label)\n",
    "        zhat = E(x)\n",
    "        xhat = G(zhat)\n",
    "        \n",
    "        gen_loss = nn.MSELoss()(xhat,x)\n",
    "        gen_loss.backward(retain_graph=True)\n",
    "        G_solver.step()\n",
    "        E_solver.step()\n",
    "        clear_grad()\n",
    "        \n",
    "        add_small = 1e-10\n",
    "        d_true = D(z)\n",
    "        d_false = D(zhat)\n",
    "        disc_loss = -(torch.mean(torch.log(d_true + add_small) + torch.log((1-d_false) + add_small)))\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        D_solver.step()\n",
    "        clear_grad()\n",
    "        \n",
    "        if(ep%3==0):\n",
    "            zhat = E(x)\n",
    "            d_false = D(zhat)\n",
    "            encoder_loss = -torch.mean(torch.log(d_false + add_small))\n",
    "            encoder_loss.backward()\n",
    "            E_solver.step()\n",
    "            clear_grad()\n",
    "            \n",
    "#     if(ep%10==0):\n",
    "#         xcheck,labels = get_train_batch(batch_size=1000)\n",
    "#         labels_sc = labels.cpu().data.numpy()\n",
    "#         #xcheck = Variable(xcheck.view(1000,28*28).cuda())\n",
    "#         zhat = E(xcheck)\n",
    "#         z_mu = zhat.cpu().data.numpy()\n",
    "#         plt.figure(figsize=(8, 6)) \n",
    "#         #colors = cm.rainbow(np.linspace(0, 1, 10))\n",
    "#         plt.scatter(z_mu[:, 0], z_mu[:, 1],c = labels_sc,cmap=plt.cm.autumn)\n",
    "#         plt.colorbar()\n",
    "#         plt.grid()\n",
    "#         plt.show()         \n",
    "        \n",
    "    print gen_loss.data[0], disc_loss.data[0], encoder_loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xchck = Variable(torch.cuda.FloatTensor(p_fingerprints))\n",
    "zchk = E(xchck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zchk = zchk.data.cpu().numpy()\n",
    "X_embedded = TSNE(n_components=2).fit_transform(zchk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6)) \n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1],c = labels2,cmap=plt.cm.spring)\n",
    "plt.colorbar()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using a random forest classifier on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0: 1, 1: 70},\n",
       "            criterion='gini', max_depth=2, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "lables2 = labels2.reshape(labels2.shape[0],)\n",
    "clf = RandomForestClassifier(n_estimators = 20,max_depth=2, random_state=0,class_weight={0:1,1:70})\n",
    "clf.fit(zchk,labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp', array([2849,  526,   17,   31]))\n"
     ]
    }
   ],
   "source": [
    "test_op = clf.predict(zchk)\n",
    "cm1 = metrics.confusion_matrix(labels2,test_op)\n",
    "print('tn, fp, fn, tp',cm1.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/bioassay-datasets/'\n",
    "p_fingerprints_test = []\n",
    "c_fp = []\n",
    "labels = []\n",
    "with open(path+fname+'red_test.csv') as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        p_fingerprints_test.append(row[:bf])\n",
    "        c_fp.append(row[bf:-1])\n",
    "        labels.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(856, 30)\n"
     ]
    }
   ],
   "source": [
    "p_fingerprints_test = np.asarray(p_fingerprints_test)[1:]\n",
    "p_fingerprints_test = p_fingerprints_test.astype(int)\n",
    "\n",
    "## get z_test ##\n",
    "p_test = Variable(torch.cuda.FloatTensor(p_fingerprints_test))\n",
    "z_test = E(p_test)\n",
    "z_test = z_test.cpu().data.numpy()\n",
    "print z_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(856, 112)\n",
      "('total no of 1s', 6305)\n",
      "('total no of 0s', 89567)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "c_fp = np.asarray(c_fp)[1:]\n",
    "c_fp = c_fp.astype(float)\n",
    "\n",
    "c_fp = (c_fp - np.mean(c_fp,axis=0))/np.std(c_fp,axis=0)\n",
    "\n",
    "fingerprints_test = np.concatenate((p_fingerprints_test,c_fp),axis=1)\n",
    "#p2_fingerprints = np.ones(p_fingerprints.shape)\n",
    "(no_examples , ip_dim) = p_fingerprints_test.shape\n",
    "labels = labels[1:]\n",
    "print(no_examples,ip_dim)\n",
    "print(\"total no of 1s\",np.sum(p_fingerprints_test))\n",
    "print(\"total no of 0s\",no_examples*ip_dim-np.sum(p_fingerprints_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels2_test = np.zeros((len(labels),1))\n",
    "for i,l in enumerate(labels):\n",
    "    if l=='Active':\n",
    "        labels2_test[i] = 1\n",
    "    else:\n",
    "        labels2_test[i] = 0\n",
    "labels2_test = np.asarray(labels2_test,dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp', array([719, 125,   4,   8]))\n"
     ]
    }
   ],
   "source": [
    "test_op = clf.predict(z_test)\n",
    "cm1 = metrics.confusion_matrix(labels2_test,test_op)\n",
    "print('tn, fp, fn, tp',cm1.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
