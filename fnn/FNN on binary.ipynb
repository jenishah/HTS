{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics as metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('screen_info.txt','rb') as fl:\n",
    "    t = pickle.load(fl)\n",
    "fnames = t[0]\n",
    "totf = t[1]\n",
    "binf = t[2]\n",
    "runfile = 1\n",
    "fname = fnames[runfile]\n",
    "bf = binf[runfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/bioassay-datasets/'\n",
    "p_fingerprints = []\n",
    "c_fingerprints = []\n",
    "labels = []\n",
    "with open(path+fname+'red_train.csv') as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        p_fingerprints.append(row[:bf])\n",
    "        c_fingerprints.append(row[bf:-1])\n",
    "        labels.append(row[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using 10 fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47831, 122)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(p_fingerprints)[1:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47831, 122)\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "p_fingerprints = np.asarray(p_fingerprints)[1:]\n",
    "p_fingerprints = p_fingerprints.astype(int)\n",
    "c_fingerprints = np.asarray(c_fingerprints)[1:]\n",
    "c_fingerprints = c_fingerprints.astype(float)\n",
    "#p2_fingerprints = np.ones(p_fingerprints.shape)\n",
    "(no_examples , ip_dim) = p_fingerprints.shape\n",
    "ip_dim2 = c_fingerprints.shape[1]\n",
    "labels = labels[1:]\n",
    "print(no_examples,ip_dim)\n",
    "print(ip_dim2)\n",
    "#p_fingerprints[(p_fingerprints==0)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels2 = np.zeros((len(labels),1))\n",
    "for i,l in enumerate(labels):\n",
    "    if l=='Active':\n",
    "        labels2[i] = 1\n",
    "    else:\n",
    "        labels2[i] = 0\n",
    "labels2 = labels2.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Randomly permute the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.arange(no_examples)\n",
    "np.random.shuffle(ind)\n",
    "p_fingerprints = p_fingerprints[ind]\n",
    "c_fingerprints = c_fingerprints[ind]\n",
    "labels2 = labels2[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\n"
     ]
    }
   ],
   "source": [
    "no_active_ele = (sum(labels2))\n",
    "print(no_active_ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mlp,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,1000)\n",
    "        self.l2 = nn.Linear(1000,500)\n",
    "        self.l3 = nn.Linear(500,500)\n",
    "        self.l4 = nn.Linear(500,200)\n",
    "        self.l5 = nn.Linear(200,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = F.leaky_relu(self.l3(x))\n",
    "        x = F.leaky_relu(self.l4(x))\n",
    "        x = (self.l5(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#criterion = nn.BCELoss()\n",
    "\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_batch(batch_size,validation_iter=0,binary=True):\n",
    "    \n",
    "    if validation_iter == 0: #no validation\n",
    "        curr_data_size = no_examples\n",
    "        labels_train = labels2\n",
    "    else:\n",
    "        curr_data_size = int(no_examples*0.8)\n",
    "        interval_size = int(no_examples*0.2)\n",
    "        \n",
    "        if(val_iter==1):\n",
    "            s_ind1 = int((validation_iter)*interval_size)\n",
    "            end_ind1 = int((validation_iter+1)*interval_size)\n",
    "            s_ind2 = int((validation_iter + 1) * interval_size)\n",
    "            end_ind2 = int(no_examples)\n",
    "        else:\n",
    "            s_ind1 = 0\n",
    "            end_ind1 = int((validation_iter)*interval_size)\n",
    "            s_ind2 = int((validation_iter + 1) * interval_size)\n",
    "            end_ind2 = int(no_examples)\n",
    "        \n",
    "        indices = range(s_ind1,end_ind1) + range(s_ind2,end_ind2)\n",
    "        c_train_data = c_fingerprints[indices]\n",
    "        p_train_data = p_fingerprints[indices]\n",
    "        labels_train = labels2[indices]\n",
    "                               \n",
    "    samples = np.random.randint(low=0,high=curr_data_size,size=(batch_size,1))\n",
    "    if binary == True:\n",
    "        train_batch = p_fingerprints[samples].reshape(batch_size,ip_dim)\n",
    "        train_batch = train_batch.astype(int)\n",
    "    else:\n",
    "        train_batch = c_fingerprints[samples].reshape(batch_size,ip_dim2)\n",
    "        train_batch = train_batch.astype(float)\n",
    "    \n",
    "    train_batch = torch.cuda.FloatTensor(train_batch)\n",
    "    train_batch = Variable(train_batch,requires_grad=False).cuda()\n",
    "    target = Variable(torch.cuda.LongTensor(labels_train[samples]),requires_grad=False)\n",
    "    target = target.view(batch_size,)\n",
    "    return train_batch,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_data(validation_iter):\n",
    "    interval_size = int(no_examples)*0.2\n",
    "    s_ind = int((validation_iter-1)*interval_size)\n",
    "    e_ind = int((validation_iter) * interval_size)\n",
    "    p_train_data = p_fingerprints[s_ind:e_ind]\n",
    "    labels_val = labels2[s_ind:e_ind]   \n",
    "    return Variable(torch.cuda.FloatTensor(p_train_data)),labels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(\"good_w_binary.txt\",'rb') as f:\n",
    "#     weights_array = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('val iter: ', 1)\n",
      "('tn, fp, fn, tp: ', array([9525,    0,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9524,    1,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9525,    0,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9525,    0,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9524,    1,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9524,    1,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9524,    1,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9524,    1,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9525,    0,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9523,    2,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9523,    2,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9521,    4,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9503,   22,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9516,    9,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9525,    0,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9503,   22,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9510,   15,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9512,   13,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9514,   11,   41,    0]))\n",
      "('tn, fp, fn, tp: ', array([9524,    1,   41,    0]))\n",
      "('val iter: ', 2)\n",
      "('tn, fp, fn, tp: ', array([9538,    0,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9538,    0,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9537,    1,   27,    1]))\n",
      "('tn, fp, fn, tp: ', array([9538,    0,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9537,    1,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9536,    2,   27,    1]))\n",
      "('tn, fp, fn, tp: ', array([9523,   15,   23,    5]))\n",
      "('tn, fp, fn, tp: ', array([9529,    9,   25,    3]))\n",
      "('tn, fp, fn, tp: ', array([9527,   11,   26,    2]))\n",
      "('tn, fp, fn, tp: ', array([9535,    3,   26,    2]))\n",
      "('tn, fp, fn, tp: ', array([9536,    2,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9526,   12,   25,    3]))\n",
      "('tn, fp, fn, tp: ', array([9536,    2,   27,    1]))\n",
      "('tn, fp, fn, tp: ', array([9527,   11,   25,    3]))\n",
      "('tn, fp, fn, tp: ', array([9525,   13,   25,    3]))\n",
      "('tn, fp, fn, tp: ', array([9527,   11,   25,    3]))\n",
      "('tn, fp, fn, tp: ', array([9529,    9,   24,    4]))\n",
      "('tn, fp, fn, tp: ', array([9532,    6,   25,    3]))\n",
      "('tn, fp, fn, tp: ', array([9535,    3,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9526,   12,   24,    4]))\n",
      "('val iter: ', 3)\n",
      "('tn, fp, fn, tp: ', array([9528,    0,   38,    0]))\n",
      "('tn, fp, fn, tp: ', array([9528,    0,   38,    0]))\n",
      "('tn, fp, fn, tp: ', array([9528,    0,   38,    0]))\n",
      "('tn, fp, fn, tp: ', array([9526,    2,   33,    5]))\n",
      "('tn, fp, fn, tp: ', array([9528,    0,   38,    0]))\n",
      "('tn, fp, fn, tp: ', array([9525,    3,   34,    4]))\n",
      "('tn, fp, fn, tp: ', array([9528,    0,   38,    0]))\n",
      "('tn, fp, fn, tp: ', array([9526,    2,   37,    1]))\n",
      "('tn, fp, fn, tp: ', array([9524,    4,   36,    2]))\n",
      "('tn, fp, fn, tp: ', array([9524,    4,   35,    3]))\n",
      "('tn, fp, fn, tp: ', array([9513,   15,   34,    4]))\n",
      "('tn, fp, fn, tp: ', array([9523,    5,   35,    3]))\n",
      "('tn, fp, fn, tp: ', array([9521,    7,   35,    3]))\n",
      "('tn, fp, fn, tp: ', array([9522,    6,   34,    4]))\n",
      "('tn, fp, fn, tp: ', array([9519,    9,   34,    4]))\n",
      "('tn, fp, fn, tp: ', array([9502,   26,   35,    3]))\n",
      "('tn, fp, fn, tp: ', array([9526,    2,   38,    0]))\n",
      "('tn, fp, fn, tp: ', array([9518,   10,   34,    4]))\n",
      "('tn, fp, fn, tp: ', array([9508,   20,   36,    2]))\n",
      "('tn, fp, fn, tp: ', array([9527,    1,   37,    1]))\n",
      "('val iter: ', 4)\n",
      "('tn, fp, fn, tp: ', array([9531,    0,   35,    0]))\n",
      "('tn, fp, fn, tp: ', array([9531,    0,   35,    0]))\n",
      "('tn, fp, fn, tp: ', array([9529,    2,   33,    2]))\n",
      "('tn, fp, fn, tp: ', array([9529,    2,   34,    1]))\n",
      "('tn, fp, fn, tp: ', array([9528,    3,   34,    1]))\n",
      "('tn, fp, fn, tp: ', array([9526,    5,   33,    2]))\n",
      "('tn, fp, fn, tp: ', array([9526,    5,   34,    1]))\n",
      "('tn, fp, fn, tp: ', array([9529,    2,   34,    1]))\n",
      "('tn, fp, fn, tp: ', array([9526,    5,   32,    3]))\n",
      "('tn, fp, fn, tp: ', array([9527,    4,   34,    1]))\n",
      "('tn, fp, fn, tp: ', array([9527,    4,   33,    2]))\n",
      "('tn, fp, fn, tp: ', array([9520,   11,   33,    2]))\n",
      "('tn, fp, fn, tp: ', array([9522,    9,   34,    1]))\n",
      "('tn, fp, fn, tp: ', array([9523,    8,   33,    2]))\n",
      "('tn, fp, fn, tp: ', array([9507,   24,   32,    3]))\n",
      "('tn, fp, fn, tp: ', array([9481,   50,   27,    8]))\n",
      "('tn, fp, fn, tp: ', array([9509,   22,   32,    3]))\n",
      "('tn, fp, fn, tp: ', array([9506,   25,   30,    5]))\n",
      "('tn, fp, fn, tp: ', array([9492,   39,   29,    6]))\n",
      "('tn, fp, fn, tp: ', array([9500,   31,   29,    6]))\n",
      "('val iter: ', 5)\n",
      "('tn, fp, fn, tp: ', array([9539,    0,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9539,    0,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9532,    7,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9534,    5,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9539,    0,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9533,    6,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9538,    1,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9517,   22,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9521,   18,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9515,   24,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9526,   13,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9530,    9,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9524,   15,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9517,   22,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9508,   31,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9512,   27,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9520,   19,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9510,   29,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9505,   34,   28,    0]))\n",
      "('tn, fp, fn, tp: ', array([9529,   10,   28,    0]))\n"
     ]
    }
   ],
   "source": [
    "min_fn = 15\n",
    "max_fp = 60\n",
    "cm_list = []\n",
    "get_model  = 1\n",
    "for val_iter in range(1,6):\n",
    "    print(\"val iter: \",val_iter)\n",
    "    \n",
    "   \n",
    "    #weights_array = [5]\n",
    "    weights_array = np.linspace(5,25,20)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp = mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(3000):\n",
    "            train_batch,target = get_train_batch(batch_size,validation_iter = val_iter)\n",
    "            model_op = mymlp(train_batch)\n",
    "            #print(model_op.type)\n",
    "            #print(target.type)\n",
    "            loss = criterion(model_op,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    #     if(ep%30==29):\n",
    "    #         print(loss.data[0])\n",
    "\n",
    "        ## After training check on cross validation data\n",
    "        val_data,labels_val = get_val_data(val_iter)\n",
    "        train_op = mymlp(val_data)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "        #tmp_labels = tmp_labels.data.cpu().numpy()\n",
    "        #print(sum(tmp_labels))\n",
    "        cf = metrics.confusion_matrix(labels_val,pred_labels).ravel()\n",
    "        #print(val_iter,w)\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        wcf = [val_iter] + [w] + [cf]\n",
    "        if(fn < 10):\n",
    "            cm_list.append(wcf)\n",
    "            if(fn==0):\n",
    "                if(fp <= max_fp+2):\n",
    "                    max_fp = fp\n",
    "                    model_path = os.getcwd()+'/b_model_lrelu_'+fname + '_' + str(get_model)\n",
    "                    torch.save(mymlp.state_dict(),model_path)\n",
    "                    print(\"saving model on val: \",val_iter,\" and weight: \",w)\n",
    "                    if(get_model<4):\n",
    "                        get_model = get_model + 1\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lsit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(\"selected_c_cm.txt\",'wb') as fp:\n",
    "#     pickle.dump(cm_lsit,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"test3.txt\",'rb') as fp:\n",
    "#     tmp_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_eg = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tmpfun(y):\n",
    "    z = n_eg*3\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 20\n",
    "tmpfun(3)\n",
    "print(n_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
