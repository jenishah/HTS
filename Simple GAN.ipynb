{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "import random\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),  transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_set = dset.MNIST('/home/daiict/Desktop/udit/C-GAN./data' ,train=True, download= True,\n",
    "                       transform = transform)\n",
    "test_set = dset.MNIST('/home/daiict/Desktop/udit/C-GAN./data' ,train=False, download=True,\n",
    "                       transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625 105\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,shuffle=True)\n",
    "print len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip_dim = 28*28\n",
    "z_dim = 10\n",
    "comb_dim = ip_dim + z_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,500)\n",
    "        self.l2 = nn.Linear(500,500)\n",
    "        self.l3 = nn.Linear(500,z_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = (self.l3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder,self).__init__()\n",
    "        self.l1 = nn.Linear(z_dim,800)\n",
    "        self.l2 = nn.Linear(800,500)\n",
    "        self.l3 = nn.Linear(500,500)\n",
    "        self.l4 = nn.Linear(500,500)\n",
    "        self.l5 = nn.Linear(500,ip_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = F.leaky_relu(self.l3(x))\n",
    "        x = F.leaky_relu(self.l4(x))\n",
    "        x = F.tanh(self.l5(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class disc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(disc,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,100)\n",
    "        #self.l2 = nn.Linear(100,100)\n",
    "        self.l3 = nn.Linear(100,100)\n",
    "        self.l4 = nn.Linear(50,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        #x = F.leaky_relu(self.l2(x))\n",
    "        x = F.sigmoid(self.l3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = decoder().cuda()\n",
    "E = encoder().cuda()\n",
    "D = disc().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_grad():\n",
    "    G.zero_grad()\n",
    "    #E.zero_grad()\n",
    "    D.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_solver = optim.Adam(E.parameters(),lr = 1e-3)\n",
    "G_solver = optim.Adam(G.parameters(),lr = 1e-2,weight_decay=1e-2)\n",
    "D1_solver = optim.Adam(D.parameters(),lr = 1e-4)\n",
    "D0_solver = optim.Adam(D.parameters(),lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Initially train with BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.743095219135\n",
      "0.73493462801\n",
      "0.762349784374\n",
      "0.74689245224\n",
      "0.704093396664\n",
      "0.714151263237\n",
      "0.709716200829\n",
      "0.696048080921\n",
      "0.722295761108\n",
      "0.736637115479\n",
      "0.685199081898\n",
      "0.71788674593\n",
      "0.763336360455\n",
      "0.698856115341\n",
      "0.713256955147\n",
      "0.693974494934\n",
      "0.721129596233\n",
      "0.716451406479\n",
      "0.715591013432\n",
      "0.730312168598\n",
      "0.744190633297\n",
      "0.696163415909\n",
      "0.724393904209\n",
      "0.716960012913\n",
      "0.723156750202\n",
      "0.70235824585\n",
      "0.699847817421\n",
      "0.741686940193\n",
      "0.738591551781\n",
      "0.727178275585\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for ep in range(epochs):\n",
    "    for idx,(x,label) in enumerate(train_loader):\n",
    "        \n",
    "        x = x.view(batch_size,28*28)\n",
    "        x = Variable(x.cuda(),requires_grad = False)\n",
    "        \n",
    "        z = Variable(torch.randn(batch_size,z_dim)).cuda()\n",
    "        xhat = G(z)\n",
    "        g_loss = nn.MSELoss()(xhat,x)\n",
    "        g_loss.backward()\n",
    "        G_solver.step()\n",
    "        clear_grad()\n",
    "    print(g_loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.545816421508789, 0.6348524689674377)\n",
      "(1.0087379217147827, 3.9255428314208984)\n",
      "(8.104669570922852, 0.1335708051919937)\n",
      "(1.394392728805542, 0.8321279287338257)\n",
      "(1.2014310359954834, 0.9631125330924988)\n",
      "(1.4422893524169922, 0.7577905058860779)\n",
      "(0.1900748461484909, 5.482553005218506)\n",
      "(1.1048508882522583, 1.0216397047042847)\n",
      "(0.2562251687049866, 7.67146110534668)\n",
      "(0.768159031867981, 1.4790114164352417)\n",
      "(1.0974057912826538, 1.1126580238342285)\n",
      "(0.05540050193667412, 6.945626735687256)\n",
      "(25.03571319580078, 0.18921634554862976)\n",
      "(1.6095576286315918, 0.98798668384552)\n",
      "(1.6328438520431519, 1.1052435636520386)\n",
      "(0.5392376184463501, 2.0490493774414062)\n",
      "(1.4967983961105347, 2.1165125370025635)\n",
      "(1.2368985414505005, 1.7636340856552124)\n",
      "(0.9343772530555725, 1.0488476753234863)\n",
      "(0.6140216588973999, 5.32877254486084)\n",
      "(1.32639479637146, 0.9238998889923096)\n",
      "(0.7475924491882324, 1.659198522567749)\n",
      "(0.4037317633628845, 1.990234136581421)\n",
      "(1.0500928163528442, 1.4275308847427368)\n",
      "(0.0036560939624905586, 6.471774578094482)\n",
      "(1.5845115184783936, 1.3894342184066772)\n",
      "(0.8712062835693359, 1.515334129333496)\n",
      "(0.17053477466106415, 5.1035943031311035)\n",
      "(0.7921248078346252, 1.342063546180725)\n",
      "(1.2029509544372559, 1.321144461631775)\n",
      "(0.5154391527175903, 2.035081386566162)\n",
      "(0.35035544633865356, 2.119703769683838)\n",
      "(0.46146440505981445, 1.9917845726013184)\n",
      "(1.6268894672393799, 0.9188576340675354)\n",
      "(1.898376226425171, 1.2166528701782227)\n",
      "(0.7821193933486938, 1.4341143369674683)\n",
      "(0.5613057613372803, 3.3756065368652344)\n",
      "(0.3535495102405548, 3.093562364578247)\n",
      "(1.0831284523010254, 1.3929270505905151)\n",
      "(0.6274977922439575, 1.982371211051941)\n",
      "(1.4830381870269775, 1.072397232055664)\n",
      "(0.3341529667377472, 2.7409141063690186)\n",
      "(0.41579699516296387, 4.125114917755127)\n",
      "(0.5490310788154602, 1.9825968742370605)\n",
      "(0.3493754267692566, 2.523059129714966)\n",
      "(0.6697172522544861, 1.9931303262710571)\n",
      "(0.6761825084686279, 2.396575450897217)\n",
      "(0.8443255424499512, 1.886950969696045)\n",
      "(0.18061867356300354, 2.855146884918213)\n",
      "(0.036701202392578125, 7.62214469909668)\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for ep in range(epochs):\n",
    "    for idx,(x,label) in enumerate(train_loader):\n",
    "        \n",
    "        x = x.view(batch_size,28*28)\n",
    "        x = Variable(x.cuda())\n",
    "        \n",
    "        #zhat = E(x)\n",
    "        \n",
    "        z = Variable(torch.randn(batch_size,z_dim)).cuda()\n",
    "        xhat = G(z)\n",
    "        \n",
    "        ## Discriminator loss ##\n",
    "        \n",
    "        d_true = D(x)\n",
    "        d_false = D(xhat)\n",
    "        \n",
    "        add_tiny = 1e-10\n",
    "        \n",
    "        if(ep%1 == 0):\n",
    "            d_loss1 = nn.BCELoss()(d_true,Variable(torch.ones(d_true.size()).cuda()))\n",
    "            d_loss1.backward(retain_graph = True)\n",
    "            d_loss2 = nn.BCELoss()(d_false,Variable(torch.zeros(d_false.size())).cuda())\n",
    "            d_loss2.backward(retain_graph = True)\n",
    "            #d_loss = -(torch.mean(torch.log(d_true + add_tiny) + torch.log((1-d_false) + add_tiny)))\n",
    "            #d_loss.backward(retain_graph= True)\n",
    "            D0_solver.step()\n",
    "        \n",
    "            clear_grad()\n",
    "        \n",
    "        ## Generator Loss ##\n",
    "        \n",
    "        d_false = D(xhat)\n",
    "        g_loss = nn.BCELoss()(d_false,Variable(torch.ones(d_false.size()).cuda()))\n",
    "        g_loss = -torch.mean(torch.log(d_false + add_tiny)) + 0.1*nn.MSELoss()(xhat,x)\n",
    "        g_loss.backward()\n",
    "       # D1_solver.step()\n",
    "        G_solver.step()\n",
    "        \n",
    "        clear_grad()\n",
    "        \n",
    "    print((d_loss1+d_loss2).data[0],g_loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8tS2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ba0500750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_check = Variable(torch.randn(1,z_dim)).cuda()\n",
    "op = G(z_check)\n",
    "op = op.resize(28,28)\n",
    "op = op.data.cpu().numpy()\n",
    "plt.imshow(op)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.8215\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
