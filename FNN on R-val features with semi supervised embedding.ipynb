{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 10 fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/bioassay-datasets/'\n",
    "p_fingerprints = []\n",
    "c_fingerprints = []\n",
    "labels = []\n",
    "with open(path+'AID362red_train.csv') as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        p_fingerprints.append(row[:112])\n",
    "        c_fingerprints.append(row[112:-1])\n",
    "        labels.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 112)\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "p_fingerprints = np.asarray(p_fingerprints)[1:]\n",
    "p_fingerprints = p_fingerprints.astype(int)\n",
    "\n",
    "c_fingerprints = np.asarray(c_fingerprints)[1:]\n",
    "c_fingerprints = c_fingerprints.astype(float)\n",
    "\n",
    "#Normalise the features\n",
    "c_fingerprints = (c_fingerprints - np.mean(c_fingerprints,axis=0))/np.std(c_fingerprints,axis=0)\n",
    "\n",
    "#p2_fingerprints = np.ones(p_fingerprints.shape)\n",
    "(no_examples , ip_dim) = p_fingerprints.shape\n",
    "ip_dim2 = c_fingerprints.shape[1]\n",
    "labels = labels[1:]\n",
    "print(no_examples,ip_dim)\n",
    "print(ip_dim2)\n",
    "p_fingerprints[(p_fingerprints==0)] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tot_positive', 48)\n",
      "('fp allowed', 168)\n"
     ]
    }
   ],
   "source": [
    "labels2 = np.zeros((len(labels),1))\n",
    "for i,l in enumerate(labels):\n",
    "    if l=='Active':\n",
    "        labels2[i] = 1\n",
    "    else:\n",
    "        labels2[i] = 0\n",
    "labels2 = labels2.astype(int)\n",
    "total_pos = np.sum(labels2)\n",
    "print(\"tot_positive\",total_pos)\n",
    "fp_allowed = int((no_examples-total_pos)*0.05)\n",
    "print(\"fp allowed\",fp_allowed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Rnadomly permute the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.arange(no_examples)\n",
    "np.random.shuffle(ind)\n",
    "p_fingerprints = p_fingerprints[ind]\n",
    "c_fingerprints = c_fingerprints[ind]\n",
    "labels2 = labels2[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_train_batch(batch_size,binary=True):\n",
    "#     samples = np.random.randint(low=0,high=no_examples,size=(batch_size,1))\n",
    "#     if binary == True:\n",
    "#         train_batch = p_fingerprints[samples].reshape(batch_size,ip_dim)\n",
    "#         train_batch = train_batch.astype(int)\n",
    "#     else:\n",
    "#         train_batch = c_fingerprints[samples].reshape(batch_size,ip_dim2)\n",
    "#         train_batch = train_batch.astype(float)\n",
    "    \n",
    "#     train_batch = torch.cuda.FloatTensor(train_batch)\n",
    "#     train_batch = Variable(train_batch,requires_grad=False).cuda()\n",
    "#     #print(labels2[samples])\n",
    "#     target = Variable(torch.cuda.LongTensor(labels2[samples]),requires_grad=False)\n",
    "#     target = target.view(batch_size,)\n",
    "#     #print(target.type)\n",
    "#     return train_batch,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48]\n"
     ]
    }
   ],
   "source": [
    "no_active_ele = (sum(labels2))\n",
    "print(no_active_ele)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_batch(batch_size,validation_iter=0,binary=True):\n",
    "    \n",
    "    if validation_iter == 0: #no validation\n",
    "        curr_data_size = no_examples\n",
    "        labels_train = labels2\n",
    "    else:\n",
    "        curr_data_size = int(no_examples*0.8)\n",
    "        interval_size = int(no_examples*0.2)\n",
    "        \n",
    "        if(val_iter==1):\n",
    "            s_ind1 = int((validation_iter)*interval_size)\n",
    "            end_ind1 = int((validation_iter+1)*interval_size)\n",
    "            s_ind2 = int((validation_iter + 1) * interval_size)\n",
    "            end_ind2 = int(no_examples)\n",
    "        else:\n",
    "            s_ind1 = 0\n",
    "            end_ind1 = int((validation_iter)*interval_size)\n",
    "            s_ind2 = int((validation_iter + 1) * interval_size)\n",
    "            end_ind2 = int(no_examples)\n",
    "        \n",
    "        #print(\"train_ind \",s_ind1,end_ind1,s_ind2,end_ind2)\n",
    "        indices = range(s_ind1,end_ind1) + range(s_ind2,end_ind2)\n",
    "        c_train_data = c_fingerprints[indices]\n",
    "        p_train_data = p_fingerprints[indices]\n",
    "        labels_train = labels2[indices]\n",
    "                               \n",
    "    samples = np.random.randint(low=0,high=curr_data_size,size=(batch_size,1))\n",
    "    if binary == True:\n",
    "        train_batch = p_fingerprints[samples].reshape(batch_size,ip_dim)\n",
    "        train_batch = train_batch.astype(int)\n",
    "    else:\n",
    "        train_batch = c_fingerprints[samples].reshape(batch_size,ip_dim2)\n",
    "        train_batch = train_batch.astype(float)\n",
    "    \n",
    "    train_batch = torch.cuda.FloatTensor(train_batch)\n",
    "    train_batch = Variable(train_batch,requires_grad=False).cuda()\n",
    "    target = Variable(torch.cuda.LongTensor(labels_train[samples]),requires_grad=False)\n",
    "    target = target.view(batch_size,)\n",
    "    return train_batch,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_data(validation_iter,binary = True):\n",
    "    interval_size = int(no_examples)*0.2\n",
    "    s_ind = int((validation_iter-1)*interval_size)\n",
    "    e_ind = int((validation_iter) * interval_size)\n",
    "    if(binary==True):\n",
    "        train_data = p_fingerprints[s_ind:e_ind]\n",
    "    else:\n",
    "        train_data = c_fingerprints[s_ind:e_ind]\n",
    "    labels_val = labels2[s_ind:e_ind]   \n",
    "    #print(\"val ind \",s_ind,e_ind)\n",
    "    return Variable(torch.cuda.FloatTensor(train_data)),labels_val  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c_mlp,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim2,100)\n",
    "        self.l2 = nn.Linear(100,100)\n",
    "        self.l4 = nn.Linear(100,50)\n",
    "        self.l5 = nn.Linear(50,2)\n",
    "        \n",
    "    def forward(self,x,sse=False):\n",
    "        f = []\n",
    "        f1 = self.l1(x)\n",
    "        self.save_for_backward(f1)\n",
    "        #f.append(x)\n",
    "        x = F.leaky_relu(f1)\n",
    "        x = self.l2(x)\n",
    "        f.append(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        f.append(x)\n",
    "        x = self.l4(x)\n",
    "        f.append(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = (self.l5(x))\n",
    "        return x,f1.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('val iter: ', 1)\n",
      "('ep:  ', 0)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'c_mlp' object has no attribute 'save_for_backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1124f4bf4276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ep:  \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mmodel_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmymlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-2fad5122dc72>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sse)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#f.append(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 262\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'c_mlp' object has no attribute 'save_for_backward'"
     ]
    }
   ],
   "source": [
    "min_fn = 15\n",
    "max_fp = 60\n",
    "cm_list = []\n",
    "for val_iter in range(1,6):\n",
    "    print(\"val iter: \",val_iter)\n",
    "    \n",
    "   \n",
    "    #weights_array = [5]\n",
    "    weights_array = np.linspace(7,30,13)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp.parameters(),lr=1e-3)\n",
    "        sse_optim = torch.optim.Adagrad(mymlp.parameters(),lr = 1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(3):\n",
    "            print(\"ep:  \",ep)\n",
    "            train_batch,target = get_train_batch(batch_size,binary = False,validation_iter = val_iter)\n",
    "            model_op,f_op = mymlp(train_batch)\n",
    "            \n",
    "            loss = criterion(model_op,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "\n",
    "    #     if(ep%30==29):\n",
    "    #         print(loss.data[0])\n",
    "    \n",
    "            t_int = (target.data.cpu().numpy())\n",
    "            t_int = t_int.astype(int)\n",
    "            #f_ac = f_op[t_int==1]\n",
    "            #f_inac = f_op[t_int==0]\n",
    "            #print(len(f_ac),len(f_inac))\n",
    "            \n",
    "            for k in range(len(f_op)):\n",
    "                ind1 = torch.LongTensor(np.argwhere(t_int==0)).cuda()\n",
    "                ind1 = ind1.view((ind1.size()[0],))\n",
    "                #fnow = (f_op[k])\n",
    "                f_ac = torch.index_select(f_op,dim=0,index = ind1)\n",
    "                #compute only for 20-20 examples in each batch\n",
    "                sse_loss = 0\n",
    "                for i in range(20):\n",
    "                    for j in range(i):\n",
    "                        sse_loss  = sse_loss + torch.norm(f_ac[i]-f_ac[j])\n",
    "\n",
    "                inac_ele = len(f_inac)\n",
    "\n",
    "                for i in range(len(f_inac)):\n",
    "                    for j in range(i):\n",
    "                        sse_loss = sse_loss +  torch.norm(f_inac[i] - f_inac[j])\n",
    "\n",
    "                for i in range(len(f_inac)):\n",
    "                    for j in range(20):\n",
    "                        sse_loss += torch.max(0, 2 - torch.norm(f_inac[i] - f_ac[j]))\n",
    "\n",
    "                sse_loss = sse_loss/((20*(20-1)/2) * (inac_ele*(inac_ele-1)/2) * 20*f_inac)\n",
    "\n",
    "                sse_loss.backward()\n",
    "                sse_optim.step()\n",
    "                sse_optim.zero_grad()\n",
    "\n",
    "                #if ep%30 == 29:\n",
    "                print sse_loss.data[0]\n",
    "            \n",
    "                    \n",
    "        ## After training check on cross validation data\n",
    "        val_data,labels_val = get_val_data(val_iter,binary = False)\n",
    "        train_op = mymlp(val_data)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "        #tmp_labels = tmp_labels.data.cpu().numpy()\n",
    "        #print(sum(tmp_labels))\n",
    "        cf = metrics.confusion_matrix(labels_val,pred_labels).ravel()\n",
    "        #print(val_iter,w)\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        wcf = [val_iter] + [w] + [cf]\n",
    "        if(fn < 3):\n",
    "            cm_list.append(wcf)\n",
    "            if(fn<4):\n",
    "                if(fp < max_fp):\n",
    "                    max_fp = fp\n",
    "                    model_path = os.getcwd() + '/cont_model_with_val_selu'\n",
    "                    torch.save(mymlp.state_dict(),model_path)\n",
    "                    print(\"saving model on val: \",val_iter,\" and weight: \",w)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Variable.type of Variable containing:\n",
       " 1.9287e-01 -7.9549e-01  2.0571e-01  ...   9.5052e-02  3.9897e-01  1.1982e-02\n",
       "-9.5301e-02 -4.3733e-01 -2.3684e-01  ...   5.4843e-01 -1.4905e-01 -2.4515e-01\n",
       "-6.9170e-01 -1.8215e-01  3.9325e-01  ...  -1.6132e-01  1.3707e-01 -1.5613e-01\n",
       "                ...                   ⋱                   ...                \n",
       " 2.5191e-01 -7.0508e-01 -3.0295e-01  ...   2.2555e-01  5.3586e-01  1.3782e-01\n",
       " 1.3518e-01 -9.6394e-01 -7.3459e-01  ...   1.1321e-01 -1.3200e-01 -1.5562e-01\n",
       " 1.0098e-01 -1.9448e-01 -1.0422e-01  ...  -5.6309e-02  1.3173e-01 -1.8353e-01\n",
       "[torch.cuda.FloatTensor of size 128x100 (GPU 0)]\n",
       ">"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_op[0].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #weights_array = np.linspace(3,25,22)\n",
    "# tmp_w = [weights_array[0]]\n",
    "# cont_cm_lsit = []\n",
    "# for i,w in enumerate(tmp_w):\n",
    "    \n",
    "    \n",
    "#     c_mymlp = c_mlp().cuda()\n",
    "#     optimizer2 = torch.optim.Adam(c_mymlp.parameters(),lr=1e-4)\n",
    "    \n",
    "#     weights = torch.cuda.FloatTensor([1,w])\n",
    "#     criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "    \n",
    "#     for ep in range(2000):\n",
    "#         train_batch,target = get_train_batch(batch_size,binary=False)\n",
    "#         #train_batch,target = sample_X(batch_size,labels='True')\n",
    "#         #target = Variable(torch.cuda.LongTensor(target),requires_grad = False)\n",
    "#         model_op = c_mymlp(train_batch)\n",
    "#         #print(model_op.type)\n",
    "#         #print(target.type)\n",
    "#         loss = criterion(model_op,target)\n",
    "#         loss.backward()\n",
    "#         optimizer2.step()\n",
    "#         optimizer2.zero_grad()\n",
    "    \n",
    "#         if(ep%100==99):\n",
    "#             print(loss.data[0])\n",
    "\n",
    "#     train_op = c_mymlp(Variable(torch.cuda.FloatTensor(c_fingerprints)))\n",
    "#     train_op = train_op.cpu().data.numpy()\n",
    "#     pred_labels = np.argmax(train_op,axis=1)\n",
    "#     #tmp_labels = tmp_labels.data.cpu().numpy()\n",
    "#     #print(sum(tmp_labels))\n",
    "#     cont_cf = metrics.confusion_matrix(labels2,pred_labels).ravel()\n",
    "#     print('tn, fp, fn, tp: ',cont_cf)\n",
    "#     cont_cm_lsit.append(cont_cf)\n",
    "    \n",
    "#     #model_path = os.getcwd() + '/model' + str(i)\n",
    "#     #torch.save(c_mymlp.state_dict(),model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Checking on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()+'/bioassay-datasets/'\n",
    "test_bin = []\n",
    "test_con = []\n",
    "labels = []\n",
    "with open(path+'AID362red_test.csv') as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        test_bin.append(row[:112])\n",
    "        test_con.append(row[112:-1])\n",
    "        labels.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(856, 112)\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "test_bin = np.asarray(test_bin)[1:]\n",
    "test_bin = test_bin.astype(int)\n",
    "\n",
    "test_con = np.asarray(test_con)[1:]\n",
    "test_con = test_con.astype(float)\n",
    "\n",
    "#Normalise the features\n",
    "test_con = (test_con - np.mean(test_con,axis=0))/np.std(test_con,axis=0)\n",
    "\n",
    "#p2_fingerprints = np.ones(p_fingerprints.shape)\n",
    "(no_examples , ip_dim) = test_bin.shape\n",
    "ip_dim2 = test_con.shape[1]\n",
    "labels = labels[1:]\n",
    "print(no_examples,ip_dim)\n",
    "print(ip_dim2)\n",
    "test_bin[(test_bin==0)] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'unexpected key \"l3.weight\" in state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4fff16c51fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_c_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparam_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/cont_model_with_val'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_c_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mown_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 raise KeyError('unexpected key \"{}\" in state_dict'\n\u001b[0;32m--> 355\u001b[0;31m                                .format(name))\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0;31m# backwards compatibility for serialized parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'unexpected key \"l3.weight\" in state_dict'"
     ]
    }
   ],
   "source": [
    "best_c_mlp = c_mlp().cuda()\n",
    "param_path = os.getcwd() + '/cont_model_with_val'\n",
    "best_c_mlp.load_state_dict(torch.load(param_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels2 = np.zeros((len(labels),1))\n",
    "for i,l in enumerate(labels):\n",
    "    if l=='Active':\n",
    "        test_labels2[i] = 1\n",
    "    else:\n",
    "        test_labels2[i] = 0\n",
    "test_labels2 = test_labels2.astype(int)\n",
    "total_pos = np.sum(test_labels2)\n",
    "print(\"tot_positive\",total_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_op = best_c_mlp(Variable(torch.cuda.FloatTensor(test_con)))\n",
    "test_op = test_op.cpu().data.numpy()\n",
    "test_pred = np.argmax(test_op,axis=1)\n",
    "    #tmp_labels = tmp_labels.data.cpu().numpy()\n",
    "    #print(sum(tmp_labels))\n",
    "t_cont_cf = metrics.confusion_matrix(test_labels2,test_pred).ravel()\n",
    "print('tn, fp, fn, tp: ',t_cont_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
