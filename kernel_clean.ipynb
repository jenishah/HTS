{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "import sampling_with_data_cleaning as sdc\n",
    "%matplotlib notebook\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "findex = 0\n",
    "xtmp,y = get_features(findex,cleaned=False)\n",
    "xtmp,y = shuffle(xtmp,y)\n",
    "y = y.astype(int)\n",
    "no_ex = xtmp.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_features are real valued features. We apply kernel on it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_dim = 250\n",
    "rbf_feature = RBFSampler(gamma=1,n_components = feat_dim, random_state=1)\n",
    "x_t = rbf_feature.fit_transform(xtmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 250)\n"
     ]
    }
   ],
   "source": [
    "print x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y.reshape(y.shape[0],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Adding 174 new samples\n",
      "removing 74 samples\n",
      "[ 821 1917 2121   35 2723 1497  746  227 1508 1022  669  886    0 1025  984\n",
      " 2971 3319 2282 2989  118 2286 2566 2757 2341 1254 3172 2322 1065  473 1522\n",
      "  108 1671 2309  422 3336 3228 3201  270 1087  819 1667  731 2531  626 2774\n",
      " 1367  166 2896 3329 2283  793 2116  418  423  823 1114 2564 2668  790 1922\n",
      " 2561  625  428 3154 3407 3257 1328  970 1808  337 2957 1242 1417 3076]\n"
     ]
    }
   ],
   "source": [
    "x,y = sdc.clean_data(x_t,y,k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c_mlp,self).__init__()\n",
    "        self.l1 = nn.Linear(feat_dim,1000)\n",
    "        self.l2 = nn.Linear(1000,1000)\n",
    "        self.l3 = nn.Linear(1000,500)\n",
    "        self.l4 = nn.Linear(500,500)\n",
    "        self.l5 = nn.Linear(500,500)\n",
    "        self.l6 = nn.Linear(500,500)\n",
    "        self.l6 = nn.Linear(500,50)\n",
    "        self.l7 = nn.Linear(50,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = F.leaky_relu(self.l3(x))\n",
    "        x = F.leaky_relu(self.l4(x))\n",
    "        x = F.leaky_relu(self.l5(x))\n",
    "        x = F.leaky_relu(self.l6(x))\n",
    "        x = self.l7(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('val iter: ', 1)\n",
      "('tn, fp, fn, tp: ', array([680,   7,   3,  14]))\n",
      "('min fp, max_percent', 7, 0.8235294117647058)\n",
      "('saving model on val: ', 1, ' and weight: ', 30.0)\n",
      "('tn, fp, fn, tp: ', array([678,   9,   1,  16]))\n",
      "('min fp, max_percent', 9, 0.9411764705882353)\n",
      "('saving model on val: ', 1, ' and weight: ', 35.0)\n",
      "('tn, fp, fn, tp: ', array([678,   9,   0,  17]))\n",
      "('min fp, max_percent', 9, 1.0)\n",
      "('saving model on val: ', 1, ' and weight: ', 40.0)\n",
      "('tn, fp, fn, tp: ', array([681,   6,   4,  13]))\n",
      "('tn, fp, fn, tp: ', array([681,   6,   4,  13]))\n",
      "('val iter: ', 2)\n",
      "('tn, fp, fn, tp: ', array([692,   4,   3,   6]))\n",
      "('tn, fp, fn, tp: ', array([688,   8,   0,   9]))\n",
      "('min fp, max_percent', 8, 1.0)\n",
      "('saving model on val: ', 2, ' and weight: ', 35.0)\n",
      "('tn, fp, fn, tp: ', array([689,   7,   1,   8]))\n",
      "('tn, fp, fn, tp: ', array([691,   5,   1,   8]))\n",
      "('tn, fp, fn, tp: ', array([692,   4,   0,   9]))\n",
      "('min fp, max_percent', 4, 1.0)\n",
      "('saving model on val: ', 2, ' and weight: ', 50.0)\n",
      "('val iter: ', 3)\n",
      "('tn, fp, fn, tp: ', array([698,   2,   0,   4]))\n",
      "('val iter: ', 4)\n",
      "('tn, fp, fn, tp: ', array([692,   3,   5,   5]))\n",
      "('tn, fp, fn, tp: ', array([693,   2,   4,   6]))\n",
      "('tn, fp, fn, tp: ', array([690,   5,   3,   7]))\n",
      "('tn, fp, fn, tp: ', array([690,   5,   1,   9]))\n",
      "('tn, fp, fn, tp: ', array([691,   4,   2,   8]))\n",
      "('val iter: ', 5)\n",
      "('tn, fp, fn, tp: ', array([522,   1,  54, 128]))\n",
      "('tn, fp, fn, tp: ', array([522,   1,  78, 104]))\n",
      "('tn, fp, fn, tp: ', array([522,   1,  79, 103]))\n",
      "('tn, fp, fn, tp: ', array([522,   1,  79, 103]))\n",
      "('tn, fp, fn, tp: ', array([522,   1,  49, 133]))\n"
     ]
    }
   ],
   "source": [
    "max_percent = 0.7\n",
    "model_no = 1\n",
    "for i in range(1,6):\n",
    "    val_iter = i\n",
    "    print(\"val iter: \",val_iter)\n",
    "    \n",
    "   \n",
    "    #weights_array = [7]\n",
    "    weights_array = np.linspace(30,50,5)\n",
    "    \n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(2500):\n",
    "            \n",
    "            ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "            xtrain,ytrain = get_train_batch(x,y,batch_size=100,indices=ind)\n",
    "            \n",
    "            model_op = mymlp(xtrain)\n",
    "           \n",
    "            loss = criterion(model_op,ytrain)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    #     if(ep%30==29):\n",
    "    #         print(loss.data[0])\n",
    "\n",
    "        ## After training check on cross validation data\n",
    "        xval,yval = get_val_data(x,y,no_examples=no_ex,val_iter=val_iter)\n",
    "        min_fp = xval.size()[0]*0.2\n",
    "        yval = yval.reshape(yval.shape[0],)\n",
    "        train_op = mymlp(xval)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "      \n",
    "        cf = metrics.confusion_matrix(yval,pred_labels).ravel()\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        percent = float(float(tp)/float(tp+fn))\n",
    "        if(percent>max_percent*0.98):\n",
    "            if(fp<min_fp):\n",
    "                if(model_no<6):\n",
    "                        max_percent = percent\n",
    "                        print(\"min fp, max_percent\",fp,percent)\n",
    "                        model_path = os.getcwd() + '/kernel_clean_' + str(findex)+'_model'+str(model_no)\n",
    "                        torch.save(mymlp.state_dict(),model_path)\n",
    "                        print(\"saving model on val: \",val_iter,\" and weight: \",w)\n",
    "                        model_no = model_no + 1\n",
    "                else:\n",
    "                    break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(856,)\n"
     ]
    }
   ],
   "source": [
    "feat_dim = 250\n",
    "\n",
    "xtest,ytest = get_features(findex,train=False)\n",
    "#xtest = Variable(torch.cuda.FloatTensor(xtest_t).cuda())\n",
    "final_pred = np.zeros(ytest.shape[0],)\n",
    "print final_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_feature = RBFSampler(gamma=1,n_components = feat_dim, random_state=1)\n",
    "trans = rbf_feature.fit(xtmp)\n",
    "xtest = trans.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "already counted a million dimensions in a given sequence. Most likely your items are also sequences and there's no way to infer how many dimension should the tensor have",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f2a4b4433267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/kernel_clean_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_model'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: already counted a million dimensions in a given sequence. Most likely your items are also sequences and there's no way to infer how many dimension should the tensor have"
     ]
    }
   ],
   "source": [
    "xtest = Variable(torch.cuda.FloatTensor(xtest))\n",
    "for i in range(1,6):\n",
    "    model_path = os.getcwd() + '/kernel_clean_' + str(findex)+'_model'+str(i)    \n",
    "    test_model = c_mlp().cuda()\n",
    "    test_model.load_state_dict(torch.load(model_path))\n",
    "    test_op = test_model(xtest)\n",
    "    test_op = test_op.cpu().data.numpy()\n",
    "    pred_labels = np.argmax(test_op,axis=1).reshape(final_pred.shape[0],)\n",
    "    print pred_labels.shape\n",
    "    final_pred = pred_labels + final_pred\n",
    "    print final_pred.shape\n",
    "    cf = metrics.confusion_matrix(ytest,pred_labels).ravel()\n",
    "    print('tn, fp, fn, tp: ',cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pred[final_pred>1] = 1\n",
    "cf = metrics.confusion_matrix(ytest,final_pred).ravel()\n",
    "print('tn, fp, fn, tp: ',cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testmlp = c_mlp().cuda()\n",
    "# model_path = os.getcwd() + '/kernel_mac' + fname + '_3'\n",
    "# testmlp.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# op = testmlp(Variable(torch.cuda.FloatTensor(c_fingerprints_test)))\n",
    "# op = op.cpu().data.numpy()\n",
    "# pred_labels = np.argmax(op,axis=1)\n",
    "# cf = metrics.confusion_matrix(labels2_t,pred_labels).ravel()\n",
    "# #print(val_iter,w)\n",
    "# print('tn, fp, fn, tp: ',cf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
