{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "import random\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import pandas as pd\n",
    "#sys.path.append(\"/home/CVShare/Jeni/hts/machine_learning/sampling_with_data_cleaning\")\n",
    "import sampling_with_data_cleaning as sdc\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN on cleaned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47383,)\n",
      "907.0\n",
      "907\n"
     ]
    }
   ],
   "source": [
    "findex = 1\n",
    "x,y = get_features(findex,train=True,cleaned=True)\n",
    "print y.shape\n",
    "print sum(y)\n",
    "y = y.astype(int)\n",
    "print sum(y)\n",
    "x,y = shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47383 154\n"
     ]
    }
   ],
   "source": [
    "no_ex,ip_dim = x.shape\n",
    "print no_ex,ip_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c_mlp,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,500)\n",
    "        self.l2 = nn.Linear(500,500)\n",
    "        self.l3 = nn.Linear(500,250)\n",
    "        self.l4 = nn.Linear(250,50)\n",
    "        self.l5 = nn.Linear(50,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = F.leaky_relu(self.l3(x))\n",
    "        x = F.leaky_relu(self.l4(x))\n",
    "        x = (self.l5(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('val iter: ', 1)\n",
      "('tn, fp, fn, tp: ', array([8779,  526,  101,   70]))\n",
      "('tn, fp, fn, tp: ', array([8811,  494,  105,   66]))\n",
      "('tn, fp, fn, tp: ', array([8554,  751,   91,   80]))\n",
      "('tn, fp, fn, tp: ', array([8692,  613,   93,   78]))\n",
      "('tn, fp, fn, tp: ', array([8160, 1145,   76,   95]))\n",
      "('min fp, max_percent', 1145, 0.5555555555555556)\n",
      "('saving model on val: ', 1, ' and weight: ', 33.333333333333336)\n",
      "('tn, fp, fn, tp: ', array([8073, 1232,   72,   99]))\n",
      "('tn, fp, fn, tp: ', array([8220, 1085,   75,   96]))\n",
      "('min fp, max_percent', 1085, 0.5614035087719298)\n",
      "('saving model on val: ', 1, ' and weight: ', 40.0)\n",
      "('tn, fp, fn, tp: ', array([7772, 1533,   65,  106]))\n",
      "('tn, fp, fn, tp: ', array([7909, 1396,   60,  111]))\n",
      "('tn, fp, fn, tp: ', array([8279, 1026,   81,   90]))\n",
      "('val iter: ', 2)\n",
      "('tn, fp, fn, tp: ', array([8180, 1105,   75,  117]))\n",
      "('tn, fp, fn, tp: ', array([8453,  832,   85,  107]))\n",
      "('tn, fp, fn, tp: ', array([8506,  779,   96,   96]))\n",
      "('tn, fp, fn, tp: ', array([8308,  977,   79,  113]))\n",
      "('min fp, max_percent', 977, 0.5885416666666666)\n",
      "('saving model on val: ', 2, ' and weight: ', 30.0)\n",
      "('tn, fp, fn, tp: ', array([8141, 1144,   79,  113]))\n",
      "('tn, fp, fn, tp: ', array([8603,  682,  100,   92]))\n",
      "('tn, fp, fn, tp: ', array([8369,  916,   84,  108]))\n",
      "('tn, fp, fn, tp: ', array([7954, 1331,   66,  126]))\n",
      "('tn, fp, fn, tp: ', array([8090, 1195,   72,  120]))\n",
      "('tn, fp, fn, tp: ', array([8290,  995,   79,  113]))\n",
      "('val iter: ', 3)\n",
      "('tn, fp, fn, tp: ', array([8895,  388,  125,   68]))\n",
      "('tn, fp, fn, tp: ', array([8570,  713,  104,   89]))\n",
      "('tn, fp, fn, tp: ', array([8344,  939,   87,  106]))\n",
      "('tn, fp, fn, tp: ', array([8427,  856,  100,   93]))\n",
      "('tn, fp, fn, tp: ', array([8293,  990,   89,  104]))\n",
      "('tn, fp, fn, tp: ', array([8151, 1132,   83,  110]))\n",
      "('tn, fp, fn, tp: ', array([8112, 1171,   82,  111]))\n",
      "('tn, fp, fn, tp: ', array([8347,  936,   94,   99]))\n",
      "('tn, fp, fn, tp: ', array([8430,  853,  104,   89]))\n",
      "('tn, fp, fn, tp: ', array([8309,  974,   95,   98]))\n",
      "('val iter: ', 4)\n",
      "('tn, fp, fn, tp: ', array([9031,  248,  151,   47]))\n",
      "('tn, fp, fn, tp: ', array([8495,  784,   96,  102]))\n",
      "('tn, fp, fn, tp: ', array([8458,  821,   99,   99]))\n",
      "('tn, fp, fn, tp: ', array([8187, 1092,   80,  118]))\n",
      "('tn, fp, fn, tp: ', array([8565,  714,  104,   94]))\n",
      "('tn, fp, fn, tp: ', array([8142, 1137,   83,  115]))\n",
      "('tn, fp, fn, tp: ', array([8182, 1097,   83,  115]))\n",
      "('tn, fp, fn, tp: ', array([8395,  884,   86,  112]))\n",
      "('tn, fp, fn, tp: ', array([8396,  883,   80,  118]))\n",
      "('min fp, max_percent', 883, 0.5959595959595959)\n",
      "('saving model on val: ', 4, ' and weight: ', 46.666666666666671)\n",
      "('tn, fp, fn, tp: ', array([7977, 1302,   76,  122]))\n",
      "('val iter: ', 5)\n",
      "('tn, fp, fn, tp: ', array([8746,  578,   98,   55]))\n",
      "('tn, fp, fn, tp: ', array([8500,  824,   85,   68]))\n",
      "('tn, fp, fn, tp: ', array([8338,  986,   73,   80]))\n",
      "('tn, fp, fn, tp: ', array([8659,  665,   90,   63]))\n",
      "('tn, fp, fn, tp: ', array([8286, 1038,   73,   80]))\n",
      "('tn, fp, fn, tp: ', array([8021, 1303,   60,   93]))\n",
      "('tn, fp, fn, tp: ', array([7807, 1517,   57,   96]))\n",
      "('tn, fp, fn, tp: ', array([7697, 1627,   55,   98]))\n",
      "('tn, fp, fn, tp: ', array([8534,  790,   78,   75]))\n",
      "('tn, fp, fn, tp: ', array([7418, 1906,   48,  105]))\n"
     ]
    }
   ],
   "source": [
    "max_percent = 0.5\n",
    "min_fp = no_ex*0.2\n",
    "for i in range(1,6):\n",
    "    val_iter = i\n",
    "    print(\"val iter: \",val_iter)\n",
    "    \n",
    "   \n",
    "    #weights_array = [7]\n",
    "    weights_array = np.linspace(20,50,10)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(1000):\n",
    "            \n",
    "            ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "            xtrain,ytrain = get_train_batch(x,y,batch_size=50,indices=ind)\n",
    "            \n",
    "            model_op = mymlp(xtrain)\n",
    "           \n",
    "            loss = criterion(model_op,ytrain)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    #     if(ep%30==29):\n",
    "    #         print(loss.data[0])\n",
    "\n",
    "        ## After training check on cross validation data\n",
    "        xval,yval = get_val_data(x,y,no_examples=no_ex,val_iter=val_iter)\n",
    "        yval = yval.reshape(yval.shape[0],)\n",
    "        train_op = mymlp(xval)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "      \n",
    "        cf = metrics.confusion_matrix(yval,pred_labels).ravel()\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        percent = float(float(tp)/float(tp+fn))\n",
    "        if(percent>max_percent):\n",
    "            if(1==1):\n",
    "                if(fp < min_fp):\n",
    "                    min_fp = fp\n",
    "                    max_percent = percent\n",
    "                    print(\"min fp, max_percent\",fp,percent)\n",
    "                    model_path = os.getcwd() + '/fnn_clean' + str(findex)\n",
    "                    torch.save(mymlp.state_dict(),model_path)\n",
    "                    print(\"saving model on val: \",val_iter,\" and weight: \",w)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.autograd.variable.Variable'>\n"
     ]
    }
   ],
   "source": [
    "xtest,ytest = get_features(findex,train=False)\n",
    "xtest = Variable(torch.cuda.FloatTensor(xtest).cuda())\n",
    "test_model = c_mlp().cuda()\n",
    "model_path = os.getcwd() + '/fnn_clean' + str(findex)\n",
    "test_model.load_state_dict(torch.load(model_path))\n",
    "test_op = test_model(xtest)\n",
    "print type(test_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp: ', array([10680,  1235,    20,    22]))\n"
     ]
    }
   ],
   "source": [
    "test_op = test_op.cpu().data.numpy()\n",
    "pred_labels = np.argmax(test_op,axis=1)\n",
    "cf = metrics.confusion_matrix(ytest,pred_labels).ravel()\n",
    "print('tn, fp, fn, tp: ',cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While copying the parameter named l1.weight, whose dimensions in the model are torch.Size([500, 154]) and whose dimensions in the checkpoint are torch.Size([500, 153]), ...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: sizes do not match at /pytorch/torch/lib/THC/THCTensorCopy.cu:31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ca7c4f5b0e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_model2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_path2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/fnn_clean'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_model2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 \u001b[0mown_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 print('While copying the parameter named {}, whose dimensions in the model are'\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: sizes do not match at /pytorch/torch/lib/THC/THCTensorCopy.cu:31"
     ]
    }
   ],
   "source": [
    "test_model2 = c_mlp().cuda()\n",
    "model_path2 = os.getcwd() + '/fnn_clean' + str(2)\n",
    "test_model2.load_state_dict(torch.load(model_path2))\n",
    "test_op = test_model2(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
