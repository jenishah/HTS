{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn.metrics as metrics\n",
    "import numpy.linalg as la\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/daiict/CVShare/Jeni/hts/bioassay-datasets/'\n",
    "p_fingerprints = []\n",
    "labels = []\n",
    "with open(path+'AID362red_train.csv') as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        p_fingerprints.append(row[:112])\n",
    "        labels.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 112)\n",
      "('total no of 1s', 25982)\n",
      "('total no of 0s', 357394)\n"
     ]
    }
   ],
   "source": [
    "p_fingerprints = np.asarray(p_fingerprints)[1:]\n",
    "p_fingerprints = p_fingerprints.astype(int)\n",
    "#p2_fingerprints = np.ones(p_fingerprints.shape)\n",
    "(no_examples , ip_dim) = p_fingerprints.shape\n",
    "labels = labels[1:]\n",
    "print(no_examples,ip_dim)\n",
    "print(\"total no of 1s\",np.sum(p_fingerprints))\n",
    "print(\"total no of 0s\",no_examples*ip_dim-np.sum(p_fingerprints))\n",
    "\n",
    "p_fingerprints[(p_fingerprints==0)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 48.]\n"
     ]
    }
   ],
   "source": [
    "labels2 = np.zeros((len(labels),1))\n",
    "for i,l in enumerate(labels):\n",
    "    if l=='Active':\n",
    "        labels2[i] = 1\n",
    "    else:\n",
    "        labels2[i] = 0\n",
    "\n",
    "no_active_ele = (sum(labels2))\n",
    "labels2 = labels2.astype(int)\n",
    "print(no_active_ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_batch(batch_size,keep_numpy=False):\n",
    "    samples = np.random.randint(low=0,high=no_examples,size=(batch_size,1))\n",
    "    train_batch = p_fingerprints[samples].reshape(batch_size,ip_dim)\n",
    "    train_batch = train_batch.astype(int)\n",
    "    train_batch = torch.cuda.FloatTensor(train_batch)\n",
    "    train_batch = Variable(train_batch,requires_grad=False).cuda()\n",
    "    if(keep_numpy==False):\n",
    "        target = (torch.cuda.LongTensor(labels2[samples]))\n",
    "    else:\n",
    "        target = labels2[samples]\n",
    "    return train_batch,target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating p_vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_active = np.float32(np.sum(p_fingerprints[labels2[:,0]==1],axis=0))/np.sum(labels2)\n",
    "p_inactive = np.float32(np.sum(p_fingerprints[labels2[:,0]==0],axis=0))/(no_examples-np.sum(labels2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying p_vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_active = p_active + 0.5*(p_active-p_inactive)\n",
    "p_active[p_active<0] = 0\n",
    "p_inactive = p_inactive + 0.5*(p_inactive - p_active)\n",
    "p_inactive[p_inactive<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#find the angle between them\n",
    "theta = np.dot(p_active,p_inactive)/(la.norm(p_active)*la.norm(p_inactive))\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,ip_dim+50)\n",
    "        self.l2 = nn.Linear(ip_dim+50,ip_dim)\n",
    "        self.l3 = nn.Linear(ip_dim,ip_dim)\n",
    "        self.l4 = nn.Linear(ip_dim,ip_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.l1(x))\n",
    "        x = F.tanh(self.l2(x))\n",
    "        x = F.tanh(self.l3(x))\n",
    "        x = self.l4(x)\n",
    "        #x = self.l4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,ip_dim)\n",
    "        self.l2 = nn.Linear(ip_dim,ip_dim)\n",
    "        self.l3 = nn.Linear(ip_dim,ip_dim+50)\n",
    "        self.l4 = nn.Linear(ip_dim+50,ip_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.l1(x))\n",
    "        x = F.tanh(self.l2(x))\n",
    "        x = F.tanh(self.l3(x))\n",
    "        x = F.tanh(self.l4(x))\n",
    "        #x = self.l4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class disc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(disc,self).__init__()\n",
    "        self.lin1 = nn.Linear(ip_dim,500)\n",
    "        self.lin2 = nn.Linear(500,500)\n",
    "        self.lin3 = nn.Linear(500,100)\n",
    "        self.lin4 = nn.Linear(100,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.selu(self.lin1(x))\n",
    "        x = F.selu(self.lin2(x))\n",
    "        x = F.selu(self.lin3(x))\n",
    "        x = F.sigmoid(self.lin4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw samples based on labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_samples(batch_size,labels,var_active,var_inactive):\n",
    "    z = np.zeros((batch_size,ip_dim))\n",
    "    rand_vec = np.random.randn(batch_size,ip_dim)\n",
    "    z[labels==1] = p_active + var_active*rand_vec[labels==1]\n",
    "    z[labels==0] = p_inactive + var_inactive*rand_vec[labels==0]\n",
    "    z = torch.cuda.FloatTensor(z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(Q,Q_solver,P,P_solver,D,D_solver,batch_size):\n",
    "    \n",
    "    for it in range(4000):\n",
    "        x,y = get_train_batch(batch_size,keep_numpy=True)\n",
    "        y = y.reshape(batch_size,)\n",
    "        z = Q(x)\n",
    "        z_false = Q(x)\n",
    "        \n",
    "        \n",
    "        #Reconstruction\n",
    "        \n",
    "        x_recon = P(z)\n",
    "        criterion = nn.MSELoss()\n",
    "        CEL = criterion(x_recon, x)\n",
    "        CEL.backward()\n",
    "        \n",
    "        Q_solver.step()\n",
    "        P_solver.step()\n",
    "        \n",
    "        Q.zero_grad()\n",
    "        P.zero_grad()\n",
    "        \n",
    "        #Discriminator\n",
    "        z_false_op = D(z_false)\n",
    "        z_true = Variable(draw_samples(batch_size,y,var_active=0.5,var_inactive=0.2))\n",
    "        \n",
    "        \n",
    "        z_true_op = Variable(D(z_true).data,requires_grad=False)\n",
    "                \n",
    "        add_small = 1e-20\n",
    "        \n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "        loss_d = criterion(z_false_op,z_true_op)\n",
    "        #loss_d = -torch.mean(torch.log(z_true_op + add_small) + torch.log(1 - z_false_op + add_small))\n",
    "        loss_d.backward(retain_variables = True)\n",
    "        D_solver.step()\n",
    "        D.zero_grad()\n",
    "        \n",
    "        #Updating the encoder\n",
    "        \n",
    "        G_loss = -torch.mean(torch.log(z_false_op+1e-20))\n",
    "        G_loss.backward()\n",
    "        Q_solver.step()\n",
    "        Q_solver.zero_grad()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if(it%50==0):\n",
    "            #print(extra_loss.data[0],CEL.data[0])\n",
    "            print('recon_loss:', CEL.data[0],'disc_loss:', loss_d.data[0],'gen_loss: ',G_loss.data[0])\n",
    "            #print(x_recon[0][:50].cpu().data.numpy().T)\n",
    "            #print()\n",
    "            #print(x[0][:50].cpu().data.numpy().T)\n",
    "           # print()\n",
    "    return Q,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    Q = encoder()\n",
    "    Q.cuda()\n",
    "    Q_solver = optim.Adam(Q.parameters(),lr=1e-4)\n",
    "    E_solver = optim.Adam(Q.parameters(),lr = 1e-5)\n",
    "    P = decoder()\n",
    "    P.cuda()\n",
    "    P_solver = optim.Adam(P.parameters(),lr = 1e-4)\n",
    "    D = disc()\n",
    "    D.cuda()\n",
    "    D_solver = optim.Adam(D.parameters(),lr = 1e-3)\n",
    "    batch_size = 120\n",
    "    Q,P = train_model(Q,Q_solver,P,P_solver,D,D_solver,batch_size)\n",
    "    \n",
    "    return Q,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('recon_loss:', 0.9891828298568726, 'disc_loss:', 0.6929869055747986, 'gen_loss: ', 0.7118141651153564)\n",
      "('recon_loss:', 0.5475317239761353, 'disc_loss:', 0.3869379162788391, 'gen_loss: ', 0.0762544646859169)\n",
      "('recon_loss:', 0.22318153083324432, 'disc_loss:', 0.4810473322868347, 'gen_loss: ', 0.03726759925484657)\n",
      "('recon_loss:', 0.21230915188789368, 'disc_loss:', 0.4877541959285736, 'gen_loss: ', 0.08886773884296417)\n",
      "('recon_loss:', 0.2181137651205063, 'disc_loss:', 0.5032536387443542, 'gen_loss: ', 0.08728349953889847)\n",
      "('recon_loss:', 0.20505750179290771, 'disc_loss:', 0.48060494661331177, 'gen_loss: ', 0.0864524319767952)\n",
      "('recon_loss:', 0.2120388150215149, 'disc_loss:', 0.48310306668281555, 'gen_loss: ', 0.08849571645259857)\n",
      "('recon_loss:', 0.20698004961013794, 'disc_loss:', 0.4826432466506958, 'gen_loss: ', 0.08823322504758835)\n",
      "('recon_loss:', 0.21206501126289368, 'disc_loss:', 0.47768017649650574, 'gen_loss: ', 0.08627975732088089)\n",
      "('recon_loss:', 0.21053947508335114, 'disc_loss:', 0.4969840347766876, 'gen_loss: ', 0.08544795215129852)\n",
      "('recon_loss:', 0.2225615382194519, 'disc_loss:', 0.4838375747203827, 'gen_loss: ', 0.08967378735542297)\n",
      "('recon_loss:', 0.21803973615169525, 'disc_loss:', 0.48928794264793396, 'gen_loss: ', 0.08950118720531464)\n",
      "('recon_loss:', 0.21285469830036163, 'disc_loss:', 0.507425844669342, 'gen_loss: ', 0.08776206523180008)\n",
      "('recon_loss:', 0.20426595211029053, 'disc_loss:', 0.4941879212856293, 'gen_loss: ', 0.08822233229875565)\n",
      "('recon_loss:', 0.20875734090805054, 'disc_loss:', 0.4976519048213959, 'gen_loss: ', 0.09271647781133652)\n",
      "('recon_loss:', 0.20864202082157135, 'disc_loss:', 0.46838992834091187, 'gen_loss: ', 0.08344125002622604)\n",
      "('recon_loss:', 0.19241701066493988, 'disc_loss:', 0.4350072145462036, 'gen_loss: ', 0.07227752357721329)\n",
      "('recon_loss:', 0.17553071677684784, 'disc_loss:', 0.4495376646518707, 'gen_loss: ', 0.07193531841039658)\n",
      "('recon_loss:', 0.16461598873138428, 'disc_loss:', 0.4302653670310974, 'gen_loss: ', 0.07291892915964127)\n",
      "('recon_loss:', 0.1823190599679947, 'disc_loss:', 0.4440392553806305, 'gen_loss: ', 0.07355360686779022)\n",
      "('recon_loss:', 0.17321479320526123, 'disc_loss:', 0.3892571032047272, 'gen_loss: ', 0.06149481609463692)\n",
      "('recon_loss:', 0.1625773310661316, 'disc_loss:', 0.37156420946121216, 'gen_loss: ', 0.05954456329345703)\n",
      "('recon_loss:', 0.16798704862594604, 'disc_loss:', 0.3759511709213257, 'gen_loss: ', 0.060176219791173935)\n",
      "('recon_loss:', 0.16963692009449005, 'disc_loss:', 0.36085397005081177, 'gen_loss: ', 0.057529348880052567)\n",
      "('recon_loss:', 0.1623792201280594, 'disc_loss:', 0.35863548517227173, 'gen_loss: ', 0.05744492635130882)\n",
      "('recon_loss:', 0.14820975065231323, 'disc_loss:', 0.35991355776786804, 'gen_loss: ', 0.057409122586250305)\n",
      "('recon_loss:', 0.16849730908870697, 'disc_loss:', 0.3688775897026062, 'gen_loss: ', 0.054686691612005234)\n",
      "('recon_loss:', 0.1488841325044632, 'disc_loss:', 0.3373783528804779, 'gen_loss: ', 0.05000071972608566)\n",
      "('recon_loss:', 0.14530698955059052, 'disc_loss:', 0.3682418465614319, 'gen_loss: ', 0.05551442876458168)\n",
      "('recon_loss:', 0.1338382065296173, 'disc_loss:', 0.36623841524124146, 'gen_loss: ', 0.05810641124844551)\n",
      "('recon_loss:', 0.13566075265407562, 'disc_loss:', 0.3608708679676056, 'gen_loss: ', 0.05638318881392479)\n",
      "('recon_loss:', 0.12833058834075928, 'disc_loss:', 0.3241919279098511, 'gen_loss: ', 0.04917775094509125)\n",
      "('recon_loss:', 0.13122273981571198, 'disc_loss:', 0.33940035104751587, 'gen_loss: ', 0.046774424612522125)\n",
      "('recon_loss:', 0.11186240613460541, 'disc_loss:', 0.31906911730766296, 'gen_loss: ', 0.04786505550146103)\n",
      "('recon_loss:', 0.11570411175489426, 'disc_loss:', 0.32529518008232117, 'gen_loss: ', 0.04577825590968132)\n",
      "('recon_loss:', 0.13054461777210236, 'disc_loss:', 0.3258562684059143, 'gen_loss: ', 0.04573071002960205)\n",
      "('recon_loss:', 0.1038345992565155, 'disc_loss:', 0.31759026646614075, 'gen_loss: ', 0.04446692019701004)\n",
      "('recon_loss:', 0.11869818717241287, 'disc_loss:', 0.2969299256801605, 'gen_loss: ', 0.041125085204839706)\n",
      "('recon_loss:', 0.11825183779001236, 'disc_loss:', 0.29536816477775574, 'gen_loss: ', 0.04211040958762169)\n",
      "('recon_loss:', 0.12556645274162292, 'disc_loss:', 0.30329468846321106, 'gen_loss: ', 0.044215671718120575)\n",
      "('recon_loss:', 0.11293795704841614, 'disc_loss:', 0.2870222330093384, 'gen_loss: ', 0.03864249214529991)\n",
      "('recon_loss:', 0.123336061835289, 'disc_loss:', 0.29563525319099426, 'gen_loss: ', 0.039053115993738174)\n",
      "('recon_loss:', 0.11932530254125595, 'disc_loss:', 0.29311344027519226, 'gen_loss: ', 0.042005911469459534)\n",
      "('recon_loss:', 0.10324201732873917, 'disc_loss:', 0.2981926500797272, 'gen_loss: ', 0.0415467768907547)\n",
      "('recon_loss:', 0.11435157805681229, 'disc_loss:', 0.28729715943336487, 'gen_loss: ', 0.03907708823680878)\n",
      "('recon_loss:', 0.12216068804264069, 'disc_loss:', 0.27956193685531616, 'gen_loss: ', 0.0390043742954731)\n",
      "('recon_loss:', 0.11045312136411667, 'disc_loss:', 0.2842891812324524, 'gen_loss: ', 0.03745458647608757)\n",
      "('recon_loss:', 0.1136692687869072, 'disc_loss:', 0.2819432318210602, 'gen_loss: ', 0.03910564258694649)\n",
      "('recon_loss:', 0.09624884277582169, 'disc_loss:', 0.279243528842926, 'gen_loss: ', 0.040756870061159134)\n",
      "('recon_loss:', 0.1070663183927536, 'disc_loss:', 0.2751925587654114, 'gen_loss: ', 0.03788229450583458)\n",
      "('recon_loss:', 0.09765039384365082, 'disc_loss:', 0.27941641211509705, 'gen_loss: ', 0.03926512971520424)\n",
      "('recon_loss:', 0.0973997637629509, 'disc_loss:', 0.269807368516922, 'gen_loss: ', 0.03649061545729637)\n",
      "('recon_loss:', 0.10797544568777084, 'disc_loss:', 0.2718445360660553, 'gen_loss: ', 0.03774861618876457)\n",
      "('recon_loss:', 0.09916841238737106, 'disc_loss:', 0.2934383451938629, 'gen_loss: ', 0.038707707077264786)\n",
      "('recon_loss:', 0.10985616594552994, 'disc_loss:', 0.2830237150192261, 'gen_loss: ', 0.0401882566511631)\n",
      "('recon_loss:', 0.10111256688833237, 'disc_loss:', 0.28651192784309387, 'gen_loss: ', 0.03984851390123367)\n",
      "('recon_loss:', 0.10703103244304657, 'disc_loss:', 0.2704187035560608, 'gen_loss: ', 0.03389124572277069)\n",
      "('recon_loss:', 0.10795781016349792, 'disc_loss:', 0.255854994058609, 'gen_loss: ', 0.03331470862030983)\n",
      "('recon_loss:', 0.09452655166387558, 'disc_loss:', 0.2736043334007263, 'gen_loss: ', 0.035409435629844666)\n",
      "('recon_loss:', 0.09453075379133224, 'disc_loss:', 0.23876263201236725, 'gen_loss: ', 0.03147289529442787)\n",
      "('recon_loss:', 0.103369802236557, 'disc_loss:', 0.2717844843864441, 'gen_loss: ', 0.0401424765586853)\n",
      "('recon_loss:', 0.10097348690032959, 'disc_loss:', 0.2807866036891937, 'gen_loss: ', 0.03440609201788902)\n",
      "('recon_loss:', 0.10328349471092224, 'disc_loss:', 0.26618102192878723, 'gen_loss: ', 0.03415947034955025)\n",
      "('recon_loss:', 0.10592780262231827, 'disc_loss:', 0.24494759738445282, 'gen_loss: ', 0.030114972963929176)\n",
      "('recon_loss:', 0.10526648908853531, 'disc_loss:', 0.24106992781162262, 'gen_loss: ', 0.03281311318278313)\n",
      "('recon_loss:', 0.08898141235113144, 'disc_loss:', 0.27595996856689453, 'gen_loss: ', 0.040110763162374496)\n",
      "('recon_loss:', 0.10028967261314392, 'disc_loss:', 0.27290546894073486, 'gen_loss: ', 0.03373628482222557)\n",
      "('recon_loss:', 0.13896459341049194, 'disc_loss:', 0.5678232312202454, 'gen_loss: ', 0.31392785906791687)\n",
      "('recon_loss:', 0.08995158970355988, 'disc_loss:', 0.4148251712322235, 'gen_loss: ', 0.08025357872247696)\n",
      "('recon_loss:', 0.08348309993743896, 'disc_loss:', 0.3284793198108673, 'gen_loss: ', 0.06574594229459763)\n",
      "('recon_loss:', 0.10229135304689407, 'disc_loss:', 0.4906490743160248, 'gen_loss: ', 0.0826893076300621)\n",
      "('recon_loss:', 0.09166279435157776, 'disc_loss:', 0.637675940990448, 'gen_loss: ', 0.03766685351729393)\n",
      "('recon_loss:', 0.10238944739103317, 'disc_loss:', 0.47448208928108215, 'gen_loss: ', 0.077534519135952)\n",
      "('recon_loss:', 0.09108530730009079, 'disc_loss:', 0.41831544041633606, 'gen_loss: ', 0.07316295802593231)\n",
      "('recon_loss:', 0.07892227917909622, 'disc_loss:', 0.4094296395778656, 'gen_loss: ', 0.09933687001466751)\n",
      "('recon_loss:', 0.09964529424905777, 'disc_loss:', 0.503633439540863, 'gen_loss: ', 0.06157168000936508)\n",
      "('recon_loss:', 0.09074990451335907, 'disc_loss:', 0.41006144881248474, 'gen_loss: ', 0.08218038082122803)\n",
      "('recon_loss:', 0.0993562713265419, 'disc_loss:', 0.45419856905937195, 'gen_loss: ', 0.05977763235569)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('recon_loss:', 0.08538656681776047, 'disc_loss:', 0.40590590238571167, 'gen_loss: ', 0.05956467613577843)\n",
      "('recon_loss:', 0.09015144407749176, 'disc_loss:', 0.5255401134490967, 'gen_loss: ', 0.06002948060631752)\n"
     ]
    }
   ],
   "source": [
    "Q,P = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_encoded = Q(Variable(torch.cuda.FloatTensor(p_fingerprints)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_np = train_encoded.data.cpu().numpy()\n",
    "#train_encoded_np = np.tile(train_encoded_np,(len(train_encoded_np),1))\n",
    "dist_active = la.norm(train_encoded_np - np.tile(p_active,(no_examples,1)),axis=1)\n",
    "dist_inactive = la.norm(train_encoded_np - np.tile(p_inactive,(no_examples,1)),axis=1)\n",
    "d = dist_active - dist_inactive\n",
    "pred_labels = np.zeros((no_examples,1))\n",
    "pred_labels[d>=0] = 1\n",
    "cf = metrics.confusion_matrix(y_pred=pred_labels,y_true=labels2)\n",
    "print('tn, fp, fn, tp: ',cf.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
