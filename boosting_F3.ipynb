{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "import random\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import pandas as pd\n",
    "#sys.path.append(\"/home/CVShare/Jeni/hts/machine_learning/sampling_with_data_cleaning\")\n",
    "import sampling_with_data_cleaning as sdc\n",
    "from utils import *\n",
    "import sampling_with_data_cleaning as sdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN on normal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21751, 1)\n",
      "[198]\n",
      "[198]\n"
     ]
    }
   ],
   "source": [
    "findex = 3\n",
    "x,y = get_features(findex,train=True,cleaned=False)\n",
    "print y.shape\n",
    "print sum(y)\n",
    "y = y.astype(int)\n",
    "print sum(y)\n",
    "x,y = shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21751 153\n"
     ]
    }
   ],
   "source": [
    "no_ex,ip_dim = x.shape\n",
    "print no_ex,ip_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c_mlp,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,500)\n",
    "        self.l2 = nn.Linear(500,500)\n",
    "        self.l3 = nn.Linear(500,500)\n",
    "        self.l4 = nn.Linear(500,100)\n",
    "        self.l5 = nn.Linear(100,30)\n",
    "        self.l6 = nn.Linear(30,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        #x = F.leaky_relu(self.l3(x))\n",
    "        x = F.leaky_relu(self.l4(x))\n",
    "        x = F.leaky_relu(self.l5(x))\n",
    "        x = (self.l6(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685879230499\n",
      "0.446011573076\n",
      "0.569152355194\n",
      "0.786725580692\n",
      "0.634990572929\n",
      "0.669770002365\n",
      "0.699559390545\n",
      "0.542193293571\n",
      "0.664620816708\n",
      "0.375814735889\n",
      "0.721620798111\n",
      "0.600204825401\n",
      "0.365251630545\n",
      "0.559467434883\n",
      "0.701574265957\n",
      "0.578196406364\n",
      "0.398209124804\n",
      "0.543348908424\n",
      "0.612983942032\n",
      "0.76937276125\n",
      "0.644605755806\n",
      "0.559027433395\n",
      "0.825178563595\n",
      "0.557818353176\n",
      "0.595799565315\n",
      "0.77188795805\n",
      "0.602504014969\n",
      "0.684322416782\n",
      "0.497777789831\n",
      "0.714362204075\n",
      "0.388214558363\n",
      "0.597586750984\n",
      "0.744971692562\n",
      "0.446371465921\n",
      "0.522579789162\n",
      "0.625858426094\n",
      "0.405963808298\n",
      "0.632392287254\n",
      "0.624153852463\n",
      "0.608142197132\n",
      "0.348951101303\n",
      "0.39599531889\n",
      "0.325050652027\n",
      "0.747975230217\n",
      "0.70149743557\n",
      "0.421750456095\n",
      "0.730386972427\n",
      "0.796245515347\n",
      "0.619739353657\n",
      "0.484712660313\n",
      "0.500463843346\n",
      "0.745280325413\n",
      "0.442388683558\n",
      "0.329340785742\n",
      "0.757700681686\n",
      "0.559502124786\n",
      "0.346723794937\n",
      "0.360006570816\n",
      "0.419556349516\n",
      "0.414009004831\n",
      "0.750950694084\n",
      "0.782113671303\n",
      "0.407918602228\n",
      "0.33359760046\n",
      "0.390164524317\n",
      "0.331143289804\n",
      "0.423135668039\n",
      "0.553063571453\n",
      "0.553684651852\n",
      "0.547491729259\n",
      "0.500586569309\n",
      "1.00622940063\n",
      "0.543929517269\n",
      "0.617136776447\n",
      "0.469419538975\n",
      "0.433160841465\n",
      "0.480019807816\n",
      "0.408072650433\n",
      "0.377443611622\n",
      "0.411126881838\n",
      "0.334315657616\n",
      "0.383771181107\n",
      "0.279824346304\n"
     ]
    }
   ],
   "source": [
    "max_percent = 0.5\n",
    "min_fp = no_ex*0.2\n",
    "#for i in range(1,6):\n",
    "if(1==1):\n",
    "    val_iter = 0\n",
    "    \n",
    "   \n",
    "    weights_array = [80]\n",
    "    #weights_array = np.linspace(10,40,10)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(2500):\n",
    "            \n",
    "            ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "            xtrain,ytrain = get_train_batch(x,y,batch_size=200,indices=ind)\n",
    "            \n",
    "            model_op = mymlp(xtrain)\n",
    "           \n",
    "            loss = criterion(model_op,ytrain)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if(ep%30==29):\n",
    "                print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training over\n",
      "('tn, fp, fn, tp: ', array([18494,  3059,    54,   144]))\n"
     ]
    }
   ],
   "source": [
    "if(1==1):\n",
    "    if(1==1):\n",
    "        ## After training check on ORINGAL data\n",
    "        print('Training over')\n",
    "        xch = Variable(torch.cuda.FloatTensor(x))\n",
    "        train_op = mymlp(xch)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "      \n",
    "        cf = metrics.confusion_matrix(y,pred_labels).ravel()\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        percent = float(float(tp)/float(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + '/boost_clean_a' + str(findex)\n",
    "torch.save(mymlp.state_dict(),model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Just checking on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp: ', array([4636,  752,   44,    6]))\n"
     ]
    }
   ],
   "source": [
    "xtest,ytest = get_features(findex,train=False)\n",
    "ytest = ytest.astype(int)\n",
    "xtest = Variable(torch.cuda.FloatTensor(xtest))\n",
    "testmodel = c_mlp().cuda()\n",
    "testmodel.load_state_dict(torch.load(model_path))\n",
    "test_op = testmodel(xtest).cpu().data.numpy()\n",
    "test_op = np.argmax(test_op,axis=1)\n",
    "cf = metrics.confusion_matrix(ytest,test_op).ravel()\n",
    "[tn,fp,fn,tp] = cf\n",
    "print('tn, fp, fn, tp: ',cf)\n",
    "percent = float(float(tp)/float(tp+fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out +ve samples on which this fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 1)\n",
      "(21697, 153) (21697,)\n"
     ]
    }
   ],
   "source": [
    "#y_hack = np.zeros(y.shape)\n",
    "#y_hack[y==1] = 5\n",
    "y = y.reshape(y.shape[0],)\n",
    "next_t = y-pred_labels  #next_ind will be 1 for which pred_labels have predicted inactive\n",
    "next_ind = np.argwhere(next_t == 1)\n",
    "print next_ind.shape\n",
    "xtmp = np.delete(x,next_ind,axis=0)\n",
    "ytmp = np.delete(y,next_ind,axis=0)\n",
    "print xtmp.shape, ytmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Adding 561 new samples\n",
      "removing 136 samples\n",
      "[16193  1987  1479  6690 13924 14802 15124 17521 13968 20346  3235 20758\n",
      " 10732  2533 11345  1343  2949 18548 13196 17520 13962  9450 10316 16289\n",
      " 19434  7116  4530 11473  7228  2611  8349  9909 13195  8458 12287  2802\n",
      " 12204  7781 18103  4331  9577 12448 19006 20948   482  8806  5811 19851\n",
      " 21414  6382  3328 16210  6473 18743 21356  2089  1486 18001  9366  3221\n",
      " 16366 16372 10818  1120 12670 10942 11255  7903  9488  5598 11123 16604\n",
      "   986  6193  4746 17932 19223 13517 13914  7394  2941 14852 13811 10864\n",
      "  8969 19960 15715  4944  9851 14707  5252  2215 15618 15197  4215 17941\n",
      " 16118  3035 16732   152  5550 21383  2208  1923  5780  7878 12480 20285\n",
      " 12593 11842 15845  3371 13545  4362  1869  9052  4937 17860 21363 17148\n",
      "  2308 11248  2408  4482 12291 20023  7176 19634 12659 16100  4510 17635\n",
      "  4317  1372  7243 20002]\n"
     ]
    }
   ],
   "source": [
    "xnew,ynew = sdc.clean_data(xtmp,ytmp,k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ynew = ynew.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.690024971962\n",
      "0.659096002579\n",
      "0.649185717106\n",
      "0.697277665138\n",
      "0.619897127151\n",
      "0.625029802322\n",
      "0.620812773705\n",
      "0.597567796707\n",
      "0.476067572832\n",
      "0.510105192661\n",
      "0.496998459101\n",
      "0.473946452141\n",
      "0.429212719202\n",
      "0.465233772993\n",
      "0.481321334839\n",
      "0.492876827717\n",
      "0.398086309433\n",
      "0.380917936563\n",
      "0.366058886051\n",
      "0.366743952036\n",
      "0.390680968761\n",
      "0.371139794588\n",
      "0.400928735733\n",
      "0.415012687445\n",
      "0.356770902872\n",
      "0.446359992027\n",
      "0.521150827408\n",
      "0.402404338121\n",
      "0.335506051779\n",
      "0.30193015933\n",
      "0.413660109043\n",
      "0.304487496614\n",
      "0.316591084003\n",
      "0.204665720463\n",
      "0.296916335821\n",
      "0.276086658239\n",
      "0.269078522921\n",
      "0.301186919212\n",
      "0.320402294397\n",
      "0.339456021786\n",
      "0.190005391836\n",
      "0.286020666361\n",
      "0.447492718697\n",
      "0.314222216606\n",
      "0.448688834906\n",
      "0.211913913488\n",
      "0.283905953169\n",
      "0.19592911005\n",
      "0.25098913908\n",
      "0.215023517609\n",
      "0.201283320785\n",
      "0.190017744899\n",
      "0.217289701104\n",
      "0.284295111895\n",
      "0.186991348863\n",
      "0.218621969223\n",
      "0.163592860103\n",
      "0.267327010632\n",
      "0.185389980674\n",
      "0.223917841911\n",
      "0.238125860691\n",
      "0.155365556479\n",
      "0.285292088985\n",
      "0.205041989684\n",
      "0.24391721189\n",
      "0.288536757231\n",
      "0.205066859722\n",
      "0.175596535206\n",
      "0.24635617435\n",
      "0.176430657506\n",
      "0.273597478867\n",
      "0.168747216463\n",
      "0.214128553867\n",
      "0.197431981564\n",
      "0.133868247271\n",
      "0.16510745883\n",
      "0.151833131909\n",
      "0.20004183054\n",
      "0.226220190525\n",
      "0.179508417845\n",
      "0.143174514174\n",
      "0.142811700702\n",
      "0.167909100652\n"
     ]
    }
   ],
   "source": [
    "max_percent = 0.5\n",
    "no_ex = xnew.shape[0]\n",
    "min_fp = no_ex*0.2\n",
    "#for i in range(1,6):\n",
    "if(1==1):\n",
    "    val_iter = 0\n",
    "    \n",
    "   \n",
    "    weights_array = [50]\n",
    "    #weights_array = np.linspace(10,40,10)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp_b = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp_b.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(2500):\n",
    "            \n",
    "            ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "            xtrain,ytrain = get_train_batch(xnew,ynew,batch_size=150,indices=ind)\n",
    "            \n",
    "            model_op = mymlp_b(xtrain)\n",
    "           \n",
    "            loss = criterion(model_op,ytrain)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if(ep%30==29):\n",
    "                print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training over\n",
      "('tn, fp, fn, tp: ', array([18900,  2517,     4,   701]))\n"
     ]
    }
   ],
   "source": [
    "if(1==1):\n",
    "    if(1==1):\n",
    "        ## After training check on ORINGAL data\n",
    "        print('Training over')\n",
    "        xch = Variable(torch.cuda.FloatTensor(xnew))\n",
    "        train_op = mymlp_b(xch)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "      \n",
    "        cf = metrics.confusion_matrix(ynew,pred_labels).ravel()\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        percent = float(float(tp)/float(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + '/boost_clean_b' + str(findex)\n",
    "torch.save(mymlp_b.state_dict(),model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp: ', array([4451,  937,   43,    7]))\n"
     ]
    }
   ],
   "source": [
    "## Test after training on both\n",
    "xtest,ytest = get_features(findex,train=False)\n",
    "xtest = Variable(torch.cuda.FloatTensor(xtest))\n",
    "opa = mymlp(xtest).data.cpu().numpy()\n",
    "pred1 = np.argmax(opa,axis=1)\n",
    "opb = mymlp_b(xtest).data.cpu().numpy()\n",
    "pred2 = np.argmax(opb,axis=1)\n",
    "#opc = mymlp_c(xtest).data.cpu().numpy()\n",
    "#pred3 = np.argmax(opc,axis=1)\n",
    "\n",
    "final_pred = pred1 + pred2# + pred3\n",
    "final_pred[final_pred>0] = 1\n",
    "\n",
    "cf = metrics.confusion_matrix(ytest,final_pred).ravel()\n",
    "[tn,fp,fn,tp] = cf\n",
    "print('tn, fp, fn, tp: ',cf)\n",
    "percent = float(float(tp)/float(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp: ', array([4738,  650,   44,    6]))\n"
     ]
    }
   ],
   "source": [
    "cf = metrics.confusion_matrix(ytest,pred2).ravel()\n",
    "[tn,fp,fn,tp] = cf\n",
    "print('tn, fp, fn, tp: ',cf)\n",
    "percent = float(float(tp)/float(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "(22118, 153) (22118,)\n"
     ]
    }
   ],
   "source": [
    "ynew = ynew.reshape(ynew.shape[0],)\n",
    "next_t = ynew-pred_labels  #next_ind will be 1 for which pred_labels have predicted inactive\n",
    "next_ind = np.argwhere(next_t == 1)\n",
    "print next_ind.shape\n",
    "xtmp = np.delete(xnew,next_ind,axis=0)\n",
    "ytmp = np.delete(ynew,next_ind,axis=0)\n",
    "print xtmp.shape, ytmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Adding 44 new samples\n",
      "removing 43 samples\n",
      "[16704 11855  3766 16138 16645 11229 11318  6378 12606  1487   571  1853\n",
      " 19955   656 13815  5451  8123  9600 15659   302 13427  7267  2427  8920\n",
      " 15308 21485 17335  3827 17674  4555 12341  9652 16946 12172 19762  9802\n",
      " 19166  5808 12209 14698  1366   540  5463]\n"
     ]
    }
   ],
   "source": [
    "xnew2,ynew2 = sdc.clean_data(xtmp,ytmp,k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ynew2 = ynew2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.617771208286\n",
      "0.638677358627\n",
      "0.514743149281\n",
      "0.65961766243\n",
      "0.723265886307\n",
      "0.631478786469\n",
      "0.475096136332\n",
      "0.477815061808\n",
      "0.518111586571\n",
      "0.493030160666\n",
      "0.343472272158\n",
      "0.560192525387\n",
      "0.418295860291\n",
      "0.419747292995\n",
      "0.331629127264\n",
      "0.395811647177\n",
      "0.574852585793\n",
      "0.332928925753\n",
      "0.297876119614\n",
      "0.394538342953\n",
      "0.285408973694\n",
      "0.261791020632\n",
      "0.395504117012\n",
      "0.314911395311\n",
      "0.27667042613\n",
      "0.262719601393\n",
      "0.437910884619\n",
      "0.335833907127\n",
      "0.312443464994\n",
      "0.266688019037\n",
      "0.235613286495\n",
      "0.322097867727\n",
      "0.318823128939\n",
      "0.378756195307\n",
      "0.376499682665\n",
      "0.313548266888\n",
      "0.292883098125\n",
      "0.286784410477\n",
      "0.379867345095\n",
      "0.173062860966\n",
      "0.235538512468\n",
      "0.247829288244\n",
      "0.178392648697\n",
      "0.302066624165\n",
      "0.192500695586\n",
      "0.192084982991\n",
      "0.203761994839\n",
      "0.248040542006\n",
      "0.216051757336\n",
      "0.253418773413\n",
      "0.241273909807\n",
      "0.239640802145\n",
      "0.19656817615\n",
      "0.267376303673\n",
      "0.153563529253\n",
      "0.180549740791\n",
      "0.255450457335\n",
      "0.164823159575\n",
      "0.221805095673\n",
      "0.16206240654\n",
      "0.125766918063\n",
      "0.125417143106\n",
      "0.204280033708\n",
      "0.176533505321\n",
      "0.157820001245\n",
      "0.150524705648\n"
     ]
    }
   ],
   "source": [
    "max_percent = 0.5\n",
    "no_ex = xnew2.shape[0]\n",
    "min_fp = no_ex*0.2\n",
    "#for i in range(1,6):\n",
    "if(1==1):\n",
    "    val_iter = 0\n",
    "    \n",
    "   \n",
    "    weights_array = [50]\n",
    "    #weights_array = np.linspace(10,40,10)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp_c = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp_c.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(2000):\n",
    "            \n",
    "            ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "            xtrain,ytrain = get_train_batch(xnew2,ynew2,batch_size=150,indices=ind)\n",
    "            \n",
    "            model_op = mymlp_c(xtrain)\n",
    "           \n",
    "            loss = criterion(model_op,ytrain)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if(ep%30==29):\n",
    "                print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + '/boost_clean_b' + str(findex)\n",
    "torch.save(mymlp_c.state_dict(),model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp: ', array([4373, 1015,   40,   10]))\n"
     ]
    }
   ],
   "source": [
    "## Test after training on both\n",
    "xtest,ytest = get_features(findex,train=False)\n",
    "xtest = Variable(torch.cuda.FloatTensor(xtest))\n",
    "opa = mymlp(xtest).data.cpu().numpy()\n",
    "pred1 = np.argmax(opa,axis=1)\n",
    "opb = mymlp_b(xtest).data.cpu().numpy()\n",
    "pred2 = np.argmax(opb,axis=1)\n",
    "opc = mymlp_c(xtest).data.cpu().numpy()\n",
    "pred3 = np.argmax(opc,axis=1)\n",
    "\n",
    "final_pred = pred1 + pred2 + pred3\n",
    "final_pred[final_pred>0] = 1\n",
    "\n",
    "cf = metrics.confusion_matrix(ytest,final_pred).ravel()\n",
    "[tn,fp,fn,tp] = cf\n",
    "print('tn, fp, fn, tp: ',cf)\n",
    "percent = float(float(tp)/float(tp+fn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
