{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "import random\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('screen_info.txt','rb') as fl:\n",
    "    t = pickle.load(fl)\n",
    "fnames = t[0]\n",
    "totf = t[1]\n",
    "binf = t[2]\n",
    "runfile = 1\n",
    "fname = fnames[runfile]\n",
    "bf = binf[runfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47831, 122)\n",
      "['0' '0' '0' '0']\n",
      "(47831, 122)\n",
      "('total no of 1s', 256419)\n",
      "('total no of 0s', 5578963)\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + '/bioassay-datasets/'\n",
    "p_fingerprints = []\n",
    "c_fingerprints = []\n",
    "labels = []\n",
    "\n",
    "with open(path+fname+'red_train.csv') as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        p_fingerprints.append(row[:bf])\n",
    "        c_fingerprints.append(row[bf:-1])\n",
    "        labels.append(row[-1])\n",
    "p_fingerprints = np.asarray(p_fingerprints)[1:]\n",
    "c_fingerprints = np.asarray(c_fingerprints)[1:]\n",
    "print(p_fingerprints.shape)\n",
    "print(p_fingerprints[1:5,-1])\n",
    "\n",
    "p_fingerprints = p_fingerprints.astype(int)\n",
    "c_fingerprints = c_fingerprints.astype(float)\n",
    "(no_examples , ip_dim) = p_fingerprints.shape\n",
    "labels = labels[1:]\n",
    "print(no_examples,ip_dim)\n",
    "print(\"total no of 1s\",np.sum(p_fingerprints))\n",
    "print(\"total no of 0s\",no_examples*ip_dim-np.sum(p_fingerprints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels2 = np.zeros((len(labels),1))\n",
    "for i,l in enumerate(labels):\n",
    "    if l=='Active':\n",
    "        labels2[i] = 1\n",
    "    else:\n",
    "        labels2[i] = 0\n",
    "labels2 = labels2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\n"
     ]
    }
   ],
   "source": [
    "no_active_ele = (sum(labels2))\n",
    "print(no_active_ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47831, 1)\n"
     ]
    }
   ],
   "source": [
    "print labels2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_embedded = TSNE(n_components=2).fit_transform(p_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 6)) \n",
    "# labels2 = labels2.astype(float)\n",
    "# labels2 = labels2.reshape(no_examples,)\n",
    "# plt.scatter(X_embedded[:, 0], X_embedded[:, 1],c = labels2)#map=plt.cm.BrOr)\n",
    "# #plt.colorbar()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 120\n",
    "\n",
    "z_dim = 30\n",
    "comb_dim = ip_dim + z_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Encoder\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,500)\n",
    "        self.l2 = nn.Linear(500,500)\n",
    "        #self.l3 = nn.Linear(500,500)\n",
    "        self.l4 = nn.Linear(500,z_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        #x = F.leaky_relu(self.l3(x))\n",
    "        x = (self.l4(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "### Decoder\n",
    "\n",
    "class decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder,self).__init__()\n",
    "        self.l1 = nn.Linear(z_dim,500)\n",
    "        self.l2 = nn.Linear(500,500)\n",
    "        #self.l3 = nn.Linear(500,500)\n",
    "        self.l4 = nn.Linear(500,ip_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        #x = F.leaky_relu(self.l3(x))\n",
    "        x = F.tanh(self.l4(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "###  Discriminator\n",
    "\n",
    "class disc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(disc,self).__init__()\n",
    "        self.l1 = nn.Linear(z_dim,100)\n",
    "        #self.l2 = nn.Linear(100,100)\n",
    "        self.l3 = nn.Linear(100,100)\n",
    "        self.l4 = nn.Linear(100,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.elu(self.l3(x))\n",
    "        x = F.sigmoid(self.l4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.arange(no_examples)\n",
    "np.random.shuffle(ind)\n",
    "p_fingerprints = p_fingerprints[ind]\n",
    "c_fingerprints = c_fingerprints[ind]\n",
    "labels2 = labels2[ind]\n",
    "labels2 = labels2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_batch(batch_size,validation_iter=0,binary=True,high_pos=False):\n",
    "    \n",
    "    if validation_iter == 0: #no validation\n",
    "        curr_data_size = no_examples\n",
    "        labels_train = labels2\n",
    "        #print labels_train.shape\n",
    "        p_train_data = p_fingerprints\n",
    "    else:\n",
    "        curr_data_size = int(no_examples*0.8)\n",
    "        interval_size = int(no_examples*0.2)\n",
    "        \n",
    "        if(val_iter==1):\n",
    "            s_ind1 = int((validation_iter)*interval_size)\n",
    "            end_ind1 = int((validation_iter+1)*interval_size)\n",
    "            s_ind2 = int((validation_iter + 1) * interval_size)\n",
    "            end_ind2 = int(no_examples)\n",
    "        else:\n",
    "            s_ind1 = 0\n",
    "            end_ind1 = int((validation_iter)*interval_size)\n",
    "            s_ind2 = int((validation_iter + 1) * interval_size)\n",
    "            end_ind2 = int(no_examples)\n",
    "        \n",
    "        #print(\"train_ind \",s_ind1,end_ind1,s_ind2,end_ind2)\n",
    "        indices = range(s_ind1,end_ind1) + range(s_ind2,end_ind2)\n",
    "        c_train_data = c_fingerprints[indices]\n",
    "        p_train_data = p_fingerprints[indices]\n",
    "        labels_train = labels2[indices]\n",
    "    samples = np.random.randint(low=0,high=curr_data_size,size=(batch_size,1))\n",
    "     \n",
    "\n",
    "    if binary == True:\n",
    "        train_batch = p_train_data[samples].reshape(batch_size,ip_dim)\n",
    "        train_batch = train_batch.astype(int)\n",
    "    else:\n",
    "        train_batch = c_fingerprints[samples].reshape(batch_size,ip_dim2)\n",
    "        train_batch = train_batch.astype(float)\n",
    "    \n",
    "    train_batch = torch.cuda.FloatTensor(train_batch)\n",
    "    train_batch = Variable(train_batch,requires_grad=False).cuda()\n",
    "    target = Variable(torch.cuda.LongTensor(labels_train[samples]),requires_grad=False)\n",
    "    target = target.view(batch_size,)\n",
    "    return train_batch,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_data(validation_iter,binary = True):\n",
    "    interval_size = int(no_examples)*0.2\n",
    "    s_ind = int((validation_iter-1)*interval_size)\n",
    "    e_ind = int((validation_iter) * interval_size)\n",
    "    if(binary==True):\n",
    "        train_data = p_fingerprints[s_ind:e_ind]\n",
    "    else:\n",
    "        train_data = c_fingerprints[s_ind:e_ind]\n",
    "    labels_val = labels2[s_ind:e_ind]   \n",
    "    #print(\"val ind \",s_ind,e_ind)\n",
    "    #print train_data.shape, labels_val.shape\n",
    "    return Variable(torch.cuda.FloatTensor(train_data)),labels_val  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = decoder().cuda()\n",
    "E = encoder().cuda()\n",
    "D = disc().cuda()\n",
    "\n",
    "def clear_grad():\n",
    "    G.zero_grad()\n",
    "    E.zero_grad()\n",
    "    D.zero_grad()\n",
    "\n",
    "E_solver = optim.Adam(E.parameters(),lr = 1e-3)\n",
    "G_solver = optim.Adam(G.parameters(),lr = 1e-3)\n",
    "D_solver = optim.Adam(D.parameters(),lr = 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_true_z(label):\n",
    "    \n",
    "    noise = np.random.randn(batch_size,z_dim)\n",
    "    label = label.numpy().reshape(batch_size,1)\n",
    "    #print noise.shape,label.shape\n",
    "    z = 0.5*noise + label*10\n",
    "    z = Variable(torch.FloatTensor(z).cuda())\n",
    "    return z\n",
    "    #z = torch.add(noise,value=1,other=label)\n",
    "    #z = Variable(z.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043869368732 1.38004851341 0.63739079237\n",
      "0.0452127121389 1.3779116869 0.63739079237\n",
      "0.0380492247641 1.37320196629 0.63739079237\n",
      "0.0399157963693 1.35718142986 0.605000078678\n",
      "0.0385810993612 1.35515403748 0.605000078678\n",
      "0.0371844656765 1.35437762737 0.605000078678\n",
      "0.0411791987717 1.34697973728 0.592301905155\n",
      "0.0392143502831 1.35802185535 0.592301905155\n",
      "0.0350101329386 1.34695827961 0.592301905155\n",
      "0.0366548411548 1.34632635117 0.589863657951\n",
      "0.0403345562518 1.37081861496 0.589863657951\n",
      "0.0369305424392 1.35806524754 0.589863657951\n",
      "0.0382278375328 1.33548855782 0.595479726791\n",
      "0.0358482450247 1.36955225468 0.595479726791\n",
      "0.0359015911818 1.35907411575 0.595479726791\n",
      "0.0323961339891 1.29697775841 0.645729243755\n",
      "0.0353337079287 1.33092427254 0.645729243755\n",
      "0.0350226275623 1.28378546238 0.645729243755\n",
      "0.0352188125253 1.24766612053 0.732438266277\n",
      "0.0341480113566 1.24348247051 0.732438266277\n",
      "0.0373438335955 1.20104777813 0.732438266277\n",
      "0.035602774471 1.10204482079 0.91320925951\n",
      "0.0353230386972 1.12848925591 0.91320925951\n",
      "0.0344254933298 1.06755495071 0.91320925951\n",
      "0.0337026752532 0.985401809216 1.14497172832\n",
      "0.0342923849821 0.994896113873 1.14497172832\n",
      "0.034818097949 0.974516749382 1.14497172832\n",
      "0.0337451547384 0.917459726334 1.27849364281\n",
      "0.036892734468 1.01000213623 1.27849364281\n",
      "0.0400582961738 0.961210310459 1.27849364281\n",
      "0.0367952436209 0.937127947807 1.15479409695\n",
      "0.0352078452706 1.07944953442 1.15479409695\n",
      "0.0359704121947 1.05755031109 1.15479409695\n",
      "0.0327080897987 1.07687056065 0.982217490673\n",
      "0.0398790687323 1.13322460651 0.982217490673\n",
      "0.0384709089994 1.14543807507 0.982217490673\n",
      "0.0345269702375 1.14968931675 0.889144003391\n",
      "0.0397291518748 1.2566075325 0.889144003391\n",
      "0.0325272381306 1.25388860703 0.889144003391\n",
      "0.0359270758927 1.19218957424 0.864590525627\n",
      "0.0350302755833 1.24675500393 0.864590525627\n",
      "0.036702323705 1.17774856091 0.864590525627\n",
      "0.0388173498213 1.12854468822 0.947963058949\n",
      "0.0347907356918 1.19722223282 0.947963058949\n",
      "0.0359383039176 1.10165512562 0.947963058949\n",
      "0.0341259390116 1.04106020927 1.06623995304\n",
      "0.0368854962289 1.12424123287 1.06623995304\n",
      "0.0342745408416 1.07520270348 1.06623995304\n",
      "0.0339812673628 1.05698871613 1.03704285622\n",
      "0.0354961045086 1.13927066326 1.03704285622\n",
      "0.0334451533854 1.14057099819 1.03704285622\n",
      "0.0371303074062 1.12101316452 0.845183908939\n",
      "0.034401576966 1.39843332767 0.845183908939\n",
      "0.0287499912083 1.41708898544 0.845183908939\n",
      "0.0330613218248 1.47756636143 0.530391454697\n",
      "0.036239925772 1.90962445736 0.530391454697\n",
      "0.0333129912615 1.98225295544 0.530391454697\n",
      "0.0334153063595 1.97577142715 0.328756809235\n",
      "0.0376365706325 2.48332834244 0.328756809235\n",
      "0.0350841246545 2.41273856163 0.328756809235\n",
      "0.0368705429137 2.47249317169 0.210395336151\n",
      "0.034031227231 2.94184041023 0.210395336151\n",
      "0.036274176091 2.91331505775 0.210395336151\n",
      "0.036177970469 2.74388980865 0.196410164237\n",
      "0.0357875227928 3.11334943771 0.196410164237\n",
      "0.0341949388385 2.83545708656 0.196410164237\n",
      "0.0334944315255 2.68474078178 0.240825206041\n",
      "0.0335285440087 2.80534601212 0.240825206041\n",
      "0.0338666960597 2.57377672195 0.240825206041\n",
      "0.0332104675472 2.25555348396 0.396232634783\n",
      "0.0306181292981 2.28294229507 0.396232634783\n",
      "0.0329889394343 2.15454554558 0.396232634783\n",
      "0.0342538617551 1.82007408142 0.653043150902\n",
      "0.0355450697243 2.03162145615 0.653043150902\n",
      "0.0355385243893 1.78870725632 0.653043150902\n",
      "0.0364856794477 1.55422449112 0.98367869854\n",
      "0.0346474051476 1.68556165695 0.98367869854\n",
      "0.0360494740307 1.53074061871 0.98367869854\n",
      "0.0367626771331 1.47114539146 1.04082810879\n",
      "0.0340575017035 1.90501892567 1.04082810879\n",
      "0.0357915461063 1.87126934528 1.04082810879\n",
      "0.0343542397022 1.76929807663 0.69552642107\n",
      "0.0353767722845 2.48703336716 0.69552642107\n",
      "0.0359229929745 2.34612727165 0.69552642107\n",
      "0.0372905433178 2.18381285667 0.591036200523\n",
      "0.0340880677104 2.57357144356 0.591036200523\n",
      "0.036520127207 2.26912021637 0.591036200523\n",
      "0.0326851941645 1.85049235821 0.969821274281\n",
      "0.037842489779 2.11567640305 0.969821274281\n",
      "0.0387616530061 1.77024757862 0.969821274281\n",
      "0.0369458459318 1.43849408627 1.62969219685\n",
      "0.0352354571223 1.71355032921 1.62969219685\n",
      "0.0371926650405 1.55988848209 1.62969219685\n",
      "0.0352846421301 1.31014442444 1.89136731625\n",
      "0.0363010801375 1.52050673962 1.89136731625\n",
      "0.035522993654 1.40291750431 1.89136731625\n",
      "0.0348172932863 1.27993535995 2.23395848274\n",
      "0.036732442677 1.48693013191 2.23395848274\n",
      "0.0330255068839 1.27158236504 2.23395848274\n",
      "0.0354557074606 1.42323231697 2.2761452198\n",
      "0.0353512838483 1.36831927299 2.2761452198\n",
      "0.0370310172439 1.3433508873 2.2761452198\n",
      "0.0335208438337 1.27204918861 2.10104346275\n",
      "0.0335926152766 1.38173747063 2.10104346275\n",
      "0.0353767760098 1.39675557613 2.10104346275\n",
      "0.0342398360372 1.27115499973 1.97401666641\n",
      "0.0352304130793 1.44677233696 1.97401666641\n",
      "0.0343516431749 1.32647848129 1.97401666641\n",
      "0.0343879573047 1.27482581139 1.96050965786\n",
      "0.0346310921013 1.26167225838 1.96050965786\n",
      "0.0327510945499 1.41889977455 1.96050965786\n",
      "0.031611122191 1.31080389023 2.05634140968\n",
      "0.036535680294 1.21090745926 2.05634140968\n",
      "0.0350173078477 1.32820010185 2.05634140968\n",
      "0.0342599153519 1.2016197443 1.94485938549\n",
      "0.0350281894207 1.14383161068 1.94485938549\n",
      "0.0404243320227 1.18385910988 1.94485938549\n",
      "0.0365672446787 1.17098987103 1.80073571205\n",
      "0.0362106114626 1.1574870348 1.80073571205\n",
      "0.0373827032745 1.1772633791 1.80073571205\n",
      "0.0348384454846 1.21569776535 1.44324815273\n",
      "0.0380968675017 1.19674372673 1.44324815273\n",
      "0.0360120944679 1.2184278965 1.44324815273\n",
      "0.0398383028805 1.22623467445 1.19517171383\n",
      "0.0372701063752 1.28393852711 1.19517171383\n",
      "0.0394062884152 1.25550472736 1.19517171383\n",
      "0.038007453084 1.31604874134 0.947560012341\n",
      "0.0408695526421 1.42603719234 0.947560012341\n",
      "0.0364405848086 1.39152145386 0.947560012341\n",
      "0.0352108888328 1.45483624935 0.761374533176\n",
      "0.0370853878558 1.5727584362 0.761374533176\n",
      "0.0360461696982 1.4834741354 0.761374533176\n",
      "0.0363601483405 1.53892588615 0.629731297493\n",
      "0.0370868109167 1.69337213039 0.629731297493\n",
      "0.0379041992128 1.55493497849 0.629731297493\n",
      "0.0368699096143 1.61331307888 0.559272229671\n",
      "0.0363078676164 1.61650276184 0.559272229671\n",
      "0.0348995402455 1.60048830509 0.559272229671\n",
      "0.0388791076839 1.62369072437 0.523029386997\n",
      "0.0370542630553 1.6821770668 0.523029386997\n",
      "0.0384229756892 1.63303494453 0.523029386997\n",
      "0.0346268825233 1.65682983398 0.488319814205\n",
      "0.0387714728713 1.69237542152 0.488319814205\n",
      "0.0363164842129 1.68664860725 0.488319814205\n",
      "0.0358217582107 1.64330363274 0.482190340757\n",
      "0.0377635061741 1.71080052853 0.482190340757\n",
      "0.041254915297 1.69649815559 0.482190340757\n",
      "0.036507576704 1.71062469482 0.464902311563\n",
      "0.0368227809668 1.67324244976 0.464902311563\n",
      "0.0371024310589 1.75321042538 0.464902311563\n",
      "0.0348761081696 1.64836263657 0.461125016212\n",
      "0.0355255976319 1.69111514091 0.461125016212\n",
      "0.0379445888102 1.77568638325 0.461125016212\n",
      "0.0334956459701 1.61949837208 0.465117752552\n",
      "0.036960631609 1.61362993717 0.465117752552\n",
      "0.0340293161571 1.61260962486 0.465117752552\n",
      "0.0362379737198 1.61204361916 0.462326973677\n",
      "0.0351163782179 1.62547802925 0.462326973677\n",
      "0.0328572615981 1.60729563236 0.462326973677\n",
      "0.0354745574296 1.59267354012 0.469753324986\n",
      "0.0347289144993 1.60225319862 0.469753324986\n",
      "0.0358544774354 1.59482574463 0.469753324986\n",
      "0.0358618162572 1.56651651859 0.475185275078\n",
      "0.0324326679111 1.54649090767 0.475185275078\n",
      "0.0390250310302 1.56609535217 0.475185275078\n",
      "0.0335384756327 1.52185189724 0.48447561264\n",
      "0.0364776700735 1.53343844414 0.48447561264\n",
      "0.0346142090857 1.50894093513 0.48447561264\n",
      "0.0339793786407 1.52008020878 0.496191948652\n",
      "0.0326732732356 1.51401901245 0.496191948652\n",
      "0.0326899811625 1.50935697556 0.496191948652\n",
      "0.0329051837325 1.47307062149 0.513126373291\n",
      "0.0307347457856 1.48003315926 0.513126373291\n",
      "0.0329532325268 1.45622944832 0.513126373291\n",
      "0.0351582467556 1.46397471428 0.516372740269\n",
      "0.034831661731 1.44877421856 0.516372740269\n",
      "0.0368482507765 1.4547470808 0.516372740269\n",
      "0.0324335582554 1.42407548428 0.534592866898\n",
      "0.0346104800701 1.43075525761 0.534592866898\n",
      "0.0339881964028 1.41074109077 0.534592866898\n",
      "0.0341027975082 1.39567136765 0.549499630928\n",
      "0.0343355089426 1.41031777859 0.549499630928\n",
      "0.0362494960427 1.39751935005 0.549499630928\n",
      "0.0347724556923 1.37604105473 0.573577702045\n",
      "0.0334844738245 1.39065444469 0.573577702045\n",
      "0.0366221815348 1.3637650013 0.573577702045\n",
      "0.0337660983205 1.34971570969 0.600907325745\n",
      "0.0343287289143 1.35468363762 0.600907325745\n",
      "0.0359597168863 1.33438825607 0.600907325745\n",
      "0.0370725654066 1.34100520611 0.636276006699\n",
      "0.0351458080113 1.31461441517 0.636276006699\n",
      "0.0360928922892 1.30190682411 0.636276006699\n",
      "0.0326500944793 1.27528607845 0.693892359734\n",
      "0.0353683196008 1.28623044491 0.693892359734\n",
      "0.0356332622468 1.25878489017 0.693892359734\n",
      "0.0332393161952 1.24144899845 0.752750575542\n",
      "0.0338994041085 1.24445414543 0.752750575542\n",
      "0.0330091752112 1.24132227898 0.752750575542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0317718312144 1.21018779278 0.795353710651\n",
      "0.0363016761839 1.23219811916 0.795353710651\n",
      "0.0354149863124 1.22510147095 0.795353710651\n",
      "0.0351158715785 1.19160032272 0.841314017773\n",
      "0.0332594625652 1.21786928177 0.841314017773\n",
      "0.0345781445503 1.20778274536 0.841314017773\n",
      "0.0351763032377 1.17294740677 0.854009568691\n",
      "0.0318442173302 1.21764600277 0.854009568691\n",
      "0.033702980727 1.2480006218 0.854009568691\n",
      "0.033207282424 1.2129124403 0.805799543858\n",
      "0.0350623205304 1.26290309429 0.805799543858\n",
      "0.034061819315 1.28005802631 0.805799543858\n",
      "0.0364218130708 1.2752301693 0.750113368034\n",
      "0.0345775596797 1.36357009411 0.750113368034\n",
      "0.0330829247832 1.35205245018 0.750113368034\n",
      "0.0371064096689 1.37138366699 0.68157607317\n",
      "0.0336755141616 1.44588804245 0.68157607317\n",
      "0.0330670326948 1.47222709656 0.68157607317\n",
      "0.0341048277915 1.4586482048 0.615107953548\n",
      "0.0347646102309 1.54670405388 0.615107953548\n",
      "0.0366040356457 1.54375779629 0.615107953548\n",
      "0.0338670052588 1.52750885487 0.577205598354\n",
      "0.0336828120053 1.61604440212 0.577205598354\n",
      "0.0329528227448 1.63340485096 0.577205598354\n",
      "0.0291024856269 1.59033823013 0.576238334179\n",
      "0.0361186973751 1.67360043526 0.576238334179\n",
      "0.0336956307292 1.63085186481 0.576238334179\n",
      "0.0345334522426 1.62980055809 0.587574720383\n",
      "0.0355816818774 1.66174924374 0.587574720383\n",
      "0.0333837717772 1.62891089916 0.587574720383\n",
      "0.032749067992 1.5742777586 0.640621423721\n",
      "0.0345504693687 1.59251403809 0.640621423721\n",
      "0.0331412702799 1.60390198231 0.640621423721\n",
      "0.0352907292545 1.56516563892 0.703189611435\n",
      "0.0333063453436 1.55745744705 0.703189611435\n",
      "0.0328421331942 1.54882454872 0.703189611435\n",
      "0.0315002724528 1.52605295181 0.781193196774\n",
      "0.0339504927397 1.53363204002 0.781193196774\n",
      "0.0348204188049 1.49292612076 0.781193196774\n",
      "0.0334044322371 1.52118599415 0.818873524666\n",
      "0.0347255468369 1.54159891605 0.818873524666\n",
      "0.035382900387 1.48797011375 0.818873524666\n",
      "0.0325914025307 1.50116562843 0.820042431355\n",
      "0.0342264585197 1.55396902561 0.820042431355\n",
      "0.0329657830298 1.57255578041 0.820042431355\n",
      "0.0341876074672 1.56342279911 0.783505320549\n",
      "0.0349116325378 1.61100375652 0.783505320549\n",
      "0.0362553633749 1.58819139004 0.783505320549\n",
      "0.036177944392 1.63098144531 0.735307514668\n",
      "0.0359321758151 1.67673456669 0.735307514668\n",
      "0.0367376208305 1.69560790062 0.735307514668\n",
      "0.033910676837 1.66983950138 0.667325377464\n",
      "0.0321613252163 1.68017578125 0.667325377464\n",
      "0.036043047905 1.7501180172 0.667325377464\n",
      "0.0342573598027 1.73579442501 0.61976224184\n",
      "0.0344475582242 1.76575362682 0.61976224184\n",
      "0.0362587235868 1.77039217949 0.61976224184\n",
      "0.0353474132717 1.7568846941 0.608723044395\n",
      "0.0322570353746 1.80585539341 0.608723044395\n",
      "0.0338547639549 1.77950465679 0.608723044395\n",
      "0.0336465500295 1.74246287346 0.613641858101\n",
      "0.0328430607915 1.77313840389 0.613641858101\n",
      "0.0366484411061 1.78707528114 0.613641858101\n",
      "0.0319920070469 1.71478497982 0.641931772232\n",
      "0.0366852506995 1.77173793316 0.641931772232\n",
      "0.0345094427466 1.71591615677 0.641931772232\n",
      "0.0347145460546 1.70795845985 0.688466846943\n",
      "0.0364309437573 1.7047945261 0.688466846943\n",
      "0.0328784435987 1.65625607967 0.688466846943\n",
      "0.0341155491769 1.64683842659 0.742336630821\n",
      "0.0377090424299 1.67279481888 0.742336630821\n",
      "0.0349305085838 1.64198148251 0.742336630821\n",
      "0.03508111462 1.58425343037 0.789159357548\n",
      "0.0324978493154 1.6415951252 0.789159357548\n",
      "0.0304979905486 1.63319730759 0.789159357548\n",
      "0.0323734879494 1.60873746872 0.798531472683\n",
      "0.0311072506011 1.59880280495 0.798531472683\n",
      "0.0330789834261 1.59824883938 0.798531472683\n",
      "0.0330328866839 1.58519721031 0.821074903011\n",
      "0.0331139564514 1.57641112804 0.821074903011\n",
      "0.034240398556 1.6024800539 0.821074903011\n",
      "0.0340781845152 1.55704832077 0.80720192194\n",
      "0.0395828261971 1.56134438515 0.80720192194\n",
      "0.0349767170846 1.56908285618 0.80720192194\n",
      "0.0357750616968 1.53627943993 0.802812576294\n",
      "0.0364907793701 1.57363498211 0.802812576294\n",
      "0.031258482486 1.5717959404 0.802812576294\n",
      "0.0330628938973 1.5885206461 0.780929982662\n",
      "0.035087607801 1.59918832779 0.780929982662\n",
      "0.0325138568878 1.58085119724 0.780929982662\n",
      "0.0316454693675 1.54616296291 0.806168198586\n",
      "0.0389366708696 1.51670539379 0.806168198586\n",
      "0.0324873179197 1.53145444393 0.806168198586\n",
      "0.0356348268688 1.48773574829 0.867669403553\n",
      "0.0331961102784 1.47067308426 0.867669403553\n",
      "0.0357114411891 1.46672546864 0.867669403553\n",
      "0.0374825075269 1.44916510582 0.900260567665\n",
      "0.0359251126647 1.48881483078 0.900260567665\n",
      "0.0343978367746 1.43981921673 0.900260567665\n",
      "0.0334388874471 1.47879469395 0.872928619385\n",
      "0.0329690463841 1.45258903503 0.872928619385\n",
      "0.0343687459826 1.43755710125 0.872928619385\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "for ep in range(epochs):\n",
    "    if(1==1):\n",
    "    #for idx ,(x,label) in enumerate(train_loader):\n",
    "        x,label = get_train_batch(batch_size,validation_iter=0)\n",
    "        label = label.type(torch.FloatTensor).data\n",
    "        z = get_true_z(label)\n",
    "        zhat = E(x)\n",
    "        xhat = G(zhat)\n",
    "        \n",
    "        gen_loss = nn.MSELoss()(xhat,x)\n",
    "        gen_loss.backward(retain_graph=True)\n",
    "        G_solver.step()\n",
    "        E_solver.step()\n",
    "        clear_grad()\n",
    "        \n",
    "        add_small = 1e-10\n",
    "        d_true = D(z)\n",
    "        d_false = D(zhat)\n",
    "        disc_loss = -(torch.mean(torch.log(d_true + add_small) + torch.log((1-d_false) + add_small)))\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        D_solver.step()\n",
    "        clear_grad()\n",
    "        \n",
    "        if(ep%3==0):\n",
    "            zhat = E(x)\n",
    "            d_false = D(zhat)\n",
    "            encoder_loss = -torch.mean(torch.log(d_false + add_small))\n",
    "            encoder_loss.backward()\n",
    "            E_solver.step()\n",
    "            clear_grad()\n",
    "            \n",
    "#     if(ep%10==0):\n",
    "#         xcheck,labels = get_train_batch(batch_size=1000)\n",
    "#         labels_sc = labels.cpu().data.numpy()\n",
    "#         #xcheck = Variable(xcheck.view(1000,28*28).cuda())\n",
    "#         zhat = E(xcheck)\n",
    "#         z_mu = zhat.cpu().data.numpy()\n",
    "#         plt.figure(figsize=(8, 6)) \n",
    "#         #colors = cm.rainbow(np.linspace(0, 1, 10))\n",
    "#         plt.scatter(z_mu[:, 0], z_mu[:, 1],c = labels_sc,cmap=plt.cm.autumn)\n",
    "#         plt.colorbar()\n",
    "#         plt.grid()\n",
    "#         plt.show()         \n",
    "        \n",
    "    print gen_loss.data[0], disc_loss.data[0], encoder_loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xchck = Variable(torch.cuda.FloatTensor(p_fingerprints))\n",
    "zchk = E(xchck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zchk = zchk.data.cpu().numpy()\n",
    "# X_embedded = TSNE(n_components=2).fit_transform(zchk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 6)) \n",
    "# plt.scatter(X_embedded[:, 0], X_embedded[:, 1],c = labels2,cmap=plt.cm.spring)\n",
    "# plt.colorbar()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using a random forest classifier on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47831\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "(47831, 30)\n"
     ]
    }
   ],
   "source": [
    "lables2 = labels2.reshape((labels2.shape[0],))\n",
    "zchk = zchk.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674827098846\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "clf = RandomForestClassifier(n_estimators = 30,max_depth=2, random_state=0,class_weight={0:1,1:200})\n",
    "clf.fit(zchk,labels2)\n",
    "toc = time.time()\n",
    "print (toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp', array([43974,  3687,   129,    41]))\n"
     ]
    }
   ],
   "source": [
    "test_op = clf.predict(zchk)\n",
    "cm1 = metrics.confusion_matrix(labels2,test_op)\n",
    "print('tn, fp, fn, tp',cm1.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/bioassay-datasets/'\n",
    "p_fingerprints_test = []\n",
    "c_fp = []\n",
    "labels = []\n",
    "with open(path+fname+'red_test.csv') as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        p_fingerprints_test.append(row[:bf])\n",
    "        c_fp.append(row[bf:-1])\n",
    "        labels.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11957, 30)\n"
     ]
    }
   ],
   "source": [
    "p_fingerprints_test = np.asarray(p_fingerprints_test)[1:]\n",
    "p_fingerprints_test = p_fingerprints_test.astype(int)\n",
    "\n",
    "## get z_test ##\n",
    "p_test = Variable(torch.cuda.FloatTensor(p_fingerprints_test))\n",
    "z_test = E(p_test)\n",
    "z_test = z_test.cpu().data.numpy()\n",
    "print z_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11957, 122)\n",
      "('total no of 1s', 64311)\n",
      "('total no of 0s', 1394443)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "c_fp = np.asarray(c_fp)[1:]\n",
    "c_fp = c_fp.astype(float)\n",
    "\n",
    "c_fp = (c_fp - np.mean(c_fp,axis=0))/np.std(c_fp,axis=0)\n",
    "\n",
    "fingerprints_test = np.concatenate((p_fingerprints_test,c_fp),axis=1)\n",
    "#p2_fingerprints = np.ones(p_fingerprints.shape)\n",
    "(no_examples , ip_dim) = p_fingerprints_test.shape\n",
    "labels = labels[1:]\n",
    "print(no_examples,ip_dim)\n",
    "print(\"total no of 1s\",np.sum(p_fingerprints_test))\n",
    "print(\"total no of 0s\",no_examples*ip_dim-np.sum(p_fingerprints_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels2_test = np.zeros((len(labels),1))\n",
    "for i,l in enumerate(labels):\n",
    "    if l=='Active':\n",
    "        labels2_test[i] = 1\n",
    "    else:\n",
    "        labels2_test[i] = 0\n",
    "labels2_test = np.asarray(labels2_test,dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp', array([10961,   954,    32,    10]))\n"
     ]
    }
   ],
   "source": [
    "test_op = clf.predict(z_test)\n",
    "cm1 = metrics.confusion_matrix(labels2_test,test_op)\n",
    "print('tn, fp, fn, tp',cm1.ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
