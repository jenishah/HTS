{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn.metrics as metrics\n",
    "import numpy.linalg as la\n",
    "import pickle\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('screen_info.txt','rb') as fl:\n",
    "    t = pickle.load(fl)\n",
    "fnames = t[0]\n",
    "totf = t[1]\n",
    "binf = t[2]\n",
    "runfile = 2\n",
    "fname = fnames[runfile]\n",
    "bf = binf[runfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/minham_'+fname) as f:\n",
    "    p = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/daiict/CVShare/Jeni/hts/bioassay-datasets/' + fname + 'red_train.csv'\n",
    "p_fingerprints = []\n",
    "labels = []\n",
    "with open(path) as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        p_fingerprints.append(row[:112])\n",
    "        labels.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7986, 112)\n",
      "('total no of 1s', 41267)\n",
      "('total no of 0s', 853165)\n"
     ]
    }
   ],
   "source": [
    "p_fingerprints = np.asarray(p_fingerprints)[1:]\n",
    "p_fingerprints = p_fingerprints.astype(int)\n",
    "#p2_fingerprints = np.ones(p_fingerprints.shape)\n",
    "(no_examples , ip_dim) = p_fingerprints.shape\n",
    "labels = labels[1:]\n",
    "print(no_examples,ip_dim)\n",
    "print(\"total no of 1s\",np.sum(p_fingerprints))\n",
    "print(\"total no of 0s\",no_examples*ip_dim-np.sum(p_fingerprints))\n",
    "\n",
    "p_fingerprints[(p_fingerprints==0)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22.]\n"
     ]
    }
   ],
   "source": [
    "labels2 = np.zeros((len(labels),1))\n",
    "for i,l in enumerate(labels):\n",
    "    if l=='Active':\n",
    "        labels2[i] = 1\n",
    "    else:\n",
    "        labels2[i] = 0\n",
    "\n",
    "no_active_ele = (sum(labels2))\n",
    "labels2 = labels2.astype(int)\n",
    "print(no_active_ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AID456'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_inactive = p[1]\n",
    "p_active = p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_batch(batch_size,keep_numpy=False):\n",
    "    samples = np.random.randint(low=0,high=no_examples,size=(batch_size,1))\n",
    "    train_batch = p_fingerprints[samples].reshape(batch_size,ip_dim)\n",
    "    train_batch = train_batch.astype(int)\n",
    "    train_batch = torch.cuda.FloatTensor(train_batch)\n",
    "    train_batch = Variable(train_batch,requires_grad=False).cuda()\n",
    "    if(keep_numpy==False):\n",
    "        target = (torch.cuda.LongTensor(labels2[samples]))\n",
    "    else:\n",
    "        target = labels2[samples]\n",
    "    return train_batch,target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating p_vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p_active = np.float32(np.sum(p_fingerprints[labels2[:,0]==1],axis=0))/np.sum(labels2)\n",
    "# p_inactive = np.float32(np.sum(p_fingerprints[labels2[:,0]==0],axis=0))/(no_examples-np.sum(labels2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying p_vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p_active = p_active + 0.5*(p_active-p_inactive)\n",
    "# p_active[p_active<0] = 0\n",
    "# p_inactive = p_inactive + 0.5*(p_inactive - p_active)\n",
    "# p_inactive[p_inactive<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#find the angle between them\n",
    "theta = np.dot(p_active,p_inactive)/(la.norm(p_active)*la.norm(p_inactive))\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,ip_dim+50)\n",
    "        self.l2 = nn.Linear(ip_dim+50,ip_dim)\n",
    "        self.l3 = nn.Linear(ip_dim,ip_dim)\n",
    "        self.l4 = nn.Linear(ip_dim,ip_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.l1(x))\n",
    "        x = F.tanh(self.l2(x))\n",
    "        x = F.tanh(self.l3(x))\n",
    "        x = self.l4(x)\n",
    "        #x = self.l4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,ip_dim)\n",
    "        self.l2 = nn.Linear(ip_dim,ip_dim)\n",
    "        self.l3 = nn.Linear(ip_dim,ip_dim+50)\n",
    "        self.l4 = nn.Linear(ip_dim+50,ip_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.l1(x))\n",
    "        x = F.tanh(self.l2(x))\n",
    "        x = F.tanh(self.l3(x))\n",
    "        x = F.tanh(self.l4(x))\n",
    "        #x = self.l4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class disc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(disc,self).__init__()\n",
    "        self.lin1 = nn.Linear(ip_dim,500)\n",
    "        self.lin2 = nn.Linear(500,500)\n",
    "        self.lin3 = nn.Linear(500,100)\n",
    "        self.lin4 = nn.Linear(100,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.selu(self.lin1(x))\n",
    "        x = F.selu(self.lin2(x))\n",
    "        x = F.selu(self.lin3(x))\n",
    "        x = F.sigmoid(self.lin4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw samples based on labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_samples(batch_size,labels,var_active,var_inactive):\n",
    "    z = np.zeros((batch_size,ip_dim))\n",
    "    rand_vec = np.random.randn(batch_size,ip_dim)\n",
    "    z[labels==1] = p_active + var_active*rand_vec[labels==1]\n",
    "    z[labels==0] = p_inactive + var_inactive*rand_vec[labels==0]\n",
    "    z = torch.cuda.FloatTensor(z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(Q,Q_solver,P,P_solver,D,D_solver,batch_size):\n",
    "    \n",
    "    for it in range(2000):\n",
    "        x,y = get_train_batch(batch_size,keep_numpy=True)\n",
    "        y = y.reshape(batch_size,)\n",
    "        z = Q(x)\n",
    "        z_false = Q(x)\n",
    "        \n",
    "        \n",
    "        #Reconstruction\n",
    "        \n",
    "        x_recon = P(z)\n",
    "        criterion = nn.MSELoss()\n",
    "        CEL = criterion(x_recon, x)\n",
    "        CEL.backward()\n",
    "        \n",
    "        Q_solver.step()\n",
    "        P_solver.step()\n",
    "        \n",
    "        Q.zero_grad()\n",
    "        P.zero_grad()\n",
    "        \n",
    "        #Discriminator\n",
    "        z_false_op = D(z_false)\n",
    "        z_true = Variable(draw_samples(batch_size,y,var_active=0.4,var_inactive=0.2))\n",
    "        \n",
    "        \n",
    "        z_true_op = Variable(D(z_true).data,requires_grad=False)\n",
    "                \n",
    "        add_small = 1e-20\n",
    "        \n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "        loss_d = criterion(z_false_op,z_true_op)\n",
    "        #loss_d = -torch.mean(torch.log(z_true_op + add_small) + torch.log(1 - z_false_op + add_small))\n",
    "        loss_d.backward(retain_variables = True)\n",
    "        D_solver.step()\n",
    "        D.zero_grad()\n",
    "        \n",
    "        #Updating the encoder\n",
    "        \n",
    "        G_loss = -torch.mean(torch.log(z_false_op+1e-20))\n",
    "        G_loss.backward()\n",
    "        Q_solver.step()\n",
    "        Q_solver.zero_grad()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if(it%50==0):\n",
    "            #print(extra_loss.data[0],CEL.data[0])\n",
    "            print('recon_loss:', CEL.data[0],'disc_loss:', loss_d.data[0],'gen_loss: ',G_loss.data[0])\n",
    "            #print(x_recon[0][:50].cpu().data.numpy().T)\n",
    "            #print()\n",
    "            #print(x[0][:50].cpu().data.numpy().T)\n",
    "           # print()\n",
    "    return Q,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    Q = encoder()\n",
    "    Q.cuda()\n",
    "    Q_solver = optim.Adam(Q.parameters(),lr=1e-4)\n",
    "    E_solver = optim.Adam(Q.parameters(),lr = 1e-5)\n",
    "    P = decoder()\n",
    "    P.cuda()\n",
    "    P_solver = optim.Adam(P.parameters(),lr = 1e-4)\n",
    "    D = disc()\n",
    "    D.cuda()\n",
    "    D_solver = optim.Adam(D.parameters(),lr = 1e-3)\n",
    "    batch_size = 120\n",
    "    Q,P = train_model(Q,Q_solver,P,P_solver,D,D_solver,batch_size)\n",
    "    \n",
    "    return Q,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (121,) (1,112) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b5bed682ec65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-faaf66f02599>\u001b[0m in \u001b[0;36mgenerate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mD_solver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQ_solver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP_solver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD_solver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-871bd96cddc5>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(Q, Q_solver, P, P_solver, D, D_solver, batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mz_false_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_false\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mz_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_active\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_inactive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-2a3f31a4835e>\u001b[0m in \u001b[0;36mdraw_samples\u001b[0;34m(batch_size, labels, var_active, var_inactive)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mip_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrand_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mip_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_active\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvar_active\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrand_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_inactive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvar_inactive\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrand_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (121,) (1,112) "
     ]
    }
   ],
   "source": [
    "Q,P = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = Q(Variable(torch.cuda.FloatTensor(p_fingerprints)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_np = train_encoded.data.cpu().numpy()\n",
    "#train_encoded_np = np.tile(train_encoded_np,(len(train_encoded_np),1))\n",
    "dist_active = la.norm(train_encoded_np - np.tile(p_active,(no_examples,1)),axis=1)\n",
    "dist_inactive = la.norm(train_encoded_np - np.tile(p_inactive,(no_examples,1)),axis=1)\n",
    "d = dist_active - dist_inactive\n",
    "pred_labels = np.zeros((no_examples,1))\n",
    "pred_labels[d>=0] = 1\n",
    "cf = metrics.confusion_matrix(y_pred=pred_labels,y_true=labels2)\n",
    "print('tn, fp, fn, tp: ',cf.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_fingerprints_test = []\n",
    "labels = []\n",
    "path = '/home/daiict/CVShare/Jeni/hts/bioassay-datasets/' + fname + 'red_test.csv'\n",
    "with open(path) as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        p_fingerprints_test.append(row[:112])\n",
    "        labels.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fingerprints_test = np.asarray( p_fingerprints_test)[1:]\n",
    "p_fingerprints_test =  p_fingerprints_test.astype(int)\n",
    "#p2_fingerprints = np.ones(p_fingerprints.shape)\n",
    "(no_examples , ip_dim) =  p_fingerprints_test.shape\n",
    "labels = labels[1:]\n",
    "print(no_examples,ip_dim)\n",
    "print(\"total no of 1s\",np.sum( p_fingerprints_test))\n",
    "print(\"total no of 0s\",no_examples*ip_dim-np.sum( p_fingerprints_test))\n",
    "\n",
    "p_fingerprints_test[( p_fingerprints_test==0)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = np.zeros((len(labels),1))\n",
    "for i,l in enumerate(labels):\n",
    "    if l=='Active':\n",
    "        labels_test[i] = 1\n",
    "    else:\n",
    "        labels_test[i] = 0\n",
    "\n",
    "no_active_ele = (sum(labels_test))\n",
    "labels_test = labels_test.astype(int)\n",
    "print(no_active_ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "test_encoded = Q(Variable(torch.cuda.FloatTensor(p_fingerprints_test)))\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_np = test_encoded.data.cpu().numpy()\n",
    "#train_encoded_np = np.tile(train_encoded_np,(len(train_encoded_np),1))\n",
    "dist_active = la.norm(test_encoded_np - np.tile(p_active,(no_examples,1)),axis=1)\n",
    "dist_inactive = la.norm(test_encoded_np - np.tile(p_inactive,(no_examples,1)),axis=1)\n",
    "d = dist_active - dist_inactive\n",
    "pred_labels = np.zeros((no_examples,1))\n",
    "pred_labels[d>=0] = 1\n",
    "cf = metrics.confusion_matrix(y_pred=pred_labels,y_true=labels_test)\n",
    "print('tn, fp, fn, tp: ',cf.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
