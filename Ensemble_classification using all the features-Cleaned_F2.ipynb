{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "import random\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import pandas as pd\n",
    "#sys.path.append(\"/home/CVShare/Jeni/hts/machine_learning/sampling_with_data_cleaning\")\n",
    "import sampling_with_data_cleaning as sdc\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN on cleaned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7881,)\n",
      "129.0\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "findex = 2\n",
    "x,y = get_features(findex,train=True,cleaned=True)\n",
    "print y.shape\n",
    "print sum(y)\n",
    "y = y.astype(int)\n",
    "print sum(y)\n",
    "x,y = shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7881 153\n"
     ]
    }
   ],
   "source": [
    "no_ex,ip_dim = x.shape\n",
    "print no_ex,ip_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c_mlp,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,1000)\n",
    "        self.l2 = nn.Linear(1000,1000)\n",
    "        self.l3 = nn.Linear(1000,500)\n",
    "        #self.l4 = nn.Linear(500,500)\n",
    "        self.l5 = nn.Linear(500,100)\n",
    "        self.l6 = nn.Linear(100,50)\n",
    "        self.l7 = nn.Linear(50,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = F.leaky_relu(self.l3(x))\n",
    "        #x = F.leaky_relu(self.l4(x))\n",
    "        x = F.leaky_relu(self.l5(x))\n",
    "        x = F.leaky_relu(self.l6(x))\n",
    "        x = (self.l7(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('val iter: ', 1)\n",
      "('tn, fp, fn, tp: ', array([1545,    6,   10,   15]))\n",
      "('min fp, max_percent', 6, 0.6)\n",
      "('saving model on val: ', 1, ' and weight: ', 30.0)\n",
      "('tn, fp, fn, tp: ', array([1545,    6,   10,   15]))\n",
      "('min fp, max_percent', 6, 0.6)\n",
      "('saving model on val: ', 1, ' and weight: ', 35.0)\n",
      "('tn, fp, fn, tp: ', array([1545,    6,   12,   13]))\n",
      "('tn, fp, fn, tp: ', array([1543,    8,   10,   15]))\n",
      "('min fp, max_percent', 8, 0.6)\n",
      "('saving model on val: ', 1, ' and weight: ', 45.0)\n",
      "('tn, fp, fn, tp: ', array([1538,   13,   10,   15]))\n",
      "('min fp, max_percent', 13, 0.6)\n",
      "('saving model on val: ', 1, ' and weight: ', 50.0)\n",
      "('val iter: ', 2)\n",
      "('tn, fp, fn, tp: ', array([1544,    3,   16,   13]))\n",
      "('tn, fp, fn, tp: ', array([1544,    3,   14,   15]))\n",
      "('tn, fp, fn, tp: ', array([1542,    5,   16,   13]))\n",
      "('tn, fp, fn, tp: ', array([1544,    3,   18,   11]))\n",
      "('tn, fp, fn, tp: ', array([1541,    6,   15,   14]))\n",
      "('val iter: ', 3)\n",
      "('tn, fp, fn, tp: ', array([1544,    9,   12,   11]))\n",
      "('tn, fp, fn, tp: ', array([1543,   10,   12,   11]))\n",
      "('tn, fp, fn, tp: ', array([1545,    8,   11,   12]))\n",
      "('tn, fp, fn, tp: ', array([1543,   10,   12,   11]))\n",
      "('tn, fp, fn, tp: ', array([1541,   12,   12,   11]))\n",
      "('val iter: ', 4)\n",
      "('tn, fp, fn, tp: ', array([1536,    9,   14,   17]))\n",
      "('tn, fp, fn, tp: ', array([1536,    9,   14,   17]))\n",
      "('tn, fp, fn, tp: ', array([1534,   11,   14,   17]))\n",
      "('tn, fp, fn, tp: ', array([1535,   10,   18,   13]))\n",
      "('tn, fp, fn, tp: ', array([1536,    9,   14,   17]))\n",
      "('val iter: ', 5)\n",
      "('tn, fp, fn, tp: ', array([1547,    9,    4,   17]))\n",
      "('min fp, max_percent', 9, 0.8095238095238095)\n",
      "('saving model on val: ', 5, ' and weight: ', 30.0)\n",
      "('tn, fp, fn, tp: ', array([1548,    8,    6,   15]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e91dbe972b5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mmodel_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmymlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-dd63af5c88be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#x = F.leaky_relu(self.l4(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/thnn/auto.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, *params)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Allocate temporary buffers and insert them into additional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0madditional_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_initialize_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'update_output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_percent = 0.6\n",
    "model_no = 1\n",
    "for i in range(1,6):\n",
    "    val_iter = i\n",
    "    print(\"val iter: \",val_iter)\n",
    "    \n",
    "   \n",
    "    #weights_array = [7]\n",
    "    weights_array = np.linspace(30,50,5)\n",
    "    \n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(2500):\n",
    "            \n",
    "            ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "            xtrain,ytrain = get_train_batch(x,y,batch_size=100,indices=ind)\n",
    "            \n",
    "            model_op = mymlp(xtrain)\n",
    "           \n",
    "            loss = criterion(model_op,ytrain)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    #     if(ep%30==29):\n",
    "    #         print(loss.data[0])\n",
    "\n",
    "        ## After training check on cross validation data\n",
    "        xval,yval = get_val_data(x,y,no_examples=no_ex,val_iter=val_iter)\n",
    "        min_fp = xval.size()[0]*0.2\n",
    "        yval = yval.reshape(yval.shape[0],)\n",
    "        train_op = mymlp(xval)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "      \n",
    "        cf = metrics.confusion_matrix(yval,pred_labels).ravel()\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        percent = float(float(tp)/float(tp+fn))\n",
    "        if(percent>max_percent*0.98):\n",
    "            if(fp<min_fp):\n",
    "                if(model_no<6):\n",
    "                        max_percent = percent\n",
    "                        print(\"min fp, max_percent\",fp,percent)\n",
    "                        model_path = os.getcwd() + '/fnn_clean_' + str(findex)+'_model'+str(model_no)\n",
    "                        torch.save(mymlp.state_dict(),model_path)\n",
    "                        print(\"saving model on val: \",val_iter,\" and weight: \",w)\n",
    "                        model_no = model_no + 1\n",
    "                else:\n",
    "                    break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1996,)\n",
      "(1996,)\n",
      "(1996,)\n",
      "('tn, fp, fn, tp: ', array([1979,   12,    5,    0]))\n",
      "(1996,)\n",
      "(1996,)\n",
      "('tn, fp, fn, tp: ', array([1975,   16,    5,    0]))\n",
      "(1996,)\n",
      "(1996,)\n",
      "('tn, fp, fn, tp: ', array([1969,   22,    5,    0]))\n",
      "(1996,)\n",
      "(1996,)\n",
      "('tn, fp, fn, tp: ', array([1973,   18,    5,    0]))\n",
      "(1996,)\n",
      "(1996,)\n",
      "('tn, fp, fn, tp: ', array([1976,   15,    5,    0]))\n"
     ]
    }
   ],
   "source": [
    "xtest_t,ytest = get_features(findex,train=False)\n",
    "xtest = Variable(torch.cuda.FloatTensor(xtest_t).cuda())\n",
    "final_pred = np.zeros(ytest.shape[0],)\n",
    "print final_pred.shape\n",
    "for i in range(1,6):\n",
    "    model_path = os.getcwd() + '/fnn_clean_' + str(findex)+'_model'+str(i)\n",
    "    \n",
    "    \n",
    "    test_model = c_mlp().cuda()\n",
    "    test_model.load_state_dict(torch.load(model_path))\n",
    "    test_op = test_model(xtest)\n",
    "    test_op = test_op.cpu().data.numpy()\n",
    "    pred_labels = np.argmax(test_op,axis=1).reshape(final_pred.shape[0],)\n",
    "    print pred_labels.shape\n",
    "    final_pred = pred_labels + final_pred\n",
    "    print final_pred.shape\n",
    "    cf = metrics.confusion_matrix(ytest,pred_labels).ravel()\n",
    "    print('tn, fp, fn, tp: ',cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred[final_pred>1] = 1\n",
    "cf = metrics.confusion_matrix(ytest,final_pred).ravel()\n",
    "print('tn, fp, fn, tp: ',cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
