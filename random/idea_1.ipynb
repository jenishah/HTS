{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn.metrics as metrics\n",
    "import numpy.linalg as la\n",
    "import pickle\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('screen_info.txt','rb') as fl:\n",
    "    t = pickle.load(fl)\n",
    "fnames = t[0]\n",
    "totf = t[1]\n",
    "binf = t[2]\n",
    "runfile = 0\n",
    "fname = fnames[runfile]\n",
    "bf = binf[runfile]\n",
    "\n",
    "with open(os.getcwd()+'/minham_'+fname) as f:\n",
    "    p = pickle.load(f)\n",
    "\n",
    "path = '/home/daiict/CVShare/Jeni/hts/bioassay-datasets/' + fname + 'red_train.csv'\n",
    "p_fingerprints = []\n",
    "labels = []\n",
    "with open(path) as csvfile:\n",
    "    readcsv = csv.reader(csvfile)\n",
    "    for row in readcsv:\n",
    "        p_fingerprints.append(row[:112])\n",
    "        labels.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3423, 112)\n",
      "('total no of 1s', 25982)\n",
      "('total no of 0s', 357394)\n",
      "[ 48.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AID362'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_fingerprints = np.asarray(p_fingerprints)[1:]\n",
    "p_fingerprints = p_fingerprints.astype(int)\n",
    "#p2_fingerprints = np.ones(p_fingerprints.shape)\n",
    "(no_examples , ip_dim) = p_fingerprints.shape\n",
    "labels = labels[1:]\n",
    "print(no_examples,ip_dim)\n",
    "print(\"total no of 1s\",np.sum(p_fingerprints))\n",
    "print(\"total no of 0s\",no_examples*ip_dim-np.sum(p_fingerprints))\n",
    "\n",
    "p_fingerprints[(p_fingerprints==0)] = -1\n",
    "\n",
    "labels2 = np.zeros((len(labels),1))\n",
    "for i,l in enumerate(labels):\n",
    "    if l=='Active':\n",
    "        labels2[i] = 1\n",
    "    else:\n",
    "        labels2[i] = 0\n",
    "\n",
    "no_active_ele = (sum(labels2))\n",
    "labels2 = labels2.astype(int)\n",
    "print(no_active_ele)\n",
    "\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_inactive = p[1]\n",
    "p_active = p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fingerprints[labels2[:,0]==0] = p_fingerprints[labels2[:,0]==0] - p_inactive\n",
    "p_fingerprints[labels2[:,0] ==1] = p_fingerprints[labels2[:,0] == 1] - p_inactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_batch(batch_size,validation_iter=0,binary=True):\n",
    "    \n",
    "    if validation_iter == 0: #no validation\n",
    "        curr_data_size = no_examples\n",
    "        labels_train = labels2\n",
    "    else:\n",
    "        curr_data_size = int(no_examples*0.8)\n",
    "        interval_size = int(no_examples*0.2)\n",
    "        \n",
    "        if(val_iter==1):\n",
    "            s_ind1 = int((validation_iter)*interval_size)\n",
    "            end_ind1 = int((validation_iter+1)*interval_size)\n",
    "            s_ind2 = int((validation_iter + 1) * interval_size)\n",
    "            end_ind2 = int(no_examples)\n",
    "        else:\n",
    "            s_ind1 = 0\n",
    "            end_ind1 = int((validation_iter)*interval_size)\n",
    "            s_ind2 = int((validation_iter + 1) * interval_size)\n",
    "            end_ind2 = int(no_examples)\n",
    "        \n",
    "        #print(\"train_ind \",s_ind1,end_ind1,s_ind2,end_ind2)\n",
    "        indices = range(s_ind1,end_ind1) + range(s_ind2,end_ind2)\n",
    "        #c_train_data = c_fingerprints[indices]\n",
    "        p_train_data = p_fingerprints[indices]\n",
    "        labels_train = labels2[indices]\n",
    "                               \n",
    "    samples = np.random.randint(low=0,high=curr_data_size,size=(batch_size,1))\n",
    "    if binary == True:\n",
    "        train_batch = p_train_data[samples].reshape(batch_size,ip_dim)\n",
    "        train_batch = train_batch.astype(int)\n",
    "    else:\n",
    "        train_batch = c_train_data[samples].reshape(batch_size,feat_dim)\n",
    "        train_batch = train_batch.astype(float)\n",
    "    \n",
    "    train_batch = torch.cuda.FloatTensor(train_batch)\n",
    "    train_batch = Variable(train_batch,requires_grad=False).cuda()\n",
    "    target = Variable(torch.cuda.LongTensor(labels_train[samples]),requires_grad=False)\n",
    "    target = target.view(batch_size,)\n",
    "    return train_batch,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_data(validation_iter,binary = True):\n",
    "    interval_size = int(no_examples)*0.2\n",
    "    s_ind = int((validation_iter-1)*interval_size)\n",
    "    e_ind = int((validation_iter) * interval_size)\n",
    "    if(binary==True):\n",
    "        train_data = p_fingerprints[s_ind:e_ind]\n",
    "    else:\n",
    "        train_data = c_fingerprints[s_ind:e_ind]\n",
    "    labels_val = labels2[s_ind:e_ind]   \n",
    "    #print(\"val ind \",s_ind,e_ind)\n",
    "    #print train_data.shape, labels_val.shape\n",
    "    return Variable(torch.cuda.FloatTensor(train_data)),labels_val  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class b_mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(b_mlp,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,300)\n",
    "        self.l2 = nn.Linear(300,300)\n",
    "        #self.l3 = nn.Linear(1000,500)\n",
    "        self.l4 = nn.Linear(300,300)\n",
    "        self.l5 = nn.Linear(300,50)\n",
    "        self.l6 = nn.Linear(50,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        #x = F.leaky_relu(self.l3(x))\n",
    "        x = F.leaky_relu(self.l4(x))\n",
    "        x = F.leaky_relu(self.l5(x))\n",
    "        x = (self.l6(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('val iter: ', 1)\n",
      "0.517964482307\n",
      "0.428581923246\n",
      "0.340609550476\n",
      "0.268686562777\n",
      "0.203801721334\n",
      "0.156224146485\n",
      "0.121023505926\n",
      "0.0975580215454\n",
      "0.0800771638751\n",
      "0.0625934079289\n",
      "0.0525837168097\n",
      "0.0435859113932\n",
      "0.03607371822\n",
      "0.0325652994215\n",
      "0.0265617761761\n",
      "0.023246653378\n",
      "0.0208307895809\n",
      "0.0175854228437\n",
      "0.0168043766171\n",
      "0.0143629843369\n",
      "0.0129594085738\n",
      "0.0116958077997\n",
      "0.0104383975267\n",
      "0.00989801902324\n",
      "0.00861436780542\n",
      "0.00838187243789\n",
      "0.00763905979693\n",
      "0.0076474850066\n",
      "0.00701396213844\n",
      "0.00640992308035\n",
      "0.00584557838738\n",
      "0.0054649328813\n",
      "0.00565512990579\n",
      "0.00499389693141\n",
      "0.00478556938469\n",
      "0.00450491392985\n",
      "0.00442972732708\n",
      "0.00429928814992\n",
      "0.00387533777393\n",
      "0.00378034915775\n",
      "0.00340229133144\n",
      "0.00346342450939\n",
      "0.00307195447385\n",
      "0.00328856054693\n",
      "0.00302573037334\n",
      "0.0027908324264\n",
      "0.00266108778305\n",
      "0.00253994995728\n",
      "0.0024267276749\n",
      "0.00232632691041\n",
      "0.00227648951113\n",
      "0.00225038803183\n",
      "0.0021446228493\n",
      "0.00209877500311\n",
      "0.00187400449067\n",
      "0.00187152752187\n",
      "0.00186821084935\n",
      "0.00211125472561\n",
      "0.00164780882187\n",
      "0.00177618663292\n",
      "0.00173735886347\n",
      "0.00161365664098\n",
      "0.00174985197373\n",
      "0.00151391292457\n",
      "0.00154603319243\n",
      "0.00140305620153\n",
      "('tn, fp, fn, tp: ', array([636,   0,  48,   0]))\n",
      "('val iter: ', 2)\n",
      "0.634358763695\n",
      "0.602554261684\n",
      "0.482792109251\n",
      "0.495006322861\n",
      "0.370345503092\n",
      "0.375909030437\n",
      "0.224709063768\n",
      "0.47201898694\n",
      "0.418388456106\n",
      "0.246327802539\n",
      "0.411724209785\n",
      "0.335580974817\n",
      "0.107117429376\n",
      "0.324510931969\n",
      "0.231069520116\n",
      "0.0920682027936\n",
      "0.432506293058\n",
      "0.328955471516\n",
      "0.207385003567\n",
      "0.204138576984\n",
      "0.0815789625049\n",
      "0.4365927279\n",
      "0.426654100418\n",
      "0.207279145718\n",
      "0.223905384541\n",
      "0.29538461566\n",
      "0.0791960582137\n",
      "0.205673873425\n",
      "0.197419270873\n",
      "0.0754772424698\n",
      "0.212902143598\n",
      "0.211714193225\n",
      "0.0726058185101\n",
      "0.330192327499\n",
      "0.203469216824\n",
      "0.4177313447\n",
      "0.192102357745\n",
      "0.524546325207\n",
      "0.0731609240174\n",
      "0.0767368748784\n",
      "0.0747391730547\n",
      "0.317349046469\n",
      "0.0769632235169\n",
      "0.214262664318\n",
      "0.424934417009\n",
      "0.220075145364\n",
      "0.200038805604\n",
      "0.435439378023\n",
      "0.208616867661\n",
      "0.206579387188\n",
      "0.305022537708\n",
      "0.456756770611\n",
      "0.515866160393\n",
      "0.424179643393\n",
      "0.47106435895\n",
      "0.32333818078\n",
      "0.526101946831\n",
      "0.0782491713762\n",
      "0.0809316784143\n",
      "0.210173815489\n",
      "0.199411347508\n",
      "0.0747843459249\n",
      "0.07681851089\n",
      "0.0772049874067\n",
      "0.213696092367\n",
      "0.49636182189\n",
      "('tn, fp, fn, tp: ', array([685]))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f0b98137cb03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#print(val_iter,w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tn, fp, fn, tp: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mwcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtmpdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    }
   ],
   "source": [
    "min_fn = 15\n",
    "max_fp = 200\n",
    "maxtmpdiff = -2\n",
    "cm_list = []\n",
    "get_model = 1\n",
    "\n",
    "batch_size = 90\n",
    "\n",
    "for val_iter in range(1,6):\n",
    "    print(\"val iter: \",val_iter)\n",
    "    \n",
    "   \n",
    "    weights_array = [5]\n",
    "    #weights_array = np.linspace(50,70,10)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp = b_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp.parameters(),lr=1e-4)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        cost_track = []\n",
    "        epochs = 2000\n",
    "        for ep in range(epochs):\n",
    "            train_batch,target = get_train_batch(batch_size,binary = True,validation_iter = val_iter)\n",
    "            model_op = mymlp(train_batch)\n",
    "            #print(model_op.type)\n",
    "            #print(target.type)\n",
    "            loss = criterion(model_op,target)\n",
    "            loss.backward()\n",
    "            cost_track.append(loss)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if(ep%30==29):\n",
    "                print(loss.data[0])\n",
    "\n",
    "        plt.plot(range(epochs),cost_track)\n",
    "        plt.show()\n",
    "        \n",
    "        ## After training check on cross validation data\n",
    "        val_data,labels_val = get_val_data(val_iter,binary = True)\n",
    "        train_op = mymlp(val_data)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "        #tmp_labels = tmp_labels.data.cpu().numpy()\n",
    "        #print(sum(tmp_labels))\n",
    "        cf = metrics.confusion_matrix(labels_val,pred_labels).ravel()\n",
    "        #print(val_iter,w)\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        wcf = [val_iter] + [w] + [cf]\n",
    "        tmpdiff = tp-fn\n",
    "        if(tmpdiff >= maxtmpdiff):\n",
    "            cm_list.append(wcf)\n",
    "            if(tmpdiff>= maxtmpdiff):\n",
    "                if(fp <= max_fp):\n",
    "                    max_fp = fp\n",
    "                    maxtmpdiff = tmpdiff\n",
    "                    model_path = os.getcwd() + '/kernel_mac' + fname + '_' + str(get_model)\n",
    "                    torch.save(mymlp.state_dict(),model_path)\n",
    "                    print(\"saving model on val: \",val_iter,\" and weight: \",w)\n",
    "                    if(get_model<4):\n",
    "                        get_model = get_model + 1\n",
    "                    else:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([685])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([685])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(labels_val,pred_labels).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
