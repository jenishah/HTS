{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from torch.autograd import Variable\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "import random\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import pandas as pd\n",
    "#sys.path.append(\"/home/CVShare/Jeni/hts/machine_learning/sampling_with_data_cleaning\")\n",
    "import sampling_with_data_cleaning as sdc\n",
    "from utils import *\n",
    "import sampling_with_data_cleaning as sdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN on normal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7881,)\n",
      "129.0\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "findex = 2\n",
    "x,y = get_features(findex,train=True,cleaned=True)\n",
    "print y.shape\n",
    "print sum(y)\n",
    "y = y.astype(int)\n",
    "print sum(y)\n",
    "x,y = shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7881 153\n"
     ]
    }
   ],
   "source": [
    "no_ex,ip_dim = x.shape\n",
    "print no_ex,ip_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c_mlp,self).__init__()\n",
    "        self.l1 = nn.Linear(ip_dim,500)\n",
    "        self.l2 = nn.Linear(500,500)\n",
    "        self.l3 = nn.Linear(500,500)\n",
    "        self.l4 = nn.Linear(500,100)\n",
    "        self.l5 = nn.Linear(100,30)\n",
    "        self.l6 = nn.Linear(30,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        #x = F.leaky_relu(self.l3(x))\n",
    "        x = F.leaky_relu(self.l4(x))\n",
    "        x = F.leaky_relu(self.l5(x))\n",
    "        x = (self.l6(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.105780228972\n",
      "0.0783683657646\n",
      "0.0376045443118\n",
      "0.106086723506\n",
      "0.0839707776904\n",
      "0.064403116703\n",
      "0.0986544042826\n",
      "0.0642578452826\n",
      "0.0667999535799\n",
      "0.0855871140957\n",
      "0.0905609354377\n",
      "0.097773462534\n",
      "0.0913430973887\n",
      "0.125619396567\n",
      "0.0441837161779\n",
      "0.0226480867714\n",
      "0.0401112698019\n",
      "0.0317909680307\n",
      "0.0739508420229\n",
      "0.100209616125\n",
      "0.0699261948466\n",
      "0.0512844100595\n",
      "0.054569683969\n",
      "0.0657065957785\n",
      "0.0816217958927\n",
      "0.135687708855\n",
      "0.0573780499399\n",
      "0.0346733294427\n",
      "0.0295233707875\n",
      "0.0528658516705\n",
      "0.019427401945\n",
      "0.0396709479392\n",
      "0.116745777428\n",
      "0.0424507521093\n",
      "0.0680215060711\n",
      "0.0678362473845\n",
      "0.0326717533171\n",
      "0.0387614704669\n",
      "0.0570288151503\n",
      "0.0174219794571\n",
      "0.0392023511231\n",
      "0.0385765470564\n",
      "0.0350663363934\n",
      "0.00908144563437\n",
      "0.0224525686353\n",
      "0.0470472685993\n",
      "0.0181341338903\n",
      "0.0381902940571\n",
      "0.0338332019746\n",
      "0.0417667850852\n",
      "0.0169199630618\n",
      "0.0440876297653\n",
      "0.02527474612\n",
      "0.0354266315699\n",
      "0.0194860361516\n",
      "0.0346940197051\n",
      "0.0400318577886\n",
      "0.0924149602652\n",
      "0.0124143026769\n",
      "0.00676574697718\n",
      "0.0435386672616\n",
      "0.00329604139552\n",
      "0.0131255909801\n",
      "0.029095903039\n",
      "0.0164857506752\n",
      "0.0304055325687\n"
     ]
    }
   ],
   "source": [
    "max_percent = 0.5\n",
    "min_fp = no_ex*0.2\n",
    "#for i in range(1,6):\n",
    "if(1==1):\n",
    "    val_iter = 0\n",
    "    \n",
    "   \n",
    "    weights_array = [1]\n",
    "    #weights_array = np.linspace(10,40,10)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(2000):\n",
    "            \n",
    "            ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "            xtrain,ytrain = get_train_batch(x,y,batch_size=200,indices=ind)\n",
    "            \n",
    "            model_op = mymlp(xtrain)\n",
    "           \n",
    "            loss = criterion(model_op,ytrain)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if(ep%30==29):\n",
    "                print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training over\n",
      "('tn, fp, fn, tp: ', array([7746,    6,   39,   90]))\n"
     ]
    }
   ],
   "source": [
    "if(1==1):\n",
    "    if(1==1):\n",
    "        ## After training check on ORINGAL data\n",
    "        print('Training over')\n",
    "        xch = Variable(torch.cuda.FloatTensor(x))\n",
    "        train_op = mymlp(xch)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "      \n",
    "        cf = metrics.confusion_matrix(y,pred_labels).ravel()\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        percent = float(float(tp)/float(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + '/boost_clean_a' + str(findex)\n",
    "torch.save(mymlp.state_dict(),model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Just checking on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp: ', array([1983,    8,    5,    0]))\n"
     ]
    }
   ],
   "source": [
    "xtest,ytest = get_features(findex,train=False)\n",
    "ytest = ytest.astype(int)\n",
    "xtest = Variable(torch.cuda.FloatTensor(xtest))\n",
    "testmodel = c_mlp().cuda()\n",
    "testmodel.load_state_dict(torch.load(model_path))\n",
    "test_op = testmodel(xtest).cpu().data.numpy()\n",
    "test_op = np.argmax(test_op,axis=1)\n",
    "cf = metrics.confusion_matrix(ytest,test_op).ravel()\n",
    "[tn,fp,fn,tp] = cf\n",
    "print('tn, fp, fn, tp: ',cf)\n",
    "percent = float(float(tp)/float(tp+fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out +ve samples on which this fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 1)\n",
      "(7842, 153) (7842,)\n"
     ]
    }
   ],
   "source": [
    "#y_hack = np.zeros(y.shape)\n",
    "#y_hack[y==1] = 5\n",
    "y = y.reshape(y.shape[0],)\n",
    "next_t = y-pred_labels  #next_ind will be 1 for which pred_labels have predicted inactive\n",
    "next_ind = np.argwhere(next_t == 1)\n",
    "print next_ind.shape\n",
    "xtmp = np.delete(x,next_ind,axis=0)\n",
    "ytmp = np.delete(y,next_ind,axis=0)\n",
    "print xtmp.shape, ytmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Adding 97 new samples\n",
      "removing 26 samples\n",
      "[2349 1990 6047 3704 1507 6230 2916 3372  553 5209 6291 7775 3161 3649 6520\n",
      " 2141 6718 7602 7178 2462 1923 6734 6099 1704 1889 5051]\n"
     ]
    }
   ],
   "source": [
    "xnew,ynew = sdc.clean_data(xtmp,ytmp,k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ynew = ynew.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.100020326674\n",
      "0.147966355085\n",
      "0.108428575099\n",
      "0.114323116839\n",
      "0.0606371499598\n",
      "0.0358465053141\n",
      "0.10158097744\n",
      "0.12946844101\n",
      "0.117929942906\n",
      "0.181353494525\n",
      "0.0705535411835\n",
      "0.136251226068\n",
      "0.11305937171\n",
      "0.0509777069092\n",
      "0.038243688643\n",
      "0.0643781498075\n",
      "0.0547373145819\n",
      "0.0607002191246\n",
      "0.0843674987555\n",
      "0.0612891949713\n",
      "0.0811889842153\n",
      "0.0480520166457\n",
      "0.0728653892875\n",
      "0.0858905315399\n",
      "0.0600149780512\n",
      "0.0659052506089\n",
      "0.02327625826\n",
      "0.0676613748074\n",
      "0.0795780420303\n",
      "0.0885193869472\n",
      "0.0381510481238\n",
      "0.045357093215\n",
      "0.0873620435596\n",
      "0.0330195501447\n",
      "0.099658280611\n",
      "0.0423472225666\n",
      "0.0139985848218\n",
      "0.0215290896595\n",
      "0.0222295317799\n",
      "0.022947544232\n",
      "0.0215113647282\n",
      "0.0154647873715\n",
      "0.0248546954244\n",
      "0.0136203793809\n",
      "0.0321335569024\n",
      "0.00886239111423\n",
      "0.0184576343745\n",
      "0.00960175786167\n",
      "0.0327467806637\n",
      "0.0141112627462\n",
      "0.0423163212836\n",
      "0.0060911718756\n",
      "0.0174268316478\n",
      "0.00693074567243\n",
      "0.00227925693616\n",
      "0.0192413870245\n",
      "0.0121884588152\n",
      "0.0122456792742\n",
      "0.0265737902373\n",
      "0.0195202063769\n",
      "0.0210574511439\n",
      "0.00402791565284\n",
      "0.00865935720503\n",
      "0.00719616096467\n",
      "0.0024342678953\n",
      "0.00310202362016\n",
      "0.0134446863085\n",
      "0.00858838576823\n",
      "0.0141840744764\n",
      "0.00357724656351\n",
      "0.0172197129577\n",
      "0.013559143059\n",
      "0.0163137242198\n",
      "0.00461338134483\n",
      "0.0123046673834\n",
      "0.0085125528276\n",
      "0.00224793842062\n",
      "0.00602463353425\n",
      "0.0067610675469\n",
      "0.00435709627345\n",
      "0.0112351318821\n",
      "0.00212007761002\n",
      "0.00423571979627\n"
     ]
    }
   ],
   "source": [
    "max_percent = 0.5\n",
    "no_ex = xnew.shape[0]\n",
    "min_fp = no_ex*0.2\n",
    "#for i in range(1,6):\n",
    "if(1==1):\n",
    "    val_iter = 0\n",
    "    \n",
    "   \n",
    "    weights_array = [1]\n",
    "    #weights_array = np.linspace(10,40,10)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp_b = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp_b.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(2500):\n",
    "            \n",
    "            ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "            xtrain,ytrain = get_train_batch(xnew,ynew,batch_size=150,indices=ind)\n",
    "            \n",
    "            model_op = mymlp_b(xtrain)\n",
    "           \n",
    "            loss = criterion(model_op,ytrain)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if(ep%30==29):\n",
    "                print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training over\n",
      "('tn, fp, fn, tp: ', array([7724,    2,    8,  179]))\n"
     ]
    }
   ],
   "source": [
    "if(1==1):\n",
    "    if(1==1):\n",
    "        ## After training check on ORINGAL data\n",
    "        print('Training over')\n",
    "        xch = Variable(torch.cuda.FloatTensor(xnew))\n",
    "        train_op = mymlp_b(xch)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "      \n",
    "        cf = metrics.confusion_matrix(ynew,pred_labels).ravel()\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        percent = float(float(tp)/float(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + '/boost_clean_b' + str(findex)\n",
    "torch.save(mymlp_b.state_dict(),model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp: ', array([1983,    8,    5,    0]))\n"
     ]
    }
   ],
   "source": [
    "## Test after training on both\n",
    "xtest,ytest = get_features(findex,train=False)\n",
    "xtest = Variable(torch.cuda.FloatTensor(xtest))\n",
    "opa = mymlp(xtest).data.cpu().numpy()\n",
    "pred1 = np.argmax(opa,axis=1)\n",
    "opb = mymlp_b(xtest).data.cpu().numpy()\n",
    "pred2 = np.argmax(opb,axis=1)\n",
    "#opc = mymlp_c(xtest).data.cpu().numpy()\n",
    "#pred3 = np.argmax(opc,axis=1)\n",
    "\n",
    "final_pred = pred1 + pred2# + pred3\n",
    "final_pred[final_pred>0] = 1\n",
    "\n",
    "cf = metrics.confusion_matrix(ytest,final_pred).ravel()\n",
    "[tn,fp,fn,tp] = cf\n",
    "print('tn, fp, fn, tp: ',cf)\n",
    "percent = float(float(tp)/float(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp: ', array([1986,    5,    5,    0]))\n"
     ]
    }
   ],
   "source": [
    "cf = metrics.confusion_matrix(ytest,pred2).ravel()\n",
    "[tn,fp,fn,tp] = cf\n",
    "print('tn, fp, fn, tp: ',cf)\n",
    "percent = float(float(tp)/float(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1)\n",
      "(7905, 153) (7905,)\n"
     ]
    }
   ],
   "source": [
    "ynew = ynew.reshape(ynew.shape[0],)\n",
    "next_t = ynew-pred_labels  #next_ind will be 1 for which pred_labels have predicted inactive\n",
    "next_ind = np.argwhere(next_t == 1)\n",
    "print next_ind.shape\n",
    "xtmp = np.delete(xnew,next_ind,axis=0)\n",
    "ytmp = np.delete(ynew,next_ind,axis=0)\n",
    "print xtmp.shape, ytmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Adding 30 new samples\n",
      "removing 15 samples\n",
      "[7453  526 5064 6541 2390 2943 7595 7688 3075  732 3489 3174 5834 3408 1513]\n"
     ]
    }
   ],
   "source": [
    "xnew2,ynew2 = sdc.clean_data(xtmp,ytmp,k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ynew2 = ynew2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.161867260933\n",
      "0.0972013548017\n",
      "0.138442531228\n",
      "0.0855605974793\n",
      "0.0636093094945\n",
      "0.052924849093\n",
      "0.0971305221319\n",
      "0.1013789922\n",
      "0.107973277569\n",
      "0.0533413179219\n",
      "0.0641384497285\n",
      "0.0764310657978\n",
      "0.0609779804945\n",
      "0.0526796393096\n",
      "0.0997552722692\n",
      "0.0389297902584\n",
      "0.0503053888679\n",
      "0.0494070313871\n",
      "0.0726574733853\n",
      "0.0770090892911\n",
      "0.0285440068692\n",
      "0.0563500486314\n",
      "0.0589921623468\n",
      "0.0229014977813\n",
      "0.0512113943696\n",
      "0.0121485311538\n",
      "0.0497678443789\n",
      "0.0151376705617\n",
      "0.0577541589737\n",
      "0.0596417933702\n",
      "0.0179365240037\n",
      "0.0266345832497\n",
      "0.0446280017495\n",
      "0.0293675065041\n",
      "0.028711521998\n",
      "0.0277307517827\n",
      "0.0357581339777\n",
      "0.0212229061872\n",
      "0.0138394720852\n",
      "0.0246779918671\n",
      "0.0187380667776\n",
      "0.0161620508879\n",
      "0.013542030938\n",
      "0.0134357418865\n",
      "0.0218046661466\n",
      "0.00901272334158\n",
      "0.00233350438066\n",
      "0.0106224957854\n",
      "0.00855824071914\n",
      "0.00510103069246\n",
      "0.016798870638\n",
      "0.0132543118671\n",
      "0.00385350384749\n",
      "0.00756954448298\n",
      "0.0121798114851\n",
      "0.00736415060237\n",
      "0.012183717452\n",
      "0.0188790280372\n",
      "0.00490781804547\n",
      "0.0107836714014\n",
      "0.00454638944939\n",
      "0.00762637844309\n",
      "0.00426781084388\n",
      "0.0042483061552\n",
      "0.00413618329912\n",
      "0.00777434743941\n"
     ]
    }
   ],
   "source": [
    "max_percent = 0.5\n",
    "no_ex = xnew2.shape[0]\n",
    "min_fp = no_ex*0.2\n",
    "#for i in range(1,6):\n",
    "if(1==1):\n",
    "    val_iter = 0\n",
    "    \n",
    "   \n",
    "    weights_array = [1]\n",
    "    #weights_array = np.linspace(10,40,10)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp_c = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp_c.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(2000):\n",
    "            \n",
    "            ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "            xtrain,ytrain = get_train_batch(xnew2,ynew2,batch_size=150,indices=ind)\n",
    "            \n",
    "            model_op = mymlp_c(xtrain)\n",
    "           \n",
    "            loss = criterion(model_op,ytrain)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if(ep%30==29):\n",
    "                print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + '/boost_clean_c' + str(findex)\n",
    "torch.save(mymlp_c.state_dict(),model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tn, fp, fn, tp: ', array([1981,   10,    5,    0]))\n"
     ]
    }
   ],
   "source": [
    "## Test after training on both\n",
    "xtest,ytest = get_features(findex,train=False)\n",
    "xtest = Variable(torch.cuda.FloatTensor(xtest))\n",
    "opa = mymlp(xtest).data.cpu().numpy()\n",
    "pred1 = np.argmax(opa,axis=1)\n",
    "opb = mymlp_b(xtest).data.cpu().numpy()\n",
    "pred2 = np.argmax(opb,axis=1)\n",
    "opc = mymlp_c(xtest).data.cpu().numpy()\n",
    "pred3 = np.argmax(opc,axis=1)\n",
    "\n",
    "final_pred = pred1 + pred2 + pred3\n",
    "final_pred[final_pred>0] = 1\n",
    "\n",
    "cf = metrics.confusion_matrix(ytest,final_pred).ravel()\n",
    "[tn,fp,fn,tp] = cf\n",
    "print('tn, fp, fn, tp: ',cf)\n",
    "percent = float(float(tp)/float(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
