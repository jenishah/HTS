{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "%matplotlib notebook\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findex = 0\n",
    "xtmp,y = get_features(findex,cleaned=True)\n",
    "xtmp,y = shuffle(xtmp,y)\n",
    "y = y.astype(int)\n",
    "no_ex = xtmp.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_features are real valued features. We apply kernel on it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_dim = 250\n",
    "\n",
    "rbf_feature = RBFSampler(gamma=1,n_components = feat_dim, random_state=1)\n",
    "x = rbf_feature.fit_transform(xtmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c_mlp,self).__init__()\n",
    "        self.l1 = nn.Linear(feat_dim,1000)\n",
    "        self.l2 = nn.Linear(1000,1000)\n",
    "        self.l3 = nn.Linear(1000,500)\n",
    "        self.l4 = nn.Linear(500,500)\n",
    "        self.l5 = nn.Linear(500,50)\n",
    "        self.l6 = nn.Linear(50,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = F.leaky_relu(self.l3(x))\n",
    "        x = F.leaky_relu(self.l4(x))\n",
    "        x = F.leaky_relu(self.l5(x))\n",
    "        x = (self.l6(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('val iter: ', 1)\n",
      "('tn, fp, fn, tp: ', array([594,  15,  39,  13]))\n",
      "('tn, fp, fn, tp: ', array([593,  16,  38,  14]))\n",
      "('tn, fp, fn, tp: ', array([598,  11,  39,  13]))\n",
      "('tn, fp, fn, tp: ', array([595,  14,  40,  12]))\n",
      "('tn, fp, fn, tp: ', array([595,  14,  41,  11]))\n",
      "('tn, fp, fn, tp: ', array([593,  16,  36,  16]))\n",
      "('tn, fp, fn, tp: ', array([592,  17,  41,  11]))\n",
      "('tn, fp, fn, tp: ', array([583,  26,  38,  14]))\n",
      "('tn, fp, fn, tp: ', array([593,  16,  37,  15]))\n",
      "('tn, fp, fn, tp: ', array([593,  16,  41,  11]))\n",
      "('val iter: ', 2)\n",
      "('tn, fp, fn, tp: ', array([597,  11,  35,  18]))\n",
      "('tn, fp, fn, tp: ', array([597,  11,  35,  18]))\n",
      "('tn, fp, fn, tp: ', array([593,  15,  37,  16]))\n",
      "('tn, fp, fn, tp: ', array([596,  12,  36,  17]))\n",
      "('tn, fp, fn, tp: ', array([597,  11,  36,  17]))\n",
      "('tn, fp, fn, tp: ', array([595,  13,  38,  15]))\n",
      "('tn, fp, fn, tp: ', array([593,  15,  36,  17]))\n",
      "('tn, fp, fn, tp: ', array([596,  12,  39,  14]))\n",
      "('tn, fp, fn, tp: ', array([597,  11,  38,  15]))\n",
      "('tn, fp, fn, tp: ', array([595,  13,  37,  16]))\n",
      "('val iter: ', 3)\n",
      "('tn, fp, fn, tp: ', array([601,  15,  29,  16]))\n",
      "('tn, fp, fn, tp: ', array([600,  16,  29,  16]))\n",
      "('tn, fp, fn, tp: ', array([597,  19,  31,  14]))\n",
      "('tn, fp, fn, tp: ', array([602,  14,  29,  16]))\n",
      "('tn, fp, fn, tp: ', array([603,  13,  28,  17]))\n",
      "('tn, fp, fn, tp: ', array([603,  13,  28,  17]))\n",
      "('tn, fp, fn, tp: ', array([603,  13,  27,  18]))\n",
      "('tn, fp, fn, tp: ', array([601,  15,  29,  16]))\n",
      "('tn, fp, fn, tp: ', array([606,  10,  27,  18]))\n",
      "('tn, fp, fn, tp: ', array([604,  12,  31,  14]))\n",
      "('val iter: ', 4)\n",
      "('tn, fp, fn, tp: ', array([596,  17,  37,  11]))\n",
      "('tn, fp, fn, tp: ', array([601,  12,  34,  14]))\n",
      "('tn, fp, fn, tp: ', array([600,  13,  34,  14]))\n",
      "('tn, fp, fn, tp: ', array([602,  11,  34,  14]))\n",
      "('tn, fp, fn, tp: ', array([598,  15,  37,  11]))\n",
      "('tn, fp, fn, tp: ', array([600,  13,  34,  14]))\n",
      "('tn, fp, fn, tp: ', array([597,  16,  34,  14]))\n",
      "('tn, fp, fn, tp: ', array([597,  16,  32,  16]))\n",
      "('tn, fp, fn, tp: ', array([599,  14,  32,  16]))\n",
      "('tn, fp, fn, tp: ', array([595,  18,  34,  14]))\n",
      "('val iter: ', 5)\n",
      "('tn, fp, fn, tp: ', array([597,  14,  42,   9]))\n",
      "('tn, fp, fn, tp: ', array([598,  13,  42,   9]))\n",
      "('tn, fp, fn, tp: ', array([596,  15,  40,  11]))\n",
      "('tn, fp, fn, tp: ', array([589,  22,  41,  10]))\n",
      "('tn, fp, fn, tp: ', array([598,  13,  40,  11]))\n",
      "('tn, fp, fn, tp: ', array([590,  21,  40,  11]))\n",
      "('tn, fp, fn, tp: ', array([596,  15,  42,   9]))\n",
      "('tn, fp, fn, tp: ', array([598,  13,  41,  10]))\n",
      "('tn, fp, fn, tp: ', array([596,  15,  39,  12]))\n",
      "('tn, fp, fn, tp: ', array([596,  15,  38,  13]))\n"
     ]
    }
   ],
   "source": [
    "max_percent = 0.5\n",
    "\n",
    "for i in range(1,6):\n",
    "    val_iter = i\n",
    "    print(\"val iter: \",val_iter)\n",
    "    \n",
    "   \n",
    "    #weights_array = [7]\n",
    "    weights_array = np.linspace(50,90,10)\n",
    "    for i,w in enumerate(weights_array): \n",
    "        mymlp = c_mlp().cuda()\n",
    "        optimizer = torch.optim.Adagrad(mymlp.parameters(),lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([1,w]))\n",
    "\n",
    "        for ep in range(2000):\n",
    "            \n",
    "            ind = get_train_ind(val_iter=val_iter,no_examples=no_ex)\n",
    "            xtrain,ytrain = get_train_batch(x,y,batch_size=90,indices=ind)\n",
    "            \n",
    "            model_op = mymlp(xtrain)\n",
    "           \n",
    "            loss = criterion(model_op,ytrain)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    #     if(ep%30==29):\n",
    "    #         print(loss.data[0])\n",
    "\n",
    "        ## After training check on cross validation data\n",
    "        xval,yval = get_val_data(x,y,no_examples=no_ex,val_iter=val_iter)\n",
    "        yval = yval.reshape(yval.shape[0],)\n",
    "        train_op = mymlp(xval)\n",
    "        train_op = train_op.cpu().data.numpy()\n",
    "        pred_labels = np.argmax(train_op,axis=1)\n",
    "        min_fp = xval.size()[0]*0.2\n",
    "        cf = metrics.confusion_matrix(yval,pred_labels).ravel()\n",
    "        [tn,fp,fn,tp] = cf\n",
    "        print('tn, fp, fn, tp: ',cf)\n",
    "        percent = float(float(tp)/float(tp+fn))\n",
    "        if(percent>max_percent):\n",
    "            if(1==1):\n",
    "                if(fp < min_fp):\n",
    "                    min_fp = fp\n",
    "                    max_percent = percent\n",
    "                    print(\"min fp, max_percent\",fp,percent)\n",
    "                    model_path = os.getcwd() + '/kernel_clean' + str(findex)\n",
    "                    torch.save(mymlp.state_dict(),model_path)\n",
    "                    print(\"saving model on val: \",val_iter,\" and weight: \",w)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-49e6067d6d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrbf_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRBFSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbf_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mc_fingerprints_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_features' is not defined"
     ]
    }
   ],
   "source": [
    "feat_dim = 250\n",
    "\n",
    "rbf_feature = RBFSampler(gamma=1,n_components = feat_dim, random_state=1)\n",
    "trans = rbf_feature.fit(X_features)\n",
    "c_fingerprints_test = trans.transform(X_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testmlp = c_mlp().cuda()\n",
    "model_path = os.getcwd() + '/kernel_mac' + fname + '_3'\n",
    "testmlp.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op = testmlp(Variable(torch.cuda.FloatTensor(c_fingerprints_test)))\n",
    "op = op.cpu().data.numpy()\n",
    "pred_labels = np.argmax(op,axis=1)\n",
    "cf = metrics.confusion_matrix(labels2_t,pred_labels).ravel()\n",
    "#print(val_iter,w)\n",
    "print('tn, fp, fn, tp: ',cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(labels2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
